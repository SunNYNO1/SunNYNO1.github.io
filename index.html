<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <link rel="dns-prefetch" href="http://yoursite.com">
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.0cf68a.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

<meta name="generator" content="Hexo 5.1.1"></head>

<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/"></a></h1>
		</hgroup>
		

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/tags/%E9%9A%8F%E7%AC%94/">随笔</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'innerArchive')" href="javascript:void(0)">所有文章</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
		        
					<a class="weibo" target="_blank" href="#" title="weibo"><i class="icon-weibo"></i></a>
		        
					<a class="rss" target="_blank" href="#" title="rss"><i class="icon-rss"></i></a>
		        
					<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author"></h1>
			</hgroup>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="#" title="github"><i class="icon-github"></i></a>
			        
						<a class="weibo" target="_blank" href="#" title="weibo"><i class="icon-weibo"></i></a>
			        
						<a class="rss" target="_blank" href="#" title="rss"><i class="icon-rss"></i></a>
			        
						<a class="zhihu" target="_blank" href="#" title="zhihu"><i class="icon-zhihu"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/tags/%E9%9A%8F%E7%AC%94/">随笔</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-hexo_blog follow CodeSheep" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="跟着CodeSheep搭建博客"><a href="#跟着CodeSheep搭建博客" class="headerlink" title="跟着CodeSheep搭建博客"></a>跟着CodeSheep搭建博客</h1><!-- TOC -->

<ul>
<li><a href="#%E8%B7%9F%E7%9D%80codesheep%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2">跟着CodeSheep搭建博客</a><ul>
<li><a href="#%E6%90%AD%E5%BB%BAhexo%E5%8D%9A%E5%AE%A2%E7%9A%84%E7%8E%AF%E5%A2%83%E6%94%AF%E6%8C%81">搭建hexo博客的环境支持</a></li>
<li><a href="#%E5%AE%89%E8%A3%85hexo">安装hexo</a></li>
<li><a href="#%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2">使用hexo搭建博客</a></li>
<li><a href="#%E5%B0%86%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2%E5%88%B0%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93">将博客部署到远程仓库</a></li>
<li><a href="#%E4%BF%AE%E6%94%B9%E5%8D%9A%E5%AE%A2%E4%B8%BB%E9%A2%98">修改博客主题</a></li>
</ul>
</li>
</ul>
<!-- /TOC -->
<h3 id="搭建hexo博客的环境支持"><a href="#搭建hexo博客的环境支持" class="headerlink" title="搭建hexo博客的环境支持"></a>搭建hexo博客的环境支持</h3><ul>
<li><p>nodejs下载安装</p>
</li>
<li><p>查看nodejs版本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node -v</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看npm包管理器版本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm -v</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h3><ul>
<li><p>安装cnpm(国内npm源)：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g cnpm ---registry=https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看cnpm版本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm -v</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装hexo：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnpm install -g hexo-cli</span><br></pre></td></tr></table></figure></li>
<li><p>验证安装是否成功：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo -v</span><br></pre></td></tr></table></figure>
<h3 id="使用hexo搭建博客"><a href="#使用hexo搭建博客" class="headerlink" title="使用hexo搭建博客"></a>使用hexo搭建博客</h3></li>
<li><p>创建本地文件夹LocalBlog（放置博客代码）</p>
</li>
<li><p>cd到LocalBlog</p>
</li>
<li><p>初始化博客：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo hexo init</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动博客：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo s </span><br><span class="line"><span class="comment"># 打开本地博客：运行上述命令，给出一个本地端口链接，在浏览器中访问该端口</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>新建一篇一篇文章：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hexo n <span class="string">&quot;博客名称&quot;</span></span><br><span class="line"><span class="comment"># 文章放置在“LocalBlog/source/_posts/”路径下</span></span><br><span class="line"><span class="comment"># 修改路径下的markdown文件即可</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者直接在该路径下创建md文件</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>重新生成博客：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd到LocalBlog根目录下</span></span><br><span class="line">hexo clean <span class="comment"># 清空之前的博客</span></span><br><span class="line">hexo g <span class="comment"># 生成博客</span></span><br><span class="line">hexo s <span class="comment"># 重新启动博客</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="将博客部署到远程仓库"><a href="#将博客部署到远程仓库" class="headerlink" title="将博客部署到远程仓库"></a>将博客部署到远程仓库</h3><ul>
<li><p><strong>推送到github的远程仓库：</strong></p>
<ul>
<li><p>new repository</p>
</li>
<li><p>仓库名字必须与github昵称一致：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SunnyNO231.github.io</span><br><span class="line"><span class="comment"># 在浏览器输入这个地址，即可访问远程博客</span></span><br><span class="line"><span class="comment"># 得到仓库地址***</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>在LocalBlog目录下，安装git</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cnpm install --save hexo-deployer-git</span><br><span class="line">cnpm install hexo-deployer-git --save <span class="comment"># 不知为什么，以这种方式不会报错，上一句代码有时会出错</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>编辑_config.yml文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将Deployment进行配置</span></span><br><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="built_in">type</span>: git</span><br><span class="line">repo:***(远程仓库地址)</span><br><span class="line">branch: master</span><br></pre></td></tr></table></figure>
</li>
<li><p>部署到远端仓库：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br><span class="line"><span class="comment"># 输入github的账号和密码即可</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>使用仓库名在浏览器访问远程博客即可</p>
</li>
</ul>
</li>
<li><p><strong>推送到gitee的远程仓库</strong></p>
<ul>
<li>新建仓库</li>
<li>仓库名字必须与gitee昵称一致<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sunNO123.gitee.io</span><br></pre></td></tr></table></figure></li>
<li>启动gitee的https服务：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># “服务” &gt; Gitee Pages &gt; 勾选“强制使用HTTPS” &gt; 点击“启动”即可。</span></span><br><span class="line"><span class="comment"># 点击启动后，会给定用于访问远程仓库的网址</span></span><br></pre></td></tr></table></figure></li>
<li>对应修改_config.yml文件：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Deployment</span></span><br><span class="line"><span class="built_in">type</span>: git</span><br><span class="line">repo:***(gitee远程仓库地址)</span><br><span class="line">branch: master</span><br></pre></td></tr></table></figure>
<h3 id="修改博客主题"><a href="#修改博客主题" class="headerlink" title="修改博客主题"></a>修改博客主题</h3></li>
</ul>
</li>
<li><p>找到主题地址：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">github.com/litten/hexo-theme-yila.git</span><br></pre></td></tr></table></figure></li>
<li><p>将上述主题克隆到“themes/”路径下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> github.com/litten/hexo-theme-yila.git themes/yilia</span><br></pre></td></tr></table></figure></li>
<li><p>将主题配置到博客中：</p>
<ul>
<li>修改_config.yml文件：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">theme: yilia <span class="comment"># 将主题名字更换为“yilia”即可</span></span><br></pre></td></tr></table></figure></li>
<li>重新生成并启动博客：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo -clean</span><br><span class="line">hexo **g**</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/hexo_blog%20follow%20CodeSheep/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Paper/Where and Who Automatic Semantic-Aware Person Composition - 副本" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Where-and-Who-Automatic-Semantic-Aware-Person-Composition"><a href="#Where-and-Who-Automatic-Semantic-Aware-Person-Composition" class="headerlink" title="Where and Who? Automatic Semantic-Aware Person Composition"></a>Where and Who? Automatic Semantic-Aware Person Composition</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><ul>
<li><h4 id="图像组合-image-composite，不是合成sythetic-步骤"><a href="#图像组合-image-composite，不是合成sythetic-步骤" class="headerlink" title="图像组合(image composite，不是合成sythetic)步骤"></a><font color=red>图像组合(image composite，不是合成sythetic)</font>步骤</h4><ul>
<li><h4 id="选择与给定背景兼容的前景"><a href="#选择与给定背景兼容的前景" class="headerlink" title="选择与给定背景兼容的前景"></a>选择与给定背景兼容的前景</h4></li>
<li><h4 id="在合适的位置、大小放置实例"><a href="#在合适的位置、大小放置实例" class="headerlink" title="在合适的位置、大小放置实例"></a>在合适的位置、大小放置实例</h4></li>
<li><h4 id="使用泊松混合等方法进行局部细化"><a href="#使用泊松混合等方法进行局部细化" class="headerlink" title="使用泊松混合等方法进行局部细化"></a>使用泊松混合等方法进行局部细化</h4></li>
<li><h4 id="全局细化"><a href="#全局细化" class="headerlink" title="全局细化"></a>全局细化</h4></li>
</ul>
</li>
<li><h4 id="问题：现有的自动处理系统只处理后两个步骤，没有考虑前两个（本文提出一个完整的图像组合自动处理系统）"><a href="#问题：现有的自动处理系统只处理后两个步骤，没有考虑前两个（本文提出一个完整的图像组合自动处理系统）" class="headerlink" title="问题：现有的自动处理系统只处理后两个步骤，没有考虑前两个（本文提出一个完整的图像组合自动处理系统）"></a>问题：现有的自动处理系统只处理后两个步骤，没有考虑前两个（本文提出一个完整的图像组合自动处理系统）</h4></li>
<li><h4 id="本文思想："><a href="#本文思想：" class="headerlink" title="本文思想："></a>本文思想：</h4><ul>
<li><h4 id="概述："><a href="#概述：" class="headerlink" title="概述："></a>概述：</h4><ul>
<li><h4 id="目的：探索前景与背景的语义关系"><a href="#目的：探索前景与背景的语义关系" class="headerlink" title="目的：探索前景与背景的语义关系"></a>目的：探索前景与背景的语义关系</h4></li>
<li><h4 id="前景（实例类型）只考虑人类（方便训练、人在图像组合中的重要性）"><a href="#前景（实例类型）只考虑人类（方便训练、人在图像组合中的重要性）" class="headerlink" title="前景（实例类型）只考虑人类（方便训练、人在图像组合中的重要性）"></a>前景（实例类型）只考虑人类（方便训练、人在图像组合中的重要性）</h4></li>
<li><h4 id="简单起见，不考虑遮挡的情况"><a href="#简单起见，不考虑遮挡的情况" class="headerlink" title="简单起见，不考虑遮挡的情况"></a>简单起见，不考虑遮挡的情况</h4></li>
</ul>
</li>
<li><h4 id="模型组成（重点）："><a href="#模型组成（重点）：" class="headerlink" title="模型组成（重点）："></a>模型组成（<font color=red>重点</font>）：</h4><ul>
<li><h4 id="首先，用设计好的CNN预测实例（人）的位置"><a href="#首先，用设计好的CNN预测实例（人）的位置" class="headerlink" title="首先，用设计好的CNN预测实例（人）的位置"></a>首先，用设计好的CNN预测实例（人）的位置</h4></li>
<li><h4 id="然后，在数据集中检索与给定背景在全局、局部兼容较好的实例"><a href="#然后，在数据集中检索与给定背景在全局、局部兼容较好的实例" class="headerlink" title="然后，在数据集中检索与给定背景在全局、局部兼容较好的实例"></a>然后，在数据集中检索与给定背景在全局、局部兼容较好的实例</h4></li>
<li><h4 id="利用MATTING等方法，调整实例与周围背景的兼容性，实现更好的过渡"><a href="#利用MATTING等方法，调整实例与周围背景的兼容性，实现更好的过渡" class="headerlink" title="利用MATTING等方法，调整实例与周围背景的兼容性，实现更好的过渡"></a>利用MATTING等方法，调整实例与周围背景的兼容性，实现更好的过渡</h4></li>
</ul>
</li>
<li><h4 id="定性与定量评估即用户研究"><a href="#定性与定量评估即用户研究" class="headerlink" title="定性与定量评估即用户研究"></a>定性与定量评估即用户研究</h4></li>
<li><h4 id="贡献总结："><a href="#贡献总结：" class="headerlink" title="贡献总结："></a>贡献总结：</h4><ul>
<li><h4 id="用上下文线索，对任意给定的背景预测一个合理的位置"><a href="#用上下文线索，对任意给定的背景预测一个合理的位置" class="headerlink" title="用上下文线索，对任意给定的背景预测一个合理的位置"></a>用上下文线索，对任意给定的背景预测一个合理的位置</h4></li>
<li><h4 id="提出一个完整的全自动图像组成系统"><a href="#提出一个完整的全自动图像组成系统" class="headerlink" title="提出一个完整的全自动图像组成系统"></a>提出一个完整的全自动图像组成系统</h4></li>
<li><h4 id="提出一个定量、定性评估用户研究"><a href="#提出一个定量、定性评估用户研究" class="headerlink" title="提出一个定量、定性评估用户研究"></a>提出一个定量、定性评估用户研究</h4></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><ul>
<li><h4 id="代写"><a href="#代写" class="headerlink" title="代写"></a>代写</h4></li>
</ul>
<h2 id="BBOX预测："><a href="#BBOX预测：" class="headerlink" title="BBOX预测："></a>BBOX预测：</h2><ul>
<li><h4 id="数据预处理：过滤掉存在遮挡、截断、较小的实例"><a href="#数据预处理：过滤掉存在遮挡、截断、较小的实例" class="headerlink" title="数据预处理：过滤掉存在遮挡、截断、较小的实例"></a>数据预处理：过滤掉存在遮挡、截断、较小的实例</h4></li>
<li><h4 id="输入图像：IB、IL"><a href="#输入图像：IB、IL" class="headerlink" title="输入图像：IB、IL"></a>输入图像：I<del>B</del>、I<del>L</del></h4><ul>
<li><h4 id="目的：需要用学习BBOX与背景上下文的映射关系"><a href="#目的：需要用学习BBOX与背景上下文的映射关系" class="headerlink" title="目的：需要用学习BBOX与背景上下文的映射关系"></a>目的：需要用学习BBOX与背景上下文的映射关系</h4></li>
<li><h4 id="为了以上目的，需要将输入图像中的实例擦除掉（只保留实例的BBOX用于监督学习）"><a href="#为了以上目的，需要将输入图像中的实例擦除掉（只保留实例的BBOX用于监督学习）" class="headerlink" title="为了以上目的，需要将输入图像中的实例擦除掉（只保留实例的BBOX用于监督学习）"></a>为了以上目的，需要将输入图像中的实例擦除掉（<font color=red>只保留实例的BBOX用于监督学习</font>）</h4><blockquote>
<ul>
<li><h4 id="利用PS的内容感知方法将实例抹除掉"><a href="#利用PS的内容感知方法将实例抹除掉" class="headerlink" title="利用PS的内容感知方法将实例抹除掉"></a>利用PS的内容感知方法将实例抹除掉</h4></li>
<li><h4 id="在用高斯模糊等方法进行边界处理，该图称为IB"><a href="#在用高斯模糊等方法进行边界处理，该图称为IB" class="headerlink" title="在用高斯模糊等方法进行边界处理，该图称为IB "></a>在用高斯模糊等方法进行边界处理，该图称为<font color=red>I<del>B</del> </font></h4></li>
</ul>
</blockquote>
</li>
<li><h4 id="用FASTER-RCNN检测不同类实例的BBOX，并将不同类的BBOX用不同颜色覆盖，其他区域用另外的颜色覆盖，称这张图为IL-表示图像的实例布局"><a href="#用FASTER-RCNN检测不同类实例的BBOX，并将不同类的BBOX用不同颜色覆盖，其他区域用另外的颜色覆盖，称这张图为IL-表示图像的实例布局" class="headerlink" title="用FASTER RCNN检测不同类实例的BBOX，并将不同类的BBOX用不同颜色覆盖，其他区域用另外的颜色覆盖，称这张图为IL ,表示图像的实例布局"></a>用FASTER RCNN检测不同类实例的BBOX，并将不同类的BBOX用不同颜色覆盖，其他区域用另外的颜色覆盖，称这张图为<font color=red>I<del>L</del> </font>,表示图像的实例布局</h4></li>
</ul>
</li>
<li><h4 id="预测目标实例："><a href="#预测目标实例：" class="headerlink" title="预测目标实例："></a>预测目标实例：</h4><ul>
<li><h4 id="目标：预测出实例（人）的bbox"><a href="#目标：预测出实例（人）的bbox" class="headerlink" title="目标：预测出实例（人）的bbox"></a>目标：预测出实例（人）的bbox</h4></li>
<li><h4 id="首先将矩形图像填充为正方形图像"><a href="#首先将矩形图像填充为正方形图像" class="headerlink" title="首先将矩形图像填充为正方形图像"></a>首先将矩形图像填充为正方形图像</h4><p>![](C:\Users\12466\Pictures\Saved Pictures\where&amp;who3.1.JPG)</p>
</li>
<li><h4 id="考虑到填充之后，BBOX的坐标会发生变化，调整BBOX坐标（这里的BBOX就是擦除掉的实例的BBOX）"><a href="#考虑到填充之后，BBOX的坐标会发生变化，调整BBOX坐标（这里的BBOX就是擦除掉的实例的BBOX）" class="headerlink" title="考虑到填充之后，BBOX的坐标会发生变化，调整BBOX坐标（这里的BBOX就是擦除掉的实例的BBOX）"></a>考虑到填充之后，BBOX的坐标会发生变化，调整BBOX坐标（<font color=red>这里的BBOX就是擦除掉的实例的BBOX</font>）</h4></li>
<li><h4 id="为了对不同分辨率的图像进行一致性的预测，对BBOX进行归一化"><a href="#为了对不同分辨率的图像进行一致性的预测，对BBOX进行归一化" class="headerlink" title="为了对不同分辨率的图像进行一致性的预测，对BBOX进行归一化"></a>为了对不同分辨率的图像进行一致性的预测，对BBOX进行归一化</h4><p>![](C:\Users\12466\Pictures\Saved Pictures\where&amp;who3.2.JPG)</p>
<blockquote>
<ul>
<li><h5 id="其中，Xstand，Ystand表示归一化后的坐标，是BBOX的最底边中心点"><a href="#其中，Xstand，Ystand表示归一化后的坐标，是BBOX的最底边中心点" class="headerlink" title="其中，Xstand，Ystand表示归一化后的坐标，是BBOX的最底边中心点"></a>其中，X<del>stand</del>，Y<del>stand</del>表示归一化后的坐标，是<font color=red>BBOX的最底边中心点</font></h5></li>
<li><h5 id="S表示正方形图像的宽度"><a href="#S表示正方形图像的宽度" class="headerlink" title="S表示正方形图像的宽度"></a>S表示正方形图像的宽度</h5></li>
<li><h5 id="此外还有归一化的bbox宽高坐标Wstand，Hstand："><a href="#此外还有归一化的bbox宽高坐标Wstand，Hstand：" class="headerlink" title="此外还有归一化的bbox宽高坐标Wstand，Hstand："></a>此外还有归一化的bbox宽高坐标W<del>stand</del>，H<del>stand</del>：</h5><h5 id="Wstand-（Xmax-Xmin-）-S"><a href="#Wstand-（Xmax-Xmin-）-S" class="headerlink" title="Wstand = （Xmax - Xmin  ）/ S"></a>W<del>stand</del> = （X<del>max</del> - X<del>min</del>  ）/ S</h5></li>
</ul>
</blockquote>
</li>
<li><h4 id="由于在四维空间中回归这4个坐标（Xstand，Ystand，Wstand，Hstand）比较难，因此将（Xstand，Ystand），（Wstand，Hstand）分别坐标离散到两个15-15的栅格中，称为gxy，gwh"><a href="#由于在四维空间中回归这4个坐标（Xstand，Ystand，Wstand，Hstand）比较难，因此将（Xstand，Ystand），（Wstand，Hstand）分别坐标离散到两个15-15的栅格中，称为gxy，gwh" class="headerlink" title="由于在四维空间中回归这4个坐标（Xstand，Ystand，Wstand，Hstand）比较难，因此将（Xstand，Ystand），（Wstand，Hstand）分别坐标离散到两个15*15的栅格中，称为gxy，gwh"></a>由于在四维空间中回归这4个坐标（X<del>stand</del>，Y<del>stand</del>，W<del>stand</del>，H<del>stand</del>）比较难，因此将（X<del>stand</del>，Y<del>stand</del>），（W<del>stand</del>，H<del>stand</del>）分别坐标离散到两个15*15的栅格中，称为g<del>xy</del>，g<del>wh</del></h4><blockquote>
<ul>
<li><h5 id="如：0-lt-Xstand，Ystand-lt-1-15时（Xstand，Ystand，Wstand，Hstand的取值范围都在-0-1-内），则对应的gxy如下所示（gwh同理）："><a href="#如：0-lt-Xstand，Ystand-lt-1-15时（Xstand，Ystand，Wstand，Hstand的取值范围都在-0-1-内），则对应的gxy如下所示（gwh同理）：" class="headerlink" title="如：0 &lt; Xstand，Ystand &lt; 1/15时（Xstand，Ystand，Wstand，Hstand的取值范围都在[0,1]内），则对应的gxy如下所示（gwh同理）："></a>如：0 &lt; X<del>stand</del>，Y<del>stand</del> &lt; 1/15时（X<del>stand</del>，Y<del>stand</del>，W<del>stand</del>，H<del>stand</del>的取值范围都在[0,1]内），则对应的g<del>xy</del>如下所示（g<del>wh</del>同理）：</h5></li>
</ul>
</blockquote>
<p>![](C:\Users\12466\Pictures\Saved Pictures\where&amp;who3.3.JPG)</p>
<blockquote>
<ul>
<li><h5 id="这样便把BBOX的预测转换成了两个分类问题（即xy分类，与wh分类）（每个分类共15-15个类别）"><a href="#这样便把BBOX的预测转换成了两个分类问题（即xy分类，与wh分类）（每个分类共15-15个类别）" class="headerlink" title="这样便把BBOX的预测转换成了两个分类问题（即xy分类，与wh分类）（每个分类共15*15个类别）"></a>这样便<font color=red>把BBOX的预测转换成了两个分类问题（即xy分类，与wh分类）</font>（每个分类共15*15个类别）</h5></li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
<ul>
<li><h4 id="用于预测BBOX的模型："><a href="#用于预测BBOX的模型：" class="headerlink" title="用于预测BBOX的模型："></a>用于预测BBOX的模型：</h4><ul>
<li><h4 id="模型的输入：图象IB-IL（沿着通道进行concat，比如480-480-6），以及学习目标gxy，gwh（即监督标签，两个15-15的矩阵）"><a href="#模型的输入：图象IB-IL（沿着通道进行concat，比如480-480-6），以及学习目标gxy，gwh（即监督标签，两个15-15的矩阵）" class="headerlink" title="模型的输入：图象IB+IL（沿着通道进行concat，比如480*480*6），以及学习目标gxy，gwh（即监督标签，两个15*15的矩阵）"></a>模型的输入：图象I<del>B</del>+I<del>L</del>（沿着通道进行concat，比如480*480*6），以及学习目标g<del>xy</del>，g<del>wh</del>（即监督标签，两个15*15的矩阵）</h4><blockquote>
<ul>
<li><h5 id="这里的输入IB-IL-即由擦除掉实例后的图像合并得到的；gxy，gwh-则是由擦除实例对应的BBOX计算得到的"><a href="#这里的输入IB-IL-即由擦除掉实例后的图像合并得到的；gxy，gwh-则是由擦除实例对应的BBOX计算得到的" class="headerlink" title="这里的输入IB+IL 即由擦除掉实例后的图像合并得到的；gxy，gwh 则是由擦除实例对应的BBOX计算得到的"></a>这里的输入I<del>B</del>+I<del>L</del> 即由<font color=red>擦除掉实例后的图像</font>合并得到的；g<del>xy</del>，g<del>wh</del> 则是由<font color=red>擦除实例对应的BBOX</font>计算得到的</h5></li>
</ul>
</blockquote>
</li>
<li><h4 id="模型结构：share-network-location-branch-size-branch（示意图及各模块的层组成如下：）"><a href="#模型结构：share-network-location-branch-size-branch（示意图及各模块的层组成如下：）" class="headerlink" title="模型结构：share network + location branch + size branch（示意图及各模块的层组成如下：）"></a>模型结构：share network + location branch + size branch（示意图及各模块的层组成如下：）</h4><p>![](C:\Users\12466\Pictures\Saved Pictures\where&amp;who3.4.png)</p>
</li>
</ul>
</li>
</ul>
<pre><code>![](C:\Users\12466\Pictures\Saved Pictures\where&amp;who3.5.png)

&gt; * ##### 其中的&lt;font color=red&gt;输入的图像又称背景图&lt;/font&gt;，用于在上面粘贴新的实例
&gt;
&gt; * ##### 其中&lt;font color=red&gt;location分支&lt;/font&gt;负责输出预测BBOX的位置信息（即G~xy~，也是一个15*15的矩阵 或 长度为255向量，对应g~xy~）；&lt;font color=red&gt;size分支&lt;/font&gt;输出预测BBOX的大小信息（即G~wh~，对应g~wh~）
&gt;
&gt; * ##### 由于size应该与局部上下文保持一致，比如人应该比汽车、房屋要小，因此在size分支的dilation输出的feature图上，&lt;font color=red&gt;将原先的（X~stand~，Y~stand~）映射到该feature图，得到位置（X~grid~，Y~grid~），并取3*3大小，称为激活切片（即ROI Slicing）&lt;/font&gt;，用于之后的size网络输入；而该&lt;font color=red&gt;feature的子map（即切片）用于捕获局部上下文&lt;/font&gt;</code></pre>
<ul>
<li><h4 id="本设计的微妙处："><a href="#本设计的微妙处：" class="headerlink" title="本设计的微妙处："></a>本设计的微妙处：</h4><blockquote>
<ul>
<li><h5 id="训练时，用于ROI切片映射的Xstand，Ystand是由已知的BBOX计算得出；而测试时，Xstand，Ystand需要location分支给出，因此测试时，先执行location分支，然后是size分支"><a href="#训练时，用于ROI切片映射的Xstand，Ystand是由已知的BBOX计算得出；而测试时，Xstand，Ystand需要location分支给出，因此测试时，先执行location分支，然后是size分支" class="headerlink" title="训练时，用于ROI切片映射的Xstand，Ystand是由已知的BBOX计算得出；而测试时，Xstand，Ystand需要location分支给出，因此测试时，先执行location分支，然后是size分支"></a>训练时，用于ROI切片映射的X<del>stand</del>，Y<del>stand</del>是由已知的BBOX计算得出；而测试时，X<del>stand</del>，Y<del>stand</del>需要location分支给出，因此<font color=red>测试时，先执行location分支，然后是size分支</font></h5></li>
</ul>
</blockquote>
</li>
</ul>
<h2 id="实例检测与组合"><a href="#实例检测与组合" class="headerlink" title="实例检测与组合"></a>实例检测与组合</h2><ul>
<li><h4 id="概述：-1"><a href="#概述：-1" class="headerlink" title="概述："></a>概述：</h4><ul>
<li><h4 id="基于混合深度特征表示的实例检索与组合"><a href="#基于混合深度特征表示的实例检索与组合" class="headerlink" title="基于混合深度特征表示的实例检索与组合"></a>基于混合深度特征表示的实例检索与组合</h4><blockquote>
<h5 id="“混合深度特征表示”-：卷积后的特征图，用于表示图像的语义信息，利用改图检索"><a href="#“混合深度特征表示”-：卷积后的特征图，用于表示图像的语义信息，利用改图检索" class="headerlink" title="“混合深度特征表示” ：卷积后的特征图，用于表示图像的语义信息，利用改图检索"></a>“混合深度特征表示” ：卷积后的特征图，用于表示图像的语义信息，利用改图检索</h5></blockquote>
</li>
<li><h4 id="顺序："><a href="#顺序：" class="headerlink" title="顺序："></a>顺序：</h4><blockquote>
<ul>
<li><h5 id="创建候选实例池"><a href="#创建候选实例池" class="headerlink" title="创建候选实例池"></a><font color=red>创建候选实例池</font></h5></li>
<li><h5 id="从池中检索"><a href="#从池中检索" class="headerlink" title="从池中检索"></a><font color=red>从池中检索</font></h5></li>
<li><h5 id="组合"><a href="#组合" class="headerlink" title="组合"></a>组合</h5></li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><h4 id="候选池创建"><a href="#候选池创建" class="headerlink" title="候选池创建"></a>候选池创建</h4><ul>
<li><h4 id="过滤掉遮挡、截断、尺度较小的实例，剩余4100个实例"><a href="#过滤掉遮挡、截断、尺度较小的实例，剩余4100个实例" class="headerlink" title="过滤掉遮挡、截断、尺度较小的实例，剩余4100个实例"></a>过滤掉遮挡、截断、尺度较小的实例，剩余4100个实例</h4></li>
<li><h4 id="由于原先数据集中自带的分割不够精细，再用PS精准分割实例"><a href="#由于原先数据集中自带的分割不够精细，再用PS精准分割实例" class="headerlink" title="由于原先数据集中自带的分割不够精细，再用PS精准分割实例"></a>由于原先数据集中自带的分割不够精细，再用PS精准分割实例</h4></li>
<li><h4 id="为了证明一般性，背景图（即输入的IB-IL）来自于YFCC-100M，Visual-Genome-Dataset，SUN等数据集"><a href="#为了证明一般性，背景图（即输入的IB-IL）来自于YFCC-100M，Visual-Genome-Dataset，SUN等数据集" class="headerlink" title="为了证明一般性，背景图（即输入的IB+IL）来自于YFCC 100M，Visual Genome Dataset，SUN等数据集"></a>为了证明一般性，背景图（即输入的I<del>B</del>+I<del>L</del>）来自于YFCC 100M，Visual Genome Dataset，SUN等数据集</h4></li>
</ul>
</li>
<li><h4 id="基于上下文进行实例搜索"><a href="#基于上下文进行实例搜索" class="headerlink" title="基于上下文进行实例搜索"></a>基于上下文进行实例搜索</h4><ul>
<li><h4 id="使用ResNet-50的中间层作为特征表示，用于语义搜索（即使低层网络不是在相关分类中进行的与训练，也可以用于语义搜索）"><a href="#使用ResNet-50的中间层作为特征表示，用于语义搜索（即使低层网络不是在相关分类中进行的与训练，也可以用于语义搜索）" class="headerlink" title="使用ResNet 50的中间层作为特征表示，用于语义搜索（即使低层网络不是在相关分类中进行的与训练，也可以用于语义搜索）"></a>使用<font color=red>ResNet 50的中间层作为特征表示，用于语义搜索</font>（即使低层网络不是在相关分类中进行的与训练，也可以用于语义搜索）</h4></li>
<li><h4 id="已存在的方法，只是用语义搜索找寻与给定图像语义相似的图像，而本文的方法用语义搜索找寻符合给定背景上下文语义的实例"><a href="#已存在的方法，只是用语义搜索找寻与给定图像语义相似的图像，而本文的方法用语义搜索找寻符合给定背景上下文语义的实例" class="headerlink" title="已存在的方法，只是用语义搜索找寻与给定图像语义相似的图像，而本文的方法用语义搜索找寻符合给定背景上下文语义的实例"></a>已存在的方法，只是用语义搜索找寻与给定图像语义相似的图像，而本文的方法<font color=red>用语义搜索找寻符合给定背景上下文语义的实例</font></h4><blockquote>
<ul>
<li><h5 id="利用实例对应的原图像（实例属于候选实例池）与给定背景图像，比较两者的全局语义（整图的特征图）、局部语义（局部区域的特征图）"><a href="#利用实例对应的原图像（实例属于候选实例池）与给定背景图像，比较两者的全局语义（整图的特征图）、局部语义（局部区域的特征图）" class="headerlink" title="利用实例对应的原图像（实例属于候选实例池）与给定背景图像，比较两者的全局语义（整图的特征图）、局部语义（局部区域的特征图）"></a>利用实例对应的原图像（实例属于候选实例池）与给定背景图像，比较两者的<font color=red>全局语义（整图的特征图）、局部语义（局部区域的特征图）</font></h5></li>
<li><h5 id="关于全局语义：将背景图像的特征图与实例原图像的特征图进行比较，找寻全局语义兼容性好的实例"><a href="#关于全局语义：将背景图像的特征图与实例原图像的特征图进行比较，找寻全局语义兼容性好的实例" class="headerlink" title="关于全局语义：将背景图像的特征图与实例原图像的特征图进行比较，找寻全局语义兼容性好的实例"></a>关于全局语义：将背景图像的特征图与实例原图像的特征图进行比较，<font color=red>找寻全局语义兼容性好的实例</font></h5></li>
<li><h5 id="关于局部区域的语义：将背景图中预测的BBOX（位置预测模块给出的）周围的2倍区域作为切片，用于局部区域的语义计算；同理，实例（候选池中的实例）对应的BBOX周围的2倍邻域作为切片，作为实例的局部区域语义计算；比较这两个局部区域的语义，找寻局部语义兼容性好的实例"><a href="#关于局部区域的语义：将背景图中预测的BBOX（位置预测模块给出的）周围的2倍区域作为切片，用于局部区域的语义计算；同理，实例（候选池中的实例）对应的BBOX周围的2倍邻域作为切片，作为实例的局部区域语义计算；比较这两个局部区域的语义，找寻局部语义兼容性好的实例" class="headerlink" title="关于局部区域的语义：将背景图中预测的BBOX（位置预测模块给出的）周围的2倍区域作为切片，用于局部区域的语义计算；同理，实例（候选池中的实例）对应的BBOX周围的2倍邻域作为切片，作为实例的局部区域语义计算；比较这两个局部区域的语义，找寻局部语义兼容性好的实例"></a>关于局部区域的语义：将<font color=red>背景图中预测的BBOX（位置预测模块给出的）</font>周围的2倍区域作为切片，用于局部区域的语义计算；同理，实例（候选池中的实例）对应的BBOX周围的2倍邻域作为切片，作为实例的局部区域语义计算；<font color=red>比较这两个局部区域的语义，找寻局部语义兼容性好的实例</font></h5></li>
</ul>
</blockquote>
</li>
<li><h4 id="检索步骤："><a href="#检索步骤：" class="headerlink" title="检索步骤："></a>检索步骤：</h4><blockquote>
<ul>
<li><h5 id="去掉预测BBOX与实例BBOX-IOU值小于0-3的实例"><a href="#去掉预测BBOX与实例BBOX-IOU值小于0-3的实例" class="headerlink" title="去掉预测BBOX与实例BBOX    IOU值小于0.3的实例"></a>去掉预测BBOX与实例BBOX    IOU值小于0.3的实例</h5></li>
<li><h5 id="用cos距离计算特征图间距离，搜索距离最小的实例"><a href="#用cos距离计算特征图间距离，搜索距离最小的实例" class="headerlink" title="用cos距离计算特征图间距离，搜索距离最小的实例"></a>用cos距离计算特征图间距离，搜索距离最小的实例</h5></li>
<li><h5 id="用KD-TREE结构加速检索"><a href="#用KD-TREE结构加速检索" class="headerlink" title="用KD-TREE结构加速检索"></a>用KD-TREE结构加速检索</h5></li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><h4 id="组合-1"><a href="#组合-1" class="headerlink" title="组合"></a>组合</h4></li>
</ul>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><ul>
<li><h4 id="定性评估"><a href="#定性评估" class="headerlink" title="定性评估"></a>定性评估</h4><ul>
<li><h4 id="统计ground-truth中BBOX的gxy分布、gwh分布；与预测BBOX的Gxy分布、Gwh分布，并计算两类分布的距离D-gxy，Gxy-，D-gwh，Gwh"><a href="#统计ground-truth中BBOX的gxy分布、gwh分布；与预测BBOX的Gxy分布、Gwh分布，并计算两类分布的距离D-gxy，Gxy-，D-gwh，Gwh" class="headerlink" title="统计ground truth中BBOX的gxy分布、gwh分布；与预测BBOX的Gxy分布、Gwh分布，并计算两类分布的距离D(gxy，Gxy)，D(gwh，Gwh)"></a>统计ground truth中BBOX的g<del>xy</del>分布、g<del>wh</del>分布；与预测BBOX的G<del>x</del>y分布、G<del>wh</del>分布，并计算两类分布的距离D(g<del>xy</del>，G<del>xy</del>)，D(g<del>wh</del>，G<del>wh</del>)</h4></li>
</ul>
</li>
<li><h4 id="用户研究与定量评估"><a href="#用户研究与定量评估" class="headerlink" title="用户研究与定量评估"></a>用户研究与定量评估</h4></li>
</ul>
<h2 id="原型用户界面"><a href="#原型用户界面" class="headerlink" title="原型用户界面"></a>原型用户界面</h2>
      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/Paper/Where%20and%20Who%20Automatic%20Semantic-Aware%20Person%20Composition%20-%20%E5%89%AF%E6%9C%AC/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Paper/UPSNet A Unified Panoptic Segmentation Network" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="UPSNet-A-Unified-Panoptic-Segmentation-Network"><a href="#UPSNet-A-Unified-Panoptic-Segmentation-Network" class="headerlink" title="UPSNet: A Unified Panoptic Segmentation Network"></a>UPSNet: A Unified Panoptic Segmentation Network</h1><h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><ul>
<li><h4 id="全景分割"><a href="#全景分割" class="headerlink" title="全景分割"></a>全景分割</h4></li>
<li><h4 id="全景分割、语义分割与实例分割-："><a href="#全景分割、语义分割与实例分割-：" class="headerlink" title="全景分割、语义分割与实例分割 ："></a>全景分割、语义分割与实例分割 ：</h4><ul>
<li><h4 id="语义分割：更关注无形状的背景（如天空、草地）；只对不同类别物体进行分割，对同类物体的不同实例不再分割"><a href="#语义分割：更关注无形状的背景（如天空、草地）；只对不同类别物体进行分割，对同类物体的不同实例不再分割" class="headerlink" title="语义分割：更关注无形状的背景（如天空、草地）；只对不同类别物体进行分割，对同类物体的不同实例不再分割"></a>语义分割：更关注无形状的背景（如天空、草地）；只对不同类别物体进行分割，对同类物体的不同实例不再分割</h4></li>
<li><h4 id="实力分割：更关注实例；对不同实例进行分割，不再对背景进行分割"><a href="#实力分割：更关注实例；对不同实例进行分割，不再对背景进行分割" class="headerlink" title="实力分割：更关注实例；对不同实例进行分割，不再对背景进行分割"></a>实力分割：更关注实例；对不同实例进行分割，不再对背景进行分割</h4></li>
<li><h4 id="区别联系：两者都是在像素层面上对场景的理解；但在建模上存在较大不同；如：前者常用到全卷积神经网络进行建模，后者常用到基于提议的检测器进行建模"><a href="#区别联系：两者都是在像素层面上对场景的理解；但在建模上存在较大不同；如：前者常用到全卷积神经网络进行建模，后者常用到基于提议的检测器进行建模" class="headerlink" title="区别联系：两者都是在像素层面上对场景的理解；但在建模上存在较大不同；如：前者常用到全卷积神经网络进行建模，后者常用到基于提议的检测器进行建模"></a>区别联系：两者都是在像素层面上对场景的理解；但在建模上存在较大不同；如：前者常用到全卷积神经网络进行建模，后者常用到基于提议的检测器进行建模</h4></li>
<li><h4 id="全景分割：即为语义分割与实力分割的统一；其中的实例在此称之为things（事物、东西），背景称之为stuff（填充物）"><a href="#全景分割：即为语义分割与实力分割的统一；其中的实例在此称之为things（事物、东西），背景称之为stuff（填充物）" class="headerlink" title="全景分割：即为语义分割与实力分割的统一；其中的实例在此称之为things（事物、东西），背景称之为stuff（填充物）"></a>全景分割：即为语义分割与实力分割的统一；其中的实例在此称之为things（事物、东西），背景称之为stuff（填充物）</h4></li>
</ul>
</li>
</ul>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><ul>
<li><h4 id="与之前的全景分割区别：之前的都是将语义分割与实力分割相隔离，并在模型上没有统一，而本文的模型实现了两者的统一"><a href="#与之前的全景分割区别：之前的都是将语义分割与实力分割相隔离，并在模型上没有统一，而本文的模型实现了两者的统一" class="headerlink" title="与之前的全景分割区别：之前的都是将语义分割与实力分割相隔离，并在模型上没有统一，而本文的模型实现了两者的统一"></a>与之前的全景分割区别：之前的都是将语义分割与实力分割相隔离，并在模型上没有统一，而本文的模型实现了两者的统一</h4></li>
<li><h4 id="组成："><a href="#组成：" class="headerlink" title="组成："></a>组成：</h4><ul>
<li><h4 id="基于可变形卷积的语义分割头；"><a href="#基于可变形卷积的语义分割头；" class="headerlink" title="基于可变形卷积的语义分割头；"></a>基于可变形卷积的语义分割头；</h4></li>
<li><h4 id="基于MASK-RCNN的实力分割头；"><a href="#基于MASK-RCNN的实力分割头；" class="headerlink" title="基于MASK RCNN的实力分割头；"></a>基于MASK RCNN的实力分割头；</h4></li>
<li><h4 id="通过逐像素分类的无参全景分割头"><a href="#通过逐像素分类的无参全景分割头" class="headerlink" title="通过逐像素分类的无参全景分割头"></a>通过逐像素分类的无参全景分割头</h4><ul>
<li><h4 id="全景分割头利用前两个分割头提供的日志，对未知类进行预测，解决了前面实例分割与语义分割的冲突"><a href="#全景分割头利用前两个分割头提供的日志，对未知类进行预测，解决了前面实例分割与语义分割的冲突" class="headerlink" title="全景分割头利用前两个分割头提供的日志，对未知类进行预测，解决了前面实例分割与语义分割的冲突"></a>全景分割头利用前两个分割头提供的日志，对未知类进行预测，解决了前面实例分割与语义分割的冲突</h4></li>
<li><h4 id="解决了不同数量实例带来的挑战，允许端到端的模型训练"><a href="#解决了不同数量实例带来的挑战，允许端到端的模型训练" class="headerlink" title="解决了不同数量实例带来的挑战，允许端到端的模型训练"></a>解决了不同数量实例带来的挑战，允许端到端的模型训练</h4><p>![](C:\Users\12466\Pictures\Saved Pictures\UPSNET模型.JPG)</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/Paper/UPSNet%20A%20Unified%20Panoptic%20Segmentation%20Network/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Paper/Understanding and Enhancing Mixed Sample Data Augmentation" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Understanding-and-Enhancing-Mixed-Sample-Data-Augmentation"><a href="#Understanding-and-Enhancing-Mixed-Sample-Data-Augmentation" class="headerlink" title="Understanding and Enhancing Mixed Sample Data Augmentation"></a>Understanding and Enhancing Mixed Sample Data Augmentation</h2><h3 id="2020-02-07"><a href="#2020-02-07" class="headerlink" title="2020-02-07"></a>2020-02-07</h3><hr>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><pre><code>     近年来，混合样本数据增强（MSDA）受到越来越多的关注，其中包括许多成功的变体，例如MixUp和Cut-Mix。 在特别了解了CutMix的功效之后，我们提出了FMix，它是一种MSDA，它使用将阈值应用于从傅立叶空间采样的低频图像而获得的二进制掩码。 FMix相对于MixUp和CutMix而言，针对一系列数据集和问题集的许多最新模型提高了性能。 我们继续**~~从信息理论的角度对MixUp，CutMix和FMix进行分析~~**，从深度上逐步压缩输入的角度对学习的模型进行特征描述。最终，我们的分析使我们能够解开扩增的两个互补属性，并提出一个统一的框架 关于MSDA的推理。 有关所有实验的代码，请访问https://github.com/ecs-vlc/FMix。</code></pre>
<h3 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h3><p>​         最近，已经提出了多种方法来获得最新的混合样本数据增强（MSDA）方法，尤其是在分类任务中获得了最新的结果（Chawla等，2002; Zhang等，2017; Tokozume等， 2017年; 2018年;井上，2018年; Yun等人，2019年;高桥等人，2019年; Summers和Dinneen，2019年）。 MSDA涉及根据某种策略组合数据样本，以创建可在其上训练模型的anaugmented数据集（在某种意义上，纯粹是因为它具有大量示例）。 迄今为止，对MSDA方法的性能的解释未能达成共识，或者与Liang等人的情况相反，都提出了反对意见。 （2018），Zhang等人（2017）和He等人。 （2019），或从不够广泛的角度来论证特定MSDA的效果，不足以提供其他方法的见解。</p>
<p>​         传统上，增强是通过统计学习的框架将其视为“邻近风险最小化”（VRM）（Vapnik，1999; Chapelle et al。，2001）。 给定数据点附近的某种概念，VRM会在数据点本身之外还训练附近样品。 这是MixUp的原始动机（Zhang et al。，2017）;基于混合数据样本提供一种新的邻近概念。 仅基于VRM和统计学习进行分析有两个主要限制。 首先，尽管VRM为MSDA提供了有用的基础，但它无法体现出特定方法对训练模型的影响。其次，VRM并不能使我们对正确的邻域分布有很好的认识，尽管事实无疑是这样。 深度学习的信息瓶颈理论（Tishby＆Zaslavsky，2015）可能有助于抵消以前的局限性。 该理论使用概括为“后处理无法增加信息”的数据处理不平等性来刻画深度网络学习到的功能。 具体而言，Tishby＆Zaslavsky（2015）提出，深层网络会逐渐丢弃有关输入的信息，同时保留有关目标的信息。 信息理论观点也可能有助于改善对良好邻域分布的不满意概念。例如，人们可能会认为，**<del>最好的邻域概念是导致压缩最普遍的代表的概念</del>**。 或者，更好的邻近概念可能是通过VRM学习的功能捕获的信息与最小化经验风险（对原始数据进行训练）时获得的信息相同。 </p>
<p>​         我们期望信息理论分析将有助于解释MSDA方法（如MixUp（Zhanget等人，2017）和CutMix（Yun等人，2019））都能够提供良好的正则化，尽管存在明显的定性差异; MixUp在样本之间进行插值，而Cut-Mix使用二进制掩码将一个数据点的正方形区域插入另一个数据点。 我们认为，MixUp抑制了学习数据中示例特定特征的能力，从而导致了更多的<strong>压缩表示</strong>形式。 相反，我们假设CutMix使学习的模型保留对真实数据的良好了解，因为观察到的特征通常仅源自一个数据点。 同时，CutMix通过大幅增加可观察数据点的数量来限制模型的过拟合能力，这与VRM的初衷保持一致。 但是，通过限制仅遮罩正方形区域，CutMix施加了不必要的限制。 确实，应该有可能构造一个使用类似于CutMix的掩码的MSDA，同时显着增加数据空间。 </p>
<p>​         在本文的基础上，我们介绍了FMix，它是一种掩膜MSDA，它可以保留任意形状的掩膜，同时保留CutMix的所需属性。 针对一系列基准和其他MSDA方法，针对一系列模型和任务演示FMix的性能。 FMix在没有外部数据和Fashion MNIST（Xiao等人，2017）的情况下，在CIFAR-10（Krizhevsky等人，2009）上获得了最新的性能，并改善了几种最新模型的性能（ ResNet，DenseNet，WideResNet和PyramidNet）上的问题和方式。 随后，我们在信息论的视角下对MixUp，CutMix和FMix进行了分析，以提供关于它们如何产生改进的广义化性能的见解。 尤其是，我们引入了数量，该数量捕获了无监督模型学习从增强数据到从真实数据中编码相同信息的程度。 该分析使我们有理由提出一个统一的MSDA说明，即插值方法（如MixUp）与掩盖方法（如FMix）在学习模型上的作用以及最终如何更好地概括方面根本不同。 我们发现插值会导致早期压缩，使模型偏向更一般的特征，并且掩盖会保留数据中语义结构的分布，更适合拟合扩充的经典定义。 </p>
<p>​        </p>
<h3 id="二、相关工作：带有二进制掩码的MSDA"><a href="#二、相关工作：带有二进制掩码的MSDA" class="headerlink" title="二、相关工作：带有二进制掩码的MSDA"></a>二、相关工作：带有二进制掩码的MSDA</h3><p>​         在本节中，我们回顾了掩盖MSDA的基础知识，这些基础将成为我们动机的基础。 LetpX（x）表示输入数据分布。 通常，我们可以定义给定混合函数MSDA的混合值mix（X1，X2，Λ），其中X1和X2是数据域上的独立随机变量，Λ是混合系数。 </p>
<p>​         合成少数采样（Chawla等人，2002）是现代MSDA方法的前身，可以看作是上述情况的特例，其中X1和X2是依赖的，共同采样为特征空间中的最近邻居。 这些合成样本仅从少数族裔中提取，与原始数据结合使用，解决了数据不平衡的问题。 混合函数为线性插值，mix（x1，x2，λ）=λx1+（1-λ）x2，且pΛ= U（0,1）。 最近，Zhanget等人。 （2017），Tokozume等。 （2017），Tokozume等。 （2018）和Inoue（2018）同时建议在整个数据集上使用此公式（分别为MixUp，Class-Class（BC）学习，BC +和样本配对），尽管每种方法的混合系数分布选择不同。 我们将其称为插值MSDA。 （2017）我们可以通过对称的Beta分布获得足够的灵活性，即ispΛ= Beta（α，α）。 </p>
<p>​         最近的变体采用二进制掩码方法（Yun等人，2019; Summers＆Dinneen，2019; Takahashi等人，2019）.LetM = mask（Λ）是一个带有mask（λ）∈{0,1}nandμ的随机变量 （mask（λ））=λ，即生成的遮罩的平均值应等于混合系数：</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func1.PNG)</p>
<p>​         其中表示逐点乘法。 促使我们采用这种方法的一个明显变体是CutMix（Yunet al。，2019）。 该方法是专门针对二维数据mask（λ）∈{0,1} w×h设计的，它使用 ：</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func2.PNG)</p>
<p>其中randrect（rw，rh）∈{0,1} w×产生一个二进制蒙版，其阴影矩形区域的大小为rw×rhat，具有均匀的随机坐标。 在一系列实验中，CutMix改善了MixUp的性能。 </p>
<p>​         在所有MSDA方法中，目标都是某种形式的混合，通常反映出输入的混合。 对于分类，插值和掩蔽策略都根据上面的插值混合函数来混合目标。 这通常与交叉熵损失一起使用，以便编写MSDA分类目标：</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func3.PNG)</p>
<p>其中p（ˆY | mix（X1，X2，Λ））是模型学习的分布，而p（Y1 | X1）和p（Y2 | X2）分别是X1和X2的地面真实目标。 可以认为，通过不同地混合目标，可以获得比标准制剂更好的结果。 但是，现有技术有两个关键的发现，使我们怀疑这种假设。 首先，可以证明上述目标等同于使用其中一个数据点的原始目标，但具有不同的Λ分布。 具体来说，正如Husźar（2017）指出的那样，可以写出目标：</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func4.PNG)</p>
<p> 其中p ^ * = Beta（α+ 1，α）。 请注意，Beta（α+ 1，α）偏向高值，仅在极限α→∞内保持平衡。 为了清楚起见，我们在附录A.1节中复制了Husźar（2017）的推导。 我们还演示了尽管这两个目标在期望中具有相同的值，但是在实践中它们并没有达到相同的结果，而重新制定的结果始终比标准目标差。 因此，我们在实验中使用标准物镜。 就是说，这种重组破坏了任何建议，因为我们将目标中的某些信息保持不变，因此我们会将其嵌入其中。 第二个观察结果来自Liang等人的实证研究。 （2018），进行了关于MixUp中标签混合比例重要性的大量实验。 一方面，他们得出结论，当目标与输入的比例不同时，可以将模型调整到欠拟合点。 然而，尽管得出了这一结论，即使在极端事件中，目标的随机混合也与输入无关，其结果仍显示出轻微的性能变化。 根据这些发现，建议MSDA最重要的元素是输入混合功能。 我们在附录A.2节中针对我们的观点提供了其他一些说明。 在本文的其余部分中，我们重点介绍更好的混合功能的输入和开发。</p>
<h3 id="三、FMIX：改进后的掩码"><a href="#三、FMIX：改进后的掩码" class="headerlink" title="三、FMIX：改进后的掩码"></a>三、FMIX：改进后的掩码</h3><p>​         为了形成我们的方法的动力，现在重要的是准确地了解为什么CutMix如此有效。 在我们的分析中，我们将当前的蒙版MSDA（例如CutMix）视为等效，因为它们都从根本上混合了矩形区域。 我们的争辩是，掩盖MSDA方法之所以有效，是因为它有效地保留了插值MSDA所不具备的数据分布，特别是在卷积神经网络（CNN）的感知空间中。 具体而言，每个卷积神经元通常一次仅编码来自一个输入的信息。 在空间上彼此靠近的元素通常从同一数据点派生的意义上，这也可以视为局部一致性。 不利于CutMix的是，模型很容易了解增强，因为完美的水平和垂直伪像不太可能成为数据的显着特征。如果我们可以增加蒙版的数量和复杂性，那么新颖特征的空间 （即，由于蒙版中的边缘而产生的特征）将变得比数据中本机特征的空间大得多。 结果，模型极不可能“适合”此信息，因为它将需要成倍的容量。 这导致了我们的核心动机：构造一个掩盖MSDA，以最大化边缘形状的空间，同时保持局部一致性。 </p>
<p>​         为了实现局部一致性，我们需要主要由单个形状或连续区域组成的蒙版。 我们可能认为这是为了尽量减少二进制掩码从“ 0”过渡到“ 1”的次数，反之亦然。 对于我们的方法，我们首先从傅立叶空间中采样一个低频率的灰度蒙版，然后将其转换为具有阈值的二进制。 在讨论我们选择阈值的方法之前，我们将首先详细介绍获取低频图像的方法。 设Z表示一个复杂的随机变量，其值在域Z = Cw×h上，密度p &lt;（Z）= N（0，Iw×h），p =（Z）= N（0，Iw×h），其中&lt;and =返回实数 和它们输入的虚部。 令freq（w，h）[i，j]表示与w×hdiscreteFourier变换的第i，j个仓相对应的样本频率的大小。 我们可以通过衰减Z的高频分量来对其应用低通滤波器。 具体来说，对于给定的衰减功率δ，我们使用：</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func5.PNG)</p>
<p> 将F-1定义为离散傅里叶逆变换，我们可以得到一个灰度图像 ：</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func6.PNG)</p>
<p>​         现在剩下的就是将灰度图像转换为二进制掩码，以使平均值为给定的λ。 Lettop（n，x）返回一个包含输入x的上位元素的集合。 将某些灰度图像的顶部λ元素设置为值“ 1”，将所有其他灰度图的元素设置为值“ 0”，我们将得到一个均值λ的二进制掩码。 具体来说，我们有：</p>
<p>​        ![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func7.PNG)</p>
<p>​         回顾一下，我们首先采样一个随机复张量，其实部和虚部都是独立的且是高斯的。 然后，我们通过参数δ根据其频率缩放各个分量，以使δ的值越高，对应的高频信息衰减越大。 接下来，我们在复数张量上执行傅立叶逆变换，并取实部以获得灰度图像。 最后，我们将图像的顶部比例设置为值“ 1”，其余部分设置为值“ 0”以获得二进制掩码。 请注意，尽管这里我们仅考虑了二维数据，但通常可以通过我们的过程创建任意数量的蒙版。清单F中为该算法提供了伪代码，并提供了一些示例二维蒙版和混合图像（带有δ = 3，λ= 0.5）在图1中。从图中我们可以看到，尽管FMix的局部一致性有所降低，但伪像的空间显着增加，满足了我们的目标。 </p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\fig1.PNG)</p>
<h3 id="四、实验"><a href="#四、实验" class="headerlink" title="四、实验"></a>四、实验</h3><p>​         在本节中，我们执行一系列实验以证明FMix的功效。 对于每个问题集和数据集，我们都会对结果进行说明，我们认为任何相关的警告都具有相关性。 在整个过程中，我们的方法一直是使用超参数选项，该选项在文献中为每种设置产生最佳结果，但对于每种测试方法都是固定的。 这使我们能够确保比较是在平等的基础上进行的，并且基线可以很好地反映现实生活的表现。 对于特定于不同方法的超参数选择，我们力求与它们各自的论文和实现相一致。 唯一的例外是MSDA中Λ的分布，除非另有说明，否则使用α=1。对于FMix，我们使用δ= 3，因为发现这会产生具有足够多样性的大型伪像。 除了FMix，MixUp和CutMix外，我们还与CutOut（DeVries＆Taylor，2017）和Random Erase（Erase）（Zhong等人，2017）进行了比较，这两种文献中的流行调节器可以看作CutMix的前身 。 在可能的情况下，我们会进行重复训练，并在最后训练之后报告平均表现和标准偏差。 附录C部分中提供了有关实验装置的完整讨论。 在所有表格中，我们给出的最佳结果和结果在粗体显示的误差范围内。</p>
<p>​         <strong>图像分类</strong>我们首先讨论在CIFAR-10 / 100（Krizhevsky等人，2009）和Fashion MNIST（Xiao等人，2017）数据集上的图像分类结果。 我们训练了：PreAct ResNet-18（He et al。，2016），WideResNet-28-10（Za-goruyko＆Komodakis，2016），DenseNet-BC-190（Huanget al。，2017）和PyramidNet-272-200（ Han等，2017）。 对于PyramidNet，我们在Lim等人之后又应用了Fast AutoAugment（Limet等人，2019）和ShakeDrop（Yamada等人，2018）。 （2019）。 表1中的结果表明，与其他测试方法相比，FMix始终提供显着的改进。 确实，只有一种情况，FMix不能在最佳结果的误差范围内执行，而只有三种情况，FMix不能提供次佳结果的显着改善（超出误差范围）。 据我们所知，在金字塔网络设置中，FMix无需使用外部数据和Fashion MNIST，就可以在CIFAR-10上获得最新的技术成果。 </p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\table1.PNG)</p>
<p>​         接下来，我们在ImageNet大规模视觉识别挑战赛（ILSVRC2012）和变量（Russakovsky et al。，2015）上获得分类结果。 我们先评估完整数据集（ImageNet）上的ResNet-101，然后再评估ImageNet模型的一组自然对抗示例，然后对ImageNet-a进行评估（Hendrycks等，2019），以确定对抗健壮性。 随后，我们在Tiny ImageNet上报告了PreAct-ResNet18的结果（斯坦福大学，2015年），这些实验的结果在表2中给出.FMix再次全面改善了这些结果。 对于ImageNet-a，它们显示出对抗性鲁棒性的明显改善。 特别是，对ImageNet-a的改进远大于对ImageNet的改进。 在TinyImageNet上，FMix可以显着提高准确性，而MixUp则无法做到。 MixUp ImageNet的结果低于基线，但是，我们应该注意，我们使用的批处理量比论文中使用的要小。 总体而言，这些结果清晰地描绘了使用FMix进行图像分类可获得的改进性能。</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\table2.PNG)</p>
<p>​         <strong>音频分类</strong>我们现在评估Google Commands数据集上的MixUp和FMix，这是语音分类任务。 我们对每种话语的梅尔频率谱图执行FMix，即将每个bin转换为Mel标度中对应的bin的频谱图。 PreAct ResNet-18的结果在表1中给出。我们评估FMixand MixUp的标准α= 1（用于我们的大多数实验），α= 0.2（Zhanget等人推荐）。 （2017）for MixUp。 在这两种情况下，我们都可以看到FMix在误差范围之外改进了MixUp的性能，这表明这是一个重要的结果。</p>
<p>​         <strong>文本分类</strong>有毒评论（Jigsaw＆Google，2018）数据集是Kaggle的挑战，将文本分类为6种毒性类别之一（包括无毒，占大多数）。 继续使用比赛的ROC-AUC指标。 在生成一维FMix掩码以混合句子之前，我们使用FastText-300d单词嵌入来嵌入每个句子。 从表1中我们可以看出，尽管相距只有一个标准偏差，但FMix的平均性能还是比基线高。 通过比较，请注意，MixUp会严重损害此任务的性能，这可能不足为奇，因为不清楚在嵌入中如何表示插值单词。 </p>
<p>​         <strong>点云分类</strong>我们现在通过ModelNet10上的点云分类论证FMix到3D的扩展（Wu等人，2015）。 在应用3DFMix蒙版之前，我们将pointclouds转换为体素表示。 表1报告了由于结果的较大差异而导致的最近5个时期的平均中值准确度。 它表明，即使在更大的尺寸下，FMix仍会继续显着改善结果 </p>
<p>​         <strong>消融研究</strong>图2a给出了三种MSDA方法的验证准确性与参数α之间的关系。 验证准确度是由10％的数据组成的验证集的平均5倍以上。 使用先前实验中的PreAct ResNet18模型对CIFAR-10数据集执行消融。在FMix和MixUp的情况下，存在最佳值。 在两种情况下，此点都接近α= 1，尽管对于MixUp，其点稍微偏向0，如其ImageNet实验所发现的那样。 衰减功率δ的选择当然更为重要。 图2b表明，低的δ值会严重降低最终精度。 这不足为奇，因为低δ对应于有斑点的蒙版，在增补中不存在任何数据点的大区域。 较大的δ值对应于每个供体图像中具有较大内聚区域的平滑标记。我们注意到，对于δ＆3几乎没有改善，这证明了我们使用δ= 3的决定。</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\fig2.PNG)</p>
<p>​        </p>
<h3 id="五、为解释MSDA的先前尝试"><a href="#五、为解释MSDA的先前尝试" class="headerlink" title="五、为解释MSDA的先前尝试"></a>五、为解释MSDA的先前尝试</h3><p>​         尝试解释MSDA的成功不仅是在引入时进行的，而且还通过随后的实证和理论研究来进行。 在本节中，将对这些研究进行综述，以描绘出有关MSDA如何工作的当前理论和争论点。 除了他们对第2节中讨论的目标的实验外，Liang等人。 （2018）认为输入的线性插值限制了网络的记忆能力。 Guo等人采用了更多关于MSDA的数学观点。 （2019），他认为MixUp通过在数据流形之外约束模型来规范化模型。 他们指出，这可能会导致减少可能的假设的空间，但也可能导致生成的示例与原始示例相反，从而降低质量。 </p>
<p>​         继张等。 （2017），He等。 （2019）从MSDA的统计学习角度出发，基于对MSDA会扭曲数据分布并且因此无法执行传统意义上的VRM的观察，对他们进行了研究。 随后，他们提议将特征分为“次要”和“主要”，如果特征是高度特定于样本的，则将这些特征称为“次要”。 据称，对分布有重大影响的增强因素使模型主要学习“主要”功能。 从信息理论的角度来看，忽略这些“次要”特征对应于模型对输入的压缩增加。 虽然他等。 （2019）指出了从信息角度表征数据增强效果的重要性，但他们没有探索任何能做到这一点的措施。 相反，Heet al。 （2019）分析了学习表示的方差。 可以看出，这与表示的熵类似，因为可以通过样本之间的成对距离来估计熵，而较高的距离则对应于较大的熵和方差（Kol-chinsky＆Tracey，2017）。 在提出歧管混合时，Verma等人。 （2019）另外建议MixUp通过增加压缩来工作。 作者计算了训练网络早期层中表示的单值，较小的奇异值又对应于较低的熵。 这些方法的问题在于，表示的熵仅是表示关于输入的信息的上限。 </p>
<p>​         这些发现的问题在于它们仅与插值MSDA有关。 在某些研究结论中也存在分歧。 如果interpolativeMSDA通过阻止模型学习所谓的“次要”功能而起作用，则表明基础数据分布已失真，从而打破了VRM的核心假设。 此外，Yun等。 （2019）建议掩盖MSDA方法通过解决这种失真来起作用。 在这种情况下，由于消除了压缩表示的偏见，我们应该期望它们的表现比插值MSDA差。显然，有关驱动MSDA泛化的基本机制尚有争议。 特别地，提供掩盖MS-DA的解释所必需的是与当前内插MSDA的解释互补的，而不是与之矛盾。 </p>
<p>​         这些发现的问题在于它们仅与插值MSDA有关。 在某些研究结论中也存在分歧。 如果interpolativeMSDA通过阻止模型学习所谓的“次要”功能而起作用，则表明基础数据分布已失真，从而打破了VRM的核心假设。 此外，Yun等。 （2019）建议掩盖MSDA方法通过解决这种失真来起作用。 在这种情况下，由于消除了压缩表示的偏见，我们应该期望它们的表现比插值MSDA差。显然，有关驱动MSDA泛化的基本机制尚有争议。 特别是，提供掩盖MS-DA的解释所必需的是与当前内插MSDA的解释互补的，而不是与之矛盾。</p>
<p>​        </p>
<h3 id="六、-对MSDA的统一理解"><a href="#六、-对MSDA的统一理解" class="headerlink" title="六、 对MSDA的统一理解"></a>六、 对MSDA的统一理解</h3><p>​         现在，我们分析插值MSDA和掩蔽MSDA，以期对其功能进行统一解释。 首先，我们提出一种措施，该措施捕获关于扩充数据的学习与对原始数据的学习相对应的程度。 特别地，学习学习的表示之间的相互信息。 我们发现，内插的效果与掩盖的效果几乎完全不同。 这一发现使人们怀疑，将两种形式都用作双重客体将比仅使用一种形式更好。 我们在一个简单的设置中验证了这一点，在该设置中，我们为每次迭代迭代在两种MSDA方法之间进行交替。</p>
<ol>
<li><p><strong>测量失真</strong></p>
<pre><code>     我们想衡量学习增强数据是否模拟了学习真实数据。 为了实现这一目标，我们提出了对真实数据和增强数据的训练模型，然后比较他们学习的表示形式。 我们首先需要对学习的表示之间的相似性进行度量。 此处的一个很好的选择是相互信息，即在已知另一个变量的情况下减少一个变量的不确定性。 本质上，此数量应捕获以一种表示形式编码的信息量，也以另一种表示形式编码的信息量。 计算互信息通常具有挑战性，因为很难确定哪个随机变量是另一变量的编码的程度。 我们可以根据可预测性来考虑。 在我们的设置中，我们希望估计原始数据集的学习表示ZX和某些扩充数据集ZA的学习表示之间的相互信息：</code></pre>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func8.PNG)</p>
<p> 其中D是Kullback-Leibler散度。 在此形式中，我们可以看到我们计算I(ZX；ZA)的能力取决于我们计算P(ZA|ZX)的能力。 现在可以观察到，我们需要一个至少足够强大的模型来撤销对X的ZX编码，然后将这个X重新编码为AZA，以便获得ZA的最佳可能预测器。 换句话说，我们的p(ZA|ZX)模型越强大，它的精度就越高，这个预测就会离ZA的边际分布越远。 这样做的结果是，我们往往会低估互信息，而且随着ZX到ZA映射复杂度的增加，我们的估计会变得更差。</p>
<p>​         我们可以通过慎重选择要用于测量的模型来缓解上述问题。 特别地，我们建议使用变分自动编码器（VAE）。 这些由编码器p（Z | X）和解码器p（X | Z）组成。我们在Z上施加标准正态先验，训练模型以最大化证据下限（ELBO）目标：</p>
<p>​        ![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func9.PNG)</p>
<p>​         此选择有三个主要动机。 首先，由VAE学习的表示形式对数据中的显着或可压缩信息进行了丰富的描述。 其次，当通过VAE对Z进行建模时，I（ZA; ZX）在某种程度上更易于计算。 将经过增强训练的VAE解码器的输出表示为ˆX = decode（ZX），并且由于数据处理不等式，当解码器将所有信息保留在Z中时，我们具有相等的I（ZA; ˆX）≤I（ZA; ZX） 。 现在，我们只需要观察已经有一个模型p（ZA | X），该模型就是在扩充数据上训练的编码器。 估计marginalpZApresentsa挑战，因为它是高斯混合。 但是，我们可以测量互信息的另一种形式，该形式等效于加法常数，并且其散度具有封闭形式的解，其中：</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\Func10.PNG)</p>
<p>​         以上适用于任何不依赖x的分布选择。 从概念上讲，这表明，如果我们以边缘pZA以外的任何恒定分布近似估计（ZA | ˆX），我们将平均平均会丢失更多信息。 另外请注意，我们在VAE训练期间隐式最小化D（pZA‖N（0，I））（Hoffman＆Johnson，2016）。 根据这一事实，我们可以写出I（ZA; ˆX）≈EˆX [D（p（ZA | ˆX）‖N（0，I））]。 使用VAE的第三个也是最后一个优点是，我们可以轻松地获得I（ZA; ZX）的有用上限，这样就可以在两边都绑定。 由于ZA只是X的一个函数，再次由于数据处理不等式，我们有I（ZA; X）≥I（ZA; ZX）。 由于仅来自ELBO物镜的相对熵项，因此这很容易计算。</p>
<p>​         总而言之，我们可以通过首先训练两个VAE（一个在原始数据上，一个在建议的数据上）来计算度量。 然后，我们使用一个VAE生成原始数据中数据点的重构，然后使用另一个VAE对其进行编码，现在我们计算编码分布与边际估计之间的相对熵的期望值，以获得 表示之间的相互信息。 然后，我们使用实际数据点（而不是重构）对其进行重新计算以获得上限。 表3给出了MixUp，FMix，CutMix和基线的上述数量。 结果表明，MixUp持续减少了从原始数据中学到的信息量。 相比之下，FMix和CutMix都设法从数据中诱导出比在真实数据上获得的互信息更大的互信息。此结果的意义是提供具体证据，证明内插MSDA的功能与掩盖MSDA的功能根本不同。 </p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\table3.PNG)</p>
<p>​         鉴于功能上的这种差异，可以合理预期，通过两种MSDA的同时动作，我们可以获得更好的性能。 表4包含在CIFAR-10上使用PreAct-ResNet18在每批之间的两个MSDA之间交替时获得的结果，内插和遮罩的组合提供了最佳结果，特别是FMix + MixUp（称为FMix +）。 比单独使用任何一种方法提供的结果都更糟。 这些发现支持了以下观点：两种类型的MSDA的作用是互补的，可以同时利用。</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\table4.PNG)</p>
<p>​         为了更好地理解这些扩充对泛化的影响，有必要在分类设置中研究学习的表示形式。 为此，我们将分类器使用梯度加权类激活图（Grad-CAMs）做出的决策可视化（Selvaraju et al。，2017）。 Grad-CAM通过获取模型输出相对于激活图的导数并根据其贡献进行加权，从而找到图像中对网络预测贡献最大的区域。 图3显示了使用MixUp，FMix，FMix +和许多CIFAR-10图像的基线训练的模型的Grad-CAM。 MixUp使模型依赖于常规或“主要”功能，并实现更大的输入压缩率。 相比之下，FMix导致模型依赖于特定的上下文或“次要”功能，并与输入保持较高的相互信息。 在这两者之间交替显示，可以在“主要”功能和“次要”功能之间取得平衡。 </p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\fig3.PNG)</p>
<p>​         由于插值方法使网络偏向于更依赖于一般特征的配置，因此，我们希望在观察数量有限且更容易学习“次要”特征的情况下，其影响最为明显。 我们通过改变CIFAR-10训练集的大小和使用图4中的不同MSDA进行训练来凭经验确定这一点。结果证实了我们的信念，即将内插法和掩蔽方法相结合会带来两全其美的效果。 值得注意的是，仅使用FMix +进行训练的数据的性能与基线上仅使用FMix +的数据的60％的性能相同，相当于示例数量增加了三倍。</p>
<p>![](C:\Users\12466\Pictures\paper\Understanding and Enhancing Mixed Sample Data Augmentation\fig4.PNG)</p>
</li>
</ol>
<h3 id="七、总结与未来工作"><a href="#七、总结与未来工作" class="headerlink" title="七、总结与未来工作"></a>七、总结与未来工作</h3><p>​         在本文中，我们介绍了FMix，它是一种遮罩MSDA，它在保留局部特征的同时大大增加了遮罩形状的数量。 通过一系列综合的实验，我们表明FMix改进了一系列模型，模式和维度的分类性能。 通过我们的分析，我们对插值MSDA和掩蔽MSDA的性能提供了统一的解释：插值导致模型依赖于一般的压缩特征； 掩盖会导致模型对原始信息进行训练时编码相同的信息，同时消除记忆。 我们进一步表明，通过交替训练程序可以在单个模型中获得两者的理想效果。这一发现是我们分析，验证我们的方法和发现的直接推论。 尽管我们的工作是在统一框架下迈出第一步的MSDA推理，但我们的理解仍有进一步发展的空间。 确实，在这个领域进行的早期实验导致了几行查询，最终没有结果，我们将在附录E节中进一步讨论。 未来的工作应该加深我们对目标空间，MSDA对尚未开发的应用程序的影响以及通过组合MSDA可以得到的改进的理解。 除了这些实际的发展，还需要更丰富的数学分析来捕捉增强训练的效果，以便在实践中充分利用MSDA。 </p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/Paper/Understanding%20and%20Enhancing%20Mixed%20Sample%20Data%20Augmentation/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Paper/SuperMix Supervising the Mixing Data Augmentation" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="SuperMix-Supervising-the-Mixing-Data-Augmentation"><a href="#SuperMix-Supervising-the-Mixing-Data-Augmentation" class="headerlink" title="SuperMix: Supervising the Mixing Data Augmentation"></a>SuperMix: Supervising the Mixing Data Augmentation</h1><h2 id="2020-05-10"><a href="#2020-05-10" class="headerlink" title="2020-05-10"></a>2020-05-10</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><pre><code>     在本文中，我们提出了一种有监督的混合增强方法，称为SuperMix，该方法**~~利用教师的知识根据图像的显着区域对图像进行混合~~**。 SuperMix优化了一个混合目标，该混合目标考虑：**~~i）强制输入图像的类别出现在混合图像中； ii）保留图像的局部结构； iii）降低抑制重要特征的风险~~**。 为了使混合适合大规模应用，我们针对同一问题</code></pre>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">对于以上三点，个人理解：</span><br><span class="line">本文方法要做的就是，将多张图像中所含有的实例部分尽量完整的混合到一张图像中，即保证了保留了多张图像中的有效内容及其特征（即实例对象）,而不会导致下文提到的:</span><br><span class="line">“通过对一个图像中的特征进行平均或覆盖而具有琐碎的特征”</span><br></pre></td></tr></table></figure>

<p>开发了一种比梯度下降快65倍的优化技术。 通过对对象分类和知识分发这两项任务的广泛评估和消融研究，我们验证了SuperMix的有效性。 在分类任务上，SuperMix提供与高级增强方法（如自动增强）相同的性能。在**<del>蒸馏任务</del>**上，SuperMix设置了具有极</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">知识蒸馏任务：？？？？</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>大简化功能的最新技术。 特别是，在来自相同架构的八位师生中，有八分之六的学生接受了混合数据的培训，其学习优势明显超过了老师 。</p>
<h3 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h3><p>​         改进深度神经网络（DNN）泛化性的一种主要方法是数据增强，它通过在给定数据集中变换图像来扩大训练集。 经典的数据增强对输入图像执行固定的随机变换组合，例如水平翻转，裁剪，缩放，色彩处理和剪切[1,2,3]。 近来，已经进行了显着的努力来改进增强，例如，通过自动搜索最佳增强策略[4,5,6,7]。 以前的大多数增强方法都集中于转换单个图像，而<font color=blue><strong>忽略了多个图像对于增强可能非常有用的组合</strong></font>。</p>
<p>​         为了解决这个缺点，最近的一些研究已经考虑合并多个图像进行增强[8,9,10,11,12,13]。 这些方法的性能受到缺乏监督的限制，从而阻止了它们充分利用输入图像的潜力。 因此，当前的混合功能不够严格，并且常常**<del>通过对一个图像中的特征进行平均或覆盖而具有琐碎的特征</del><strong>，例如从背景中对另一图像进行平均，从而抑制视觉图案。 缺乏监督进一步限制了在混合图像上进行训练的性能，因为相应的伪标签不准确。 混合来自同一类别的图像可以缓解此问题，但</strong><font color=blue>会大大减少所生成图像的多样性</font><strong>。 通过设计更</strong><del>全面</del><strong>的混合功能并为混合图像生成~~**准确</strong>~~的软标签，可以利用教师的知识来解决这些问题。 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">之前已有的相关方法（比如cutmix，mixup）均由于缺乏监督，使得混合图像的潜力没有充分发挥。且对于前者（将图像的一部分矩形区域用领一张图像的对应区域替代，标签也对应的进行混合），经常会出现混合标签不准确的情况（因为替代的区域不一定包含有效实例）；而对于后者（将两个图像按一定比例进行通道逐像素混合，标签也进行混合），但这样会使得实例的特征被平均，而使得特征琐碎。将同类别的图像进行混合可以有效解决以上两个问题，但这大大限制了生成图像的多样性。</span><br></pre></td></tr></table></figure>

<p>​         在本文中，我们提出了一种监督混合增强方法，称为SuperMix，该方法利用教师的知识来基于输入图像的显着区域混合输入图像。 在这里， <strong><del>在这里，教师可以是在原始数据集上预先训练的目标模型本身，即自我训练[14,15,16,17,18,19]，也可以是旨在通过知识转移指导学生网络的更复杂的模型 [20,21]。</del></strong>  我们通过采用一组混合遮罩来规范监督混</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p>合增强的问题，**<del>该混合遮罩将混合图像中每个空间位置处的像素值与输入图像中相应位置处的像素值相关联。</del>** 使用遮罩，我们定义了一个一般的混合功能，与以前的方法相</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">混合遮罩是什么样子，作用是？？？？</span><br><span class="line">混合图像是指？？？？</span><br></pre></td></tr></table></figure>

<p>比，它允许将多个输入图像本地组合。 为找到混合遮罩而提出的优化问题考虑了三个条件，以产生宝贵的混合图像。 首先，**<del>教师网咯对混合图像预测出的前k个类必须包含k张输入图像中的每个预测类</del><strong>。 这样可确保在混合过程中保留所有图像的重要特征。 其次，~~**遮罩必须在空间上平滑，以使混合后的图像类似于输入图像的结构</strong>~~。 第三，必</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">怎么理解所谓的空间平滑？？？？</span><br></pre></td></tr></table></figure>

<p>须在**<del>遮罩的元素在每个空间位置处必须在输入样本之间稀疏</del>**，以减少抑制重要特征的风</p>
<p>险。 **<del>这强制将混合图像中的每个空间位置分配给单个输入图像</del>**。 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">第三点 遮罩每个空间位置在输入样本间稀疏的理解？？？？</span><br></pre></td></tr></table></figure>

<p>​         由于问题的复杂性，使用随机梯度下降（SGD）优化蒙版非常耗时且不可行，尤其是对于大型数据集而言。 因此，我们在ImageNet上为SuperMix开发了一种迭代算法，该算法与SGD相比提供了65倍的提速。 通过对对象分类和知识蒸馏这两个任务的广泛实验和消融研究，我们验证了SuperMix的有效性，并证明它通过产生具有本质上平滑的软标签的丰富混合图像来揭示教师网络的知识。 SuperMix展示了与SOTA自动扩充方法相似的性能[4,5,6]。 此外，训练学生仅对SuperMix数据进行分类，以明显的优势超越了以前的复杂SOTA蒸馏方法。 图1概述了如何将SuperMix纳入DNN的训练阶段。 </p>
<p>​        ![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\fig1.PNG)</p>
<h3 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h3><p>​         <strong>数据扩充</strong> Cubuk等人提出了AutoAugment（AA）[4]，以在给定预定义的一组转换和数据集的情况下自动搜索增强策略。 尽管自动增强AA表现出显着的性能，但即使对于小型数据集，它也需要花费大量的训练时间。 因此，多种方法已经尝试通过采用更有效的搜索方法来减少自动增强的训练时间，例如快速自动扩增（FAA）[5]或基于人群的扩增（PBA）[6]中的密度匹配。</p>
<p>​         最近的一些研究已经考虑采用多个图像进行数据增强**<del>[8,10,11,12,13]</del>**。 Smart </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">重要参考文献：</span><br><span class="line">[8]:Smart augmentation learning an optimaldata augmentation strategy. </span><br><span class="line">[11]:Mixup as locally linear out-of-manifold regularization.</span><br><span class="line">[13]:Between-class learning for image classification.</span><br></pre></td></tr></table></figure>

<p>Augmentation [8]建议使用与目标模型同时训练的DNN合并同一类的多个图像。 但是，与每个目标模型一起训练额外的深度模型会占用大量资源，并严重限制了解决大规模问题的方法的可伸缩性。 此外，该方法限于来自同一类别的合并图像，这限制了合并图像中视觉图案的多样性和新颖性。 MixUp [10,13]通过凸线性插值组合了一对图像以进行增强。 CutMix [12]提出将输入图像的裁剪区域覆盖在另一图像上以增强数据。 尽管MixUp和CutMix在训练对象识别模型方面已显示出显着的改进，但它们仍存在上一节中讨论的主要缺点。 </p>
<p>​         <strong>知识蒸馏。</strong>在这项研究中，我们证明SuperMix对知识蒸馏的任务特别有利。 因此，在本节中，我们简要回顾其背景。 Buciluaet等。[20]提出通过匹配教师和学生的对数，即在softmax normalization之前的输出，来利用教师的知识。 Hintonet等 [21]指出，除了优胜者以外，老师关于其他课程的决定中包含着重要的信息。 为了更好地利用此信息，他们在softmax中引入了温度系数，以使匹配之前的概率预测变得平滑。 此后，针对KD提出了许多方法[21,22,23,24,25,26,27,28,29,30,31, 32,33]。</p>
<p>​         注意转移（AT）[24]和FitNet [23]提出了使用教师的中间表示以及输出来指导学生的方法。 Ahnet al。 [27]提出了变分信息提纯（VID），它最大化了教师和学生之间相互信息的下界。 最近，Tianet等人。 [22]提出了对比表示散播（CRD），它通过对比损失最大化了相互信息的更紧密的下界。 他们已经对数十种SOTA方法的知识蒸馏进行了基准测试，并说明CRD优于以前的所有蒸馏方法。 尽管作者采用了内存缓冲区来改善该理论的实践可行性，但CRD要求在每次迭代中都嵌入大量训练样本的表示形式。 但是，我们证明，增加训练集可以使我们通过简单的蒸馏方法获得SOTA性能。 </p>
<h3 id="三、混合数据增强"><a href="#三、混合数据增强" class="headerlink" title="三、混合数据增强"></a>三、混合数据增强</h3><p>​         混合增强[10,11,12,13]具有增加训练集大小的巨大潜力。 形式上，给定训练集D = {（xi，yi）} ，其中i 属于区间（0，N-1），混合方法采用子集X⊂D来产生混合数据点ˆx和标签ˆy。混合图像的关键特性是它们必须靠近训练集的流形， 因为混合的目的是扩大训练分布的支持。 先前的混合方法[10,13]通过采用保留图像局部平滑度的操作考虑了这一要求。MixUp[10,13]使用凸线性插值将一对图像（xi，xj）组合为：ˆx = rxi +（1 −r）xj，其中r〜Beta（α，α）是来自对称β分布且α∈（0，∞）的随机混合权重。 <strong><del>由于缺乏监督，x^的软标签y^也使用相同的线性插值计算</del>**：ˆy =rδ（yi）+（1-r）δ（yj），其中δ（·）是one-hot编码函数。 尽管这种方法及其变体[12,11]已证明对训练深层模型有效，但它们存在</strong><del>盲混合</del>**带来的两个缺点。 **<del>首先，系数对整个图像具有同等的重要性，可以通过平均背景图像或其他图像的次要特征来抑制重要特征。 其次，计算出的软标签不能准确地描述混合图像所代表的类的概率</del>**，从而对训练性能产生负面</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1、这里的“盲混合”就是上面所说的：没有针对性的混合两张图像的有效内容</span><br><span class="line">2、为什么称之为盲混合或为什么说是缺乏监督？？？？</span><br><span class="line">首先，系数对整个图像（参与混合的每一张图像）赋予相同的重要性（因此本文做的就是，对于不同图像的不同位置分配不同的权重），这使得其可能通过平均背景图像或平均其他图像的次要特征来抑制原图像的重要特征。 </span><br><span class="line">其次，计算出的软标签不能准确地描述混合图像所代表的类的概率</span><br></pre></td></tr></table></figure>

<p>影响。为解决这些问题，我们为增强函数构建了一个一般公式。 为实现这一目的，我们使用一组混合掩码M = {mi}，**<del>其中i属于区间（0，k-1）</del>**，其中mi：Λ→[0,1]，将xi中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">K指的是：用于混合的K张图像</span><br><span class="line">mi表示这k张图像中的第i张图像对应的掩码，掩码值位于区间[0,1]内</span><br><span class="line">Λ-&gt;(0,1)：表示从图像位置空间Λ到[0,1]区间的映射</span><br></pre></td></tr></table></figure>

<p>每个空间位置u∈Λ与标量值**<del>mi（u）</del>**相关联。 使用混合掩码，我们将广义混合函数定</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mi（u）：表示掩码mi在位置u处的值</span><br></pre></td></tr></table></figure>

<p>义为： </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\func1.PNG)</p>
<p>其中xi是X中的第i个样本，该运算符⊙表示逐元素乘积，**<del>且∑imi（u）= 1以保持组合的凸性</del>**。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">保证所有用于混合图像在同一位置处的系数和应该为1</span><br><span class="line">什么叫保证组合凸性？？？？（在高数中有凸函数、凸曲线，在这里的凸性指的是什么）</span><br></pre></td></tr></table></figure>

<p> <strong><del>当k = 2并且每个掩码中的所有值相等时，即实现了MixUp的混合功能</del></strong> <del><strong>[10]。 当k = 2时，并且其中一个蒙版中除裁切区域之外的所有值都等于1，它也会恢复CutMix [12]</strong></del>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">该方法与mixup和cutmix的主要区别在于，其对于每个像素都给出了不同的混合系数，而不是整体的（mixup）或局部的（cutmix）给出混合系数。即可以实现更准确的mix</span><br><span class="line">但是标签y是怎么混合的？？？？</span><br></pre></td></tr></table></figure>

<p> 图2提供了蒙版在混合增强中的作用的视觉比较。 在下一节中，我们将描述如何使用教师模型的知识来计算M，以使混合图像ˆx包含X中样本的丰富视觉信息。 </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\fig2.PNG)</p>
<ol>
<li><p><strong>监督混合</strong></p>
<p>​         在图像分类任务中，类别信息被嵌入到描述每个类别的视觉特征的空间模式中。 DNN的性能高度取决于它可以如何充分利用这些空间特征来识别类别。 因此，我们假设结合训练模型（老师）的知识来识别和组合多个图像的显着区域可以指导目标模型（学生）学习更多的判别性和可概括的特征。 此外，采用监督机制可以解决上一节中讨论的盲混合的缺点。</p>
<p>​         在此，我们开发了一种监督输入图像混合的方法。 让f^T = [f^T0，…，f^Tm-1]^T：R^W×H×C→[0,1]^ m表示由教师模型对m个类别进行预测的概率向量。 我们的**<del>目标是优化方程1中的这一组掩码M</del>**，以便根据老师的知识，使得X中的所有显</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如何求解掩码组M的：由方程（1）可以看出，掩码组M中的每一个mi构成了合成图像^x，通过对下面KL（fT（ˆx）|| ˆy）的最小化，则可以对M进行优化，而其中^y由教师网络预测得到，所以其起到了对掩码mi的约束与监督。</span><br></pre></td></tr></table></figure>

<p>着区域都出现在混合图像ˆx中。 可以解释为：f^T（ˆx）≈ˆy， 其中，对于与X中的图像相关联的类，^y是高的 。 因此，对于k=2时，我们首先使用Beta分布公式来公式化  使用先前方法[10,12]中计算出的目标软标签^y。 对于k≥2，我们通过从Dirichlet分布中采样混合系数来泛化。 令**<del>（r0，…，rk-1）〜Dir（α）为参数α和尺寸k的对称多元Dirichlet分布的随机样本</del>**，我们将目标软标签定义为： </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\func2.PNG)</p>
<p> <strong><del>其中yT（xi）= arg maxjfTj（xi）是教师模型对于图像xi∈X预测的类别标签。</del></strong> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">则δ（y^T）表示对教师模型预测类别的onehot编码</span><br><span class="line">其中，ri是通过迪利克雷分布随机采样得到的</span><br></pre></td></tr></table></figure>

<p>​         然后，通过最小化KL（fT（ˆx）|| ˆy）可以找到一组混合掩码，其中KL是Kullback-Leibler散度。 但是，遮罩必须具有两个附加属性才能构造出丰富的混合图像。 首先，**<del>生成的图像必须驻留在训练数据的流形附近。 在实践中，这解释为每个遮罩必须在空间上平滑，以便生成的图像类似于输入的空间结构</del>**。 其次，必</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">生成图像驻留在训练数据的流形附近，可以解释为遮罩在空间上平滑？？？？</span><br><span class="line">个人理解：遮罩平滑使得混合的不混乱，边缘平滑且内容完整？</span><br></pre></td></tr></table></figure>

<p>须<del><strong>在输入样本上稀疏放置遮罩，以便将输出图像中的每个空间位置仅分配给输入集中的单个图像。 这样可    以防止在每个空间位置平均多个图像，从而抑制重要特征</strong></del>。 考虑到这些，找到混合掩模的优化问题可以写</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">再输入样本上稀疏放置遮罩，怎么理解？？？？</span><br><span class="line">个人理解：如果每个图像i的遮罩mi都比较稀疏，则会尽量减少多个遮罩间重叠的可能，进而不会发生特征的干扰与平均</span><br><span class="line">本文主要通过Ls实现该目的。</span><br></pre></td></tr></table></figure>

<p>成： </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\func3.PNG)</p>
<p> 其中Lσ是蒙版粗糙度的惩罚项，例如，总变化（TV：total variation）范数，而Ls是损失函数，可鼓励跨输入样本的蒙版稀疏性。 </p>
<p>​         由于任务的复杂性，我们开发了一种迭代算法来解决该问题。 在每次迭代t时，可以通过以下归一化来满足凸条件： </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\func4.PNG)</p>
<p> 这里的s（·）是**<del>sigmoid函数</del>**。 因此，等式1中的广义混合函数采用归一化的掩码来构造ˆx。 使用归一化的掩</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sigmoid函数（即S型函数）：</span><br><span class="line">1&#x2F;（1+e^-x）</span><br><span class="line">以上公式能够使得∑i mi（u）&#x3D;1，即公式3中的第二条件，但是为什么要使用sigmoid函数呢，m^t-i（u）的值本身不就在区间[0,1]内吗？？？？</span><br><span class="line">所谓的凸条件就是指加和为1？？？？</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>码，我们将**<del>稀疏性促进损失</del>**定义为： </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\func5.PNG)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">如何实现了遮罩的稀疏放置？？？？</span><br><span class="line">（|mti（u）（mti（u）-1）|值域为[0，0.25]）</span><br><span class="line">通过后面的牛顿方法更新，可以最小化损失Ls，即最小化∑_ui |mti（u）（mti（u）-1）|</span><br><span class="line">最小化过程：因为每个位置之间是独立的，所以假设u&#x3D;1（即只有一个位置），即求解多元函数的条件极值，即构造多元函数方程y&#x3D;target+λcondition，并使用拉格朗日系数法求解最小值？？？？（高数内容，但拉格朗日系数法只能求解最大值？？？？）</span><br><span class="line">求解值为：mti&#x3D;1&#x2F;k，k为用于混合的图像数量，当每一个mti&#x3D;1&#x2F;k时会有最大值，随意LS最小化，会避免这种平均的出现？？？？</span><br><span class="line"></span><br><span class="line">参考链接：https:&#x2F;&#x2F;blog.csdn.net&#x2F;a493823882&#x2F;article&#x2F;details&#x2F;80508455</span><br></pre></td></tr></table></figure>

<p>​        可以通过最小化SuperMix的目标（LSM = KL +λσLσ+λsLs）来估计一组适当的混合蒙版。 通过使用SGD [34]或深度生成器[35]进行显着性检测和DNN预测解释的任务，已经研究了此问题的一种简单形式。 然而，当前的问题更加复杂，因为**<del>在优化中涉及多个图像，并且在所有相应的掩模上都应当最小化粗糙度损失和稀疏性促进损失</del>**。 正如我们在4.4节中讨论和评估的那样，SGD非常慢，并且无法生成大量数据，例如，原始数据集大小的数倍。 此外，通过扩展[35]，采用专用的深度模型来混合数据使算法与模型相关，并且计算效率不高。 </p>
<p>​         我们开发了一种快速有效的算法，以牛顿迭代法为基础来优化混合蒙版，以便在不确定情况下找到非线性方程组的根[36,37]。 具体来说，我们使用平滑投影（SP）[38]来优化L’sm = KL +λsLs，而不是优化Lsm [38]，该投影直接满足蒙版的平滑度。 正如我们在第4.4节中稍后分析的那样，这大大缩短了混合的执行时间。 考虑到L’sm在M处的一阶近似，可以在迭代时更新每个掩码，以找到根为：mt + 1i←mti + ∆mti。 可以使用牛顿的方法来计算更新： </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\func6.PNG)</p>
<p> 这里的梯度是相对于Mt的，即{mt0，…，mtk-1}的集合。由于散度和Ls均为非负，我们也有| L′SM | = L′SM。此公式使用L2范数投影 去计算∆Mt。 我们使用平滑投影（SP）对其进行修改，以保留蒙版的平滑度并计算平滑更新量 :</p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\func7.PNG)</p>
<p> 其中gσ∗ ∇L′SM是使用标准偏差为σ的二维高斯平滑滤波器g的梯度的平滑版本。 必须注意，等式6和7中的所有矩阵在矩阵运算之前均已矢量化，并且在迭代结束时将蒙版重新reshape。 此外，由于蒙版的平滑性，在进行混合之前，我们优化了一组下采样过的掩码对其进行了上采样。 图3展示了所建议的混合方法的示意图。</p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\fig3.PNG)</p>
<p>​         当fT（ˆx）的TopK预测类与X中样本的预测类相同时，算法终止。 例如，当X由识别为“猫”和“狗”的两个样本组成时，fT（ˆx）的前2个预测类也应为“猫”和“狗”的类别。 根据教师的知识，此标准可确保输入集中的所有样本在混合样本中可见。算法1和图3分别演示了SuperMix的详细算法和原理图。 我们对从D提取的随机输入样本集执行算法以生成D’。 为了简洁起见，我们定义增强因子κ= | D’|/| D |，以显示混合数据集的大小与原始数据集的大小之比。 图5提供了SuperMix，MixUp和CutMix生成的混合图像的视觉比较。为了更好的评估，针对混合图像中的两个类别计算了类别激活图[39]。 </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\fig5.PNG)</p>
</li>
<li><p><strong>训练目标</strong></p>
<p>​        使得F^T与F^S分别表示教师和学生的logits输出。 Hinton等文献[21]引入了温度系数τ，用于计算概率输出：f^T（x，τ）= softmax（F^T（x）/τ），f^S（x，τ）= **<del>softmax</del>**（F^S（x）/ τ）。 然后将蒸馏的原始目</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">softmax函数：</span><br><span class="line">   xi &#x3D; e^xi&#x2F;(∑_n e^xn)</span><br><span class="line">与sigmoid异同：</span><br><span class="line">   值域同样是[0,1]，但softmax加和为1，而sigmoid没有该特性</span><br></pre></td></tr></table></figure>


</li>
</ol>
<p>   标定义为： </p>
<p>   ![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\func8.PNG)</p>
<p>​    其中H（·，·）是交叉熵损失函数，λ_KD是平衡系数，并且y是x的真实标签。 在此设置中，所有训练样本x都假定来自原始数据集D。 我们观察到，使用具有相等权重的交叉熵损失函数在D与D’上同时训练学生足以实现SOTA性能。 因此，我们将分类和蒸馏任务的简单交叉熵损失视为： </p>
<p>   ![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\func9.PNG)</p>
<p>​    其中，yT（ˆx）是教师生成的伪标签。 我们还通过最小化训练集和扩充集上的LKD来评估由扩充数据集增强的原始蒸馏的性能。 </p>
<h3 id="四、实验"><a href="#四、实验" class="headerlink" title="四、实验"></a>四、实验</h3><p>​         我们使用CIFAR-100 [1]和ImageNet [40]的两个基准数据集来评估SuperMix在对象分类和知识提取两个任务上的性能。 对于知识提炼，我们将SuperMix与之前的四种主要SOTA方法和两种混合增强技术进行了比较。为了公平地比较，我们使用老师的知识为MixUp和CutMix的数据计算了伪标签。 我们还遵循标准的自动增强评估设置[4,5,6]，并将它们与SuperMix在对象分类任务上进行比较。 对于CIFAR-100上的知识蒸馏，我们还通过使用ImageNet32x32 [41]（ImgNet32）训练集中的未标记数据来构建未标记集来考虑其他基准。 这有助于更好地评估混合增强方法提供的数据的作用。 </p>
<p>​         对于蒸馏，我们遵循Tianet等人定义的培训设置。 [22]。在CIFAR-100上，我们使用SGD优化器，其学习速率为0.1，动量为0.9，重量衰减为5e-4。 在200、300、400和500时，学习率下降了0.1，最大时数设置为600。我们还遵循标准的Pytoch练习，在ImageNet上增加了10个训练时。 根据混合数据集的纪元数用1κ缩放。 例如，当κ= 5时，混合数据集的最大时期数是120。对于CIFAR-10和ImageNet，批次大小分别设置为128和256。 对于CIFAR-100数据集，我们将SuperMix中高斯平滑的σ设置为1，并将蒙版的空间大小设置为8×8。 对于ImageNet，σ设置为2，蒙版的大小设置为16×16。 对于所有基准比较，我们设置τ= 4，α= 3，λKD= 0.1，λs=25。此外，在所有实验中，除非另外说明，否则SuperMix的性能是通过分别在CIFAR-100和ImageNet上生成5×105和106个图像来评估的 。 根据[22]的实验设置和第4.3节中的消融研究，选择所有超参数。 补充材料中提供了网络体系结构，基准方法的设置以及更多培训详细信息。 </p>
<ol>
<li><p><strong>目标分类</strong></p>
<p>​         为了提供对MixUp，CutMix和SuperMix的监督，我们首先在原始数据集上训练目标模型，然后使用它生成CIFAR-100和ImageNet分别等于2和3的混合数据。 之后，使用方程式9中的LCE从头开始在增强数据和原始数据的混合物上训练目标模型。其余结果从原始论文中报告。 表1列出了这些实验的结果。 在五种网络架构中的四种中，SuperMix提供了与SOTA自动扩充方法相似的结果。 这突出了混合多个图像以进行数据增强的有效性。 </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\table1.PNG)</p>
</li>
<li><p><strong>知识蒸馏</strong></p>
<p>​         CIFAR-100表2和3的结果分别给出了两种具有挑战性的蒸馏方案的结果，在这种方案中，教师和学生分别来自和不来自同一体系结构。 在两种蒸馏方案中，训练学生对通过混合增强方法生成的数据进行分类的性能始终优于以前的方法。 SuperMix生成的数据证明了所有评估中的最佳表现，并且在同一架构的七个师生设置中，有五分之二的学生接受了SuperMix数据的培训，其表现优于其老师。 表2和表3的最后五行显示了使用原始KD进行知识蒸馏的结果[21]。 有趣的是，当网络共享相同的体系结构时，即使将ImgNet32的未标记数据与KD配合使用，其性能也优于CRD + KD。 MixUp，CutMix和SuperMix的结果表明，它们可以增强其他蒸馏技术的性能。 </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\table2.PNG)</p>
<p>![table3](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\table3.PNG)</p>
<p>​         这些观察突出了三个关键点。 首先，训练集的规模有限是制约知识蒸馏性能的主要因素。 根据表2，当提供ImgNet32的外部数据时，几乎所有学生都能获得与CRD相当的结果。 其次，与来自外部来源的未标记数据相比，混合增强为蒸馏提供了更多信息。 第三，有监督的混合产生了丰富的图像，这些图像非常适合知识蒸馏的任务，并且优于盲目混合方法。 </p>
<p>​         <strong>ImageNet上的结果</strong>：通过将ResNet-34的知识提取到ResNet-18中，我们展示了Im-ageNet上混合数据的有效性。 表4列出了ImageNet数据集上的蒸馏结果。 对通过混合增强方法生成并由教师模型标记的数据进行分类的结果始终明显优于以前的SOTA方法。更重要的是，在八种使用混合图像进行蒸馏的实验中，有五项表现优于教师。 这证明了混合扩充对知识蒸馏任务的可扩展性和有效性。此外，将蒸馏与原始蒸馏目标相结合进一步增强了蒸馏性能，并验证了混合增强对提高其他蒸馏方法性能的有效性。</p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\table4.PNG) </p>
</li>
<li><p><strong>消融实验</strong></p>
<p>​        <strong>训练集大小的影响：</strong>在这一部分中，我们通过测量学生的Top-1test准确性与CIFAR-100上的扩充大小，来研究数据集的大小如何影响蒸馏性能。 对于所有混合方法，我们设置k = 2和α= 1，即从均匀分布器〜Unif（0,1）中采样混合系数。 图6a和6b给出了在两个师生设置上进行的评估结果。 通过增加5×105处的扩增大小和平稳期，可以改善分散性能。 使用混合增强生成的所有数据集均优于未标记的ImgNet32数据集。 这凸显了混合图像用于知识蒸馏的优势，与来自外部来源的未标记数据相比，基于这些观察，我们将CIFAR-100上所有实验的混合数据集的大小设置为5×105。 </p>
<pre><code>     **α的影响：**如式2所示，α确定了混合图像中每个输入类别的存在的概率分布。 我们测量了相对于几个α值的蒸馏性能，以确定其最佳值。图6c和6d给出了这些实验的结果。 对于α→0，由于增强图像中仅出现一个输入类别，即r0 = 1或r1 = 1，因此混合增强无效。在这种情况下，蒸馏的性能与不进行增强的情况相同。 对于α→+∞，图像的贡献变得相等，即，r 0 ＝ r 1 ＝ 0.5。 这对于蒸馏更有利，因为两个输入图像均对混合图像贡献相等。 对于α= 1，从均匀分布Unif（0,1）中选择混合图像中每个输入的贡献。 这比α→+∞效果更好，因为不仅两个输入图像的特征都将出现在输出图像中，而且每个图像的特征数量将在混合图像之间随机变化。 根据这些评估，除非另有说明，否则所有实验的α= 3。 </code></pre>
<p>​         <strong>k的影响：</strong>我们通过在CIFAR-100和ImageNet数据集上进行实验来评估k的作用。 图6e，6f和6g给出了此评估的结果。 MixUp和CutMix的主要缺点是它们在没有任何监督的情况下混合图像。 这解释了使用这些扩增方法在所有k&gt; 2的实验中蒸馏性能的显着下降。 包含更多输入样本以生成混合图像会增加在CutMix中进行错误裁剪的机会，并会在Mixup中平均重叠的功能。 这两种事件都降低了混合图像中特征的质量和有效性，这也可以从图5中提供的视觉比较中观察到。但是，SuperMix通过考虑老师的监督来缓解此问题。 我们还观察到图像的空间大小可以限制。 如图6e和6f所示，由于对32×32空间大小的限制，SuperMix图像上的蒸馏性能会使CIFAR-100上的fork&gt; 2降级。 但是在ImageNet上，SuperMix = 3可获得最佳蒸馏性能。 </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\fig6.PNG)</p>
<p>​         <strong>蒙版之间的稀疏性：</strong>稀疏性促进损失会强制将输出图像中的每个空间位置分配给输入集中的一个图像。 通过在每个空间位置保留最重要的功能，可以提高混合性能。 为了验证这一点，我们在图6h中评估了蒸馏性能与λs的关系。 通过增加稀疏度的权重，蒸馏性能提高到λs≈25。 之后，由于稀疏性促进损失主导了KLloss，因此掩模的准确性降低。 图4通过可视化混合掩模与λs的关系评估了这种现象。</p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\fig4.PNG)</p>
</li>
<li><p><strong>执行时间</strong></p>
<p>​         我们计算SuperMix的执行时间，以进一步评估其有效性。 为此，为了比较，我们定义了两个基线。 对于第一个基线，我们使用SGD而不是Newton方法来优化蒙版设置。 第二个基准是没有SP的牛顿法。 因此，在两个基线上的优化都是在LSM = KL +λσLσ+λsLs上进行的。受先前显着性检测工作的启发[34]，我们将电视标准用于空间平滑度损失为：Ls = 1kWH∑i∑u∈Λ |。 |∇mi（u）|| 33。 根据实验观察，我们将λs= 250设置为SGD的学习率为0.1。 所有其他参数均设置为上一节中确定的值。 为了计算执行时间，所有算法都在批处理容量为128的两个NVIDA Titan RTX上进行了并行处理。图7c给出了这些比较的结果。 在两个数据集上，带SP的牛顿法（即SuperMix）至少比SGD快65倍。 而且，由于SP直接满足空间平滑条件，SuperMixis比没有SP的纯牛顿迭代法快至少19倍。 </p>
<p>![](C:\Users\12466\Pictures\paper\SuperMix Supervising the Mixing Data Augmentation\fig7.PNG)</p>
</li>
<li><p><strong>嵌入空间评估</strong></p>
<p>​         我们对CIFAR-100进行了两组评估，以分析混合图像的特征。 在第一组实验中，我们将原始数据和混合图像馈送到VGG13，并使用2D PCA对三个随机类将嵌入空间（即logits层之前的一层）可视化。 SuperVix图像是在VGG13的监督下以k = 2生成的。图7a演示了这些评估。 SuperMixdata的表示与原始数据的表示分布有较少的重叠。 这表明与原始数据，其他混合方法或外部来源的未标记数据相比，SuperMix数据包含更新颖的结构。 而且，由于表示集中在嵌入层的中心附近，因此SuperMix数据很难为模型分类。 为了更好地对此进行评估，我们为每个类计算表示形式的类标准偏差（c-std）。 计算值报告在图7a中相应图像的顶部。 </p>
<p>​         Hintonet等 [21]指出，模型的平滑概率预测可以更好地揭示其对任务的了解。 由于SuperMix通过组合多个输入来生成图像，因此与其他扩展类型的输出相比，SuperMixdata的模型输出本质上更加平滑。 我们通过计算CIFAR-100原始图像和增强图像上VGG13的排名前5位概率预测的平均值来验证这一点。 图7b给出了该评估的结果。 如图7b所示，目标模型的预测在混合图像上更加平滑。 而且，SuperMix产生的数据具有最平滑的概率。 </p>
</li>
</ol>
<h3 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h3><p>​         在本文中，我们研究了在老师的监督下进行数据增强混合多个图像的潜力。 我们提出了SuperMix，一种有监督的混合增强方法，该方法将多个图像组合在一起以生成丰富的数据。 SuperMix的有效性和效率通过广泛的实验和评估得到了验证。 我们证明了SuperMix显着改善了最新的知识蒸馏技术，并提供了与复杂的自动扩充方法相同的性能。 </p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/Paper/SuperMix%20Supervising%20the%20Mixing%20Data%20Augmentation/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Paper/SLOT-BASEDIMAGEAUGMENTATIONSYSTEM  FOROBJECTDETECTION" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="SLOT-BASEDIMAGEAUGMENTATIONSYSTEM-FOROBJECTDETECTION"><a href="#SLOT-BASEDIMAGEAUGMENTATIONSYSTEM-FOROBJECTDETECTION" class="headerlink" title="SLOT-BASEDIMAGEAUGMENTATIONSYSTEM  FOROBJECTDETECTION"></a>SLOT-BASEDIMAGEAUGMENTATIONSYSTEM  FOROBJECTDETECTION</h1><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li><h4 id="传统的数据增强方法（翻转、旋转、放缩）可能使会使目标检测的结果更差"><a href="#传统的数据增强方法（翻转、旋转、放缩）可能使会使目标检测的结果更差" class="headerlink" title="传统的数据增强方法（翻转、旋转、放缩）可能使会使目标检测的结果更差"></a>传统的数据增强方法（翻转、旋转、放缩）可能使会使目标检测的结果更差</h4></li>
<li><h4 id="原因："><a href="#原因：" class="headerlink" title="原因："></a>原因：</h4><ul>
<li><h4 id="目标检测与图像分类的检测特征不同。"><a href="#目标检测与图像分类的检测特征不同。" class="headerlink" title="目标检测与图像分类的检测特征不同。"></a>目标检测与图像分类的检测特征不同。</h4><ul>
<li><h4 id="后者仅需要检测目标对象的特征，而前者还需要位置与上下文特征"><a href="#后者仅需要检测目标对象的特征，而前者还需要位置与上下文特征" class="headerlink" title="后者仅需要检测目标对象的特征，而前者还需要位置与上下文特征"></a>后者仅需要检测目标对象的特征，而前者还需要位置与上下文特征</h4></li>
</ul>
</li>
<li><h4 id="且手动图像转换不能保证额外可学习的特征得到增加"><a href="#且手动图像转换不能保证额外可学习的特征得到增加" class="headerlink" title="且手动图像转换不能保证额外可学习的特征得到增加"></a>且手动图像转换不能保证额外可学习的特征得到增加</h4></li>
</ul>
</li>
</ul>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><ul>
<li><h4 id="基于插槽的图像增强方法（将前景与背景进行组合）"><a href="#基于插槽的图像增强方法（将前景与背景进行组合）" class="headerlink" title="基于插槽的图像增强方法（将前景与背景进行组合）"></a>基于插槽的图像增强方法（将前景与背景进行组合）</h4></li>
<li><h4 id="以预处理的方式实现，不需要训练"><a href="#以预处理的方式实现，不需要训练" class="headerlink" title="以预处理的方式实现，不需要训练"></a>以预处理的方式实现，不需要训练</h4></li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/Paper/SLOT-BASEDIMAGEAUGMENTATIONSYSTEM%20%20FOROBJECTDETECTION/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Paper/Simple Copy-Paste is a Strong Data Augmentation Methodfor Instance Segmentation" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <!--
 * @Author: your name
 * @Date: 2019-11-15 10:44:32
 * @LastEditTime: 2020-12-17 15:31:14
 * @LastEditors: Please set LastEditors
 * @Description: In User Settings Edit
 * @FilePath: \C++c:\Users\12466\Documents\笔记\论文阅读笔记\Simple Copy-Paste is a Strong Data Augmentation Methodfor Instance Segmentation.md
-->
<h1 id="Where-and-Who-Automatic-Semantic-Aware-Person-Composition"><a href="#Where-and-Who-Automatic-Semantic-Aware-Person-Composition" class="headerlink" title="Where and Who? Automatic Semantic-Aware Person Composition"></a>Where and Who? Automatic Semantic-Aware Person Composition</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul>
<li><h4 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h4><ul>
<li><h4 id="系统研究使用随机简单的copypaste方法对实力分割的影响"><a href="#系统研究使用随机简单的copypaste方法对实力分割的影响" class="headerlink" title="系统研究使用随机简单的copypaste方法对实力分割的影响"></a>系统研究使用随机简单的copypaste方法对实力分割的影响</h4></li>
<li><h4 id="在coco分割数据集上，实现49-1-maskAP与57-3-boxAP"><a href="#在coco分割数据集上，实现49-1-maskAP与57-3-boxAP" class="headerlink" title="在coco分割数据集上，实现49.1 maskAP与57.3 boxAP"></a>在coco分割数据集上，实现49.1 maskAP与57.3 boxAP</h4></li>
<li><h4 id="研究copypaste对LVIS-benchmark的影响；在稀有类别上，超过3-6-maskAP"><a href="#研究copypaste对LVIS-benchmark的影响；在稀有类别上，超过3-6-maskAP" class="headerlink" title="研究copypaste对LVIS benchmark的影响；在稀有类别上，超过3.6 maskAP"></a>研究copypaste对LVIS benchmark的影响；在稀有类别上，超过3.6 maskAP</h4></li>
</ul>
</li>
<li><h4 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h4><ul>
<li><h4 id="we-show-Copy-Paste-is-additive-withsemi-supervised-methods-that-leverage-extra-data-through-pseudo-labeling-e-g-self-training"><a href="#we-show-Copy-Paste-is-additive-withsemi-supervised-methods-that-leverage-extra-data-through-pseudo-labeling-e-g-self-training" class="headerlink" title="we show Copy-Paste is additive withsemi-supervised methods that leverage extra data through pseudo  labeling  (e.g.  self-training)"></a>we show Copy-Paste is additive withsemi-supervised methods that leverage extra data through pseudo  labeling  (e.g.  self-training)</h4></li>
<li><h4 id="LVIS-benchmark"><a href="#LVIS-benchmark" class="headerlink" title="LVIS benchmark"></a>LVIS benchmark</h4><ul>
<li>Facebook 实例分割的数据。包含了用于训练以及验证的 82k 图像中的 1230 个对象类别，注释有超过 700k 的分割掩码。</li>
<li></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><ul>
<li><h4 id="主要内容-1"><a href="#主要内容-1" class="headerlink" title="主要内容"></a>主要内容</h4><ul>
<li><h4 id="实例分割模型（Spinenet、Effientnet、resnest）数据饥渴"><a href="#实例分割模型（Spinenet、Effientnet、resnest）数据饥渴" class="headerlink" title="实例分割模型（Spinenet、Effientnet、resnest）数据饥渴"></a>实例分割模型（Spinenet、Effientnet、resnest）数据饥渴</h4></li>
<li><h4 id="标注时长久：coco中1000个实例分割标注需要22个小时"><a href="#标注时长久：coco中1000个实例分割标注需要22个小时" class="headerlink" title="标注时长久：coco中1000个实例分割标注需要22个小时"></a>标注时长久：coco中1000个实例分割标注需要22个小时</h4></li>
<li><h4 id="为目前新模型设计高效的数据标注方法"><a href="#为目前新模型设计高效的数据标注方法" class="headerlink" title="为目前新模型设计高效的数据标注方法"></a>为目前新模型设计高效的数据标注方法</h4></li>
<li><h4 id="已有一些数据增强方法，如scale-jittering，random-resize方法，但这些方法并不是专门应用于实例分割的，如果数据增强是更加关注目标实例本身（object-aware），比如形状或类别，这对于实力分割任务将更有意义。这是copypaste能够做到的，其能够将各种尺度的实例粘贴增强"><a href="#已有一些数据增强方法，如scale-jittering，random-resize方法，但这些方法并不是专门应用于实例分割的，如果数据增强是更加关注目标实例本身（object-aware），比如形状或类别，这对于实力分割任务将更有意义。这是copypaste能够做到的，其能够将各种尺度的实例粘贴增强" class="headerlink" title="已有一些数据增强方法，如scale jittering，random resize方法，但这些方法并不是专门应用于实例分割的，如果数据增强是更加关注目标实例本身（object-aware），比如形状或类别，这对于实力分割任务将更有意义。这是copypaste能够做到的，其能够将各种尺度的实例粘贴增强"></a>已有一些数据增强方法，如scale jittering，random resize方法，但这些方法并不是专门应用于实例分割的，如果数据增强是更加关注目标实例本身（object-aware），比如形状或类别，这对于实力分割任务将更有意义。这是copypaste能够做到的，其能够将各种尺度的实例粘贴增强</h4></li>
<li><h4 id="多种组合的增强图像：源图像与目标图像的多种选择，源图像各个实例的选择，目标图像中粘贴位置的选择"><a href="#多种组合的增强图像：源图像与目标图像的多种选择，源图像各个实例的选择，目标图像中粘贴位置的选择" class="headerlink" title="多种组合的增强图像：源图像与目标图像的多种选择，源图像各个实例的选择，目标图像中粘贴位置的选择"></a>多种组合的增强图像：源图像与目标图像的多种选择，源图像各个实例的选择，目标图像中粘贴位置的选择</h4></li>
<li><h4 id="该文章就是探索如何从这么多种选择中找出最优的增强方式"><a href="#该文章就是探索如何从这么多种选择中找出最优的增强方式" class="headerlink" title="该文章就是探索如何从这么多种选择中找出最优的增强方式"></a>该文章就是探索如何从这么多种选择中找出最优的增强方式</h4></li>
<li><h4 id="之前工作的视觉上下文约束不见得奏效，反而通过多种设置，随机选择位置粘贴起到提升效果。具体而言，它在各种设置上都提供了扎实的改进，包括主干架构的可变性，尺度抖动的程度，训练计划和图像大小。"><a href="#之前工作的视觉上下文约束不见得奏效，反而通过多种设置，随机选择位置粘贴起到提升效果。具体而言，它在各种设置上都提供了扎实的改进，包括主干架构的可变性，尺度抖动的程度，训练计划和图像大小。" class="headerlink" title="之前工作的视觉上下文约束不见得奏效，反而通过多种设置，随机选择位置粘贴起到提升效果。具体而言，它在各种设置上都提供了扎实的改进，包括主干架构的可变性，尺度抖动的程度，训练计划和图像大小。"></a>之前工作的视觉上下文约束不见得奏效，反而通过多种设置，随机选择位置粘贴起到提升效果。具体而言，它在各种设置上都提供了扎实的改进，包括主干架构的可变性，尺度抖动的程度，训练计划和图像大小。</h4></li>
<li><h4 id="配合large-scale-jittering，copypaste方法能够在少量数据（10-）上提高10个点，在大量数据基础上提高5个点。（-Mask-R-CNN-EfficientNet-B7-FPN-trained-on-an-image-size-of-640×640）"><a href="#配合large-scale-jittering，copypaste方法能够在少量数据（10-）上提高10个点，在大量数据基础上提高5个点。（-Mask-R-CNN-EfficientNet-B7-FPN-trained-on-an-image-size-of-640×640）" class="headerlink" title="配合large scale jittering，copypaste方法能够在少量数据（10%）上提高10个点，在大量数据基础上提高5个点。（ Mask R-CNN EfficientNet-B7 FPN trained on an image size of 640×640）"></a>配合large scale jittering，copypaste方法能够在少量数据（10%）上提高10个点，在大量数据基础上提高5个点。（ Mask R-CNN EfficientNet-B7 FPN trained on an image size of 640×640）</h4></li>
<li><h4 id="复制粘贴增强策略通过自训练提供了额外的好处；从真实数据中提取实例，并将其粘贴到带有伪标签的未标记数据中。"><a href="#复制粘贴增强策略通过自训练提供了额外的好处；从真实数据中提取实例，并将其粘贴到带有伪标签的未标记数据中。" class="headerlink" title="复制粘贴增强策略通过自训练提供了额外的好处；从真实数据中提取实例，并将其粘贴到带有伪标签的未标记数据中。"></a>复制粘贴增强策略通过自训练提供了额外的好处；从真实数据中提取实例，并将其粘贴到带有伪标签的未标记数据中。</h4></li>
<li><h4 id="在分割任务上多个模型的提高，在目标检测任务上多个模型的提高，以及在LVIS测试基准上经常使用的两阶段模型上的分割效果提升（常见类3-7，稀有类6-1）"><a href="#在分割任务上多个模型的提高，在目标检测任务上多个模型的提高，以及在LVIS测试基准上经常使用的两阶段模型上的分割效果提升（常见类3-7，稀有类6-1）" class="headerlink" title="在分割任务上多个模型的提高，在目标检测任务上多个模型的提高，以及在LVIS测试基准上经常使用的两阶段模型上的分割效果提升（常见类3.7，稀有类6.1）"></a>在分割任务上多个模型的提高，在目标检测任务上多个模型的提高，以及在LVIS测试基准上经常使用的两阶段模型上的分割效果提升（常见类3.7，稀有类6.1）</h4></li>
<li><h4 id="适用于多数模型，可以有效利用未标注数据，不会带来训练或测试的计算开销。"><a href="#适用于多数模型，可以有效利用未标注数据，不会带来训练或测试的计算开销。" class="headerlink" title="适用于多数模型，可以有效利用未标注数据，不会带来训练或测试的计算开销。"></a>适用于多数模型，可以有效利用未标注数据，不会带来训练或测试的计算开销。</h4></li>
<li><h4 id="通过将feature-learning和rebalancing分开来进行两阶段训练策略的有效性，因为以重平衡训练结束的端到端训练不利于特征学习"><a href="#通过将feature-learning和rebalancing分开来进行两阶段训练策略的有效性，因为以重平衡训练结束的端到端训练不利于特征学习" class="headerlink" title="通过将feature learning和rebalancing分开来进行两阶段训练策略的有效性，因为以重平衡训练结束的端到端训练不利于特征学习"></a>通过将feature learning和rebalancing分开来进行两阶段训练策略的有效性，因为以重平衡训练结束的端到端训练不利于特征学习</h4></li>
</ul>
</li>
<li><h4 id="主要内容-2"><a href="#主要内容-2" class="headerlink" title="主要内容"></a>主要内容</h4><ul>
<li><h4 id="自训练"><a href="#自训练" class="headerlink" title="自训练"></a>自训练</h4></li>
</ul>
</li>
</ul>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><ul>
<li><h4 id="主要内容-3"><a href="#主要内容-3" class="headerlink" title="主要内容"></a>主要内容</h4><ul>
<li><h4 id="数据增强工作在视觉领域关注度低"><a href="#数据增强工作在视觉领域关注度低" class="headerlink" title="数据增强工作在视觉领域关注度低"></a>数据增强工作在视觉领域关注度低</h4></li>
<li><h4 id="随即裁剪、颜色抖动、自动增强等数据增强方法是比较通用的，且用于数据变换不变性编码"><a href="#随即裁剪、颜色抖动、自动增强等数据增强方法是比较通用的，且用于数据变换不变性编码" class="headerlink" title="随即裁剪、颜色抖动、自动增强等数据增强方法是比较通用的，且用于数据变换不变性编码"></a>随即裁剪、颜色抖动、自动增强等数据增强方法是比较通用的，且用于数据变换不变性编码</h4></li>
<li><h4 id="混合图像增强：不关注实例本身，难以用于实力分割"><a href="#混合图像增强：不关注实例本身，难以用于实力分割" class="headerlink" title="混合图像增强：不关注实例本身，难以用于实力分割"></a>混合图像增强：不关注实例本身，难以用于实力分割</h4></li>
<li><h4 id="复制粘贴增强：本文与之不同的是（1）没有使用几何变换；高斯模糊没有用；（2）本文在将一幅图像中包含的对象粘贴到已经填充有实例的另一幅图像的背景下研究复制粘贴。而-13-在拥有一堆对象实例和背景场景的情况下研究复制粘贴以提高性能；（3）通过结合自我训练，我们研究了复制粘贴在半监督学习环境中的功效；数据集不同-前者用COCO-and-LVIS，后者GMU。"><a href="#复制粘贴增强：本文与之不同的是（1）没有使用几何变换；高斯模糊没有用；（2）本文在将一幅图像中包含的对象粘贴到已经填充有实例的另一幅图像的背景下研究复制粘贴。而-13-在拥有一堆对象实例和背景场景的情况下研究复制粘贴以提高性能；（3）通过结合自我训练，我们研究了复制粘贴在半监督学习环境中的功效；数据集不同-前者用COCO-and-LVIS，后者GMU。" class="headerlink" title="复制粘贴增强：本文与之不同的是（1）没有使用几何变换；高斯模糊没有用；（2）本文在将一幅图像中包含的对象粘贴到已经填充有实例的另一幅图像的背景下研究复制粘贴。而[13]在拥有一堆对象实例和背景场景的情况下研究复制粘贴以提高性能；（3）通过结合自我训练，我们研究了复制粘贴在半监督学习环境中的功效；数据集不同,前者用COCO and LVIS，后者GMU。"></a>复制粘贴增强：本文与之不同的是（1）没有使用几何变换；高斯模糊没有用；（2）本文在将一幅图像中包含的对象粘贴到已经填充有实例的另一幅图像的背景下研究复制粘贴。而[13]在拥有一堆对象实例和背景场景的情况下研究复制粘贴以提高性能；（3）通过结合自我训练，我们研究了复制粘贴在半监督学习环境中的功效；数据集不同,前者用COCO and LVIS，后者GMU。</h4></li>
<li><h4 id="实例分割：v"><a href="#实例分割：v" class="headerlink" title="实例分割：v"></a>实例分割：v</h4></li>
<li><h4 id="长尾分布识别：对长尾分布的关注；现在解决长尾分布问题的主要方法分两类：重采样与loss-reweighting，长尾分布其他方法：元学习、因果推理、贝叶斯方法；我们的工作表明，在LVIS基准测试的单阶段和两阶段训练中，简单的复制粘贴数据增强都会产生明显的收益，尤其是对于稀有物体类别而言。"><a href="#长尾分布识别：对长尾分布的关注；现在解决长尾分布问题的主要方法分两类：重采样与loss-reweighting，长尾分布其他方法：元学习、因果推理、贝叶斯方法；我们的工作表明，在LVIS基准测试的单阶段和两阶段训练中，简单的复制粘贴数据增强都会产生明显的收益，尤其是对于稀有物体类别而言。" class="headerlink" title="长尾分布识别：对长尾分布的关注；现在解决长尾分布问题的主要方法分两类：重采样与loss reweighting，长尾分布其他方法：元学习、因果推理、贝叶斯方法；我们的工作表明，在LVIS基准测试的单阶段和两阶段训练中，简单的复制粘贴数据增强都会产生明显的收益，尤其是对于稀有物体类别而言。"></a>长尾分布识别：对长尾分布的关注；现在解决长尾分布问题的主要方法分两类：重采样与loss reweighting，长尾分布其他方法：元学习、因果推理、贝叶斯方法；我们的工作表明，在LVIS基准测试的单阶段和两阶段训练中，简单的复制粘贴数据增强都会产生明显的收益，尤其是对于稀有物体类别而言。</h4></li>
</ul>
</li>
<li><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><ul>
<li><h4 id="数据变换不变性编码"><a href="#数据变换不变性编码" class="headerlink" title="数据变换不变性编码"></a>数据变换不变性编码</h4></li>
<li><h4 id="A-classic-example-is-the-mixup-dataaugmentation-65-method-which-creates-new-data-pointsfor-free-from-convex-combinations-of-the-input-pixels-andthe-output-labels"><a href="#A-classic-example-is-the-mixup-dataaugmentation-65-method-which-creates-new-data-pointsfor-free-from-convex-combinations-of-the-input-pixels-andthe-output-labels" class="headerlink" title="A  classic  example  is  the  mixup  dataaugmentation  [65]  method  which  creates  new  data  pointsfor free from convex combinations of the input pixels andthe  output  labels."></a>A  classic  example  is  the  mixup  dataaugmentation  [65]  method  which  creates  new  data  pointsfor free from convex combinations of the input pixels andthe  output  labels.</h4></li>
<li><h4 id="本文在将一幅图像中包含的对象粘贴到已经填充有实例的另一幅图像的背景下研究复制粘贴。而-13-在拥有一堆对象实例和背景场景的情况下研究复制粘贴以提高性能"><a href="#本文在将一幅图像中包含的对象粘贴到已经填充有实例的另一幅图像的背景下研究复制粘贴。而-13-在拥有一堆对象实例和背景场景的情况下研究复制粘贴以提高性能" class="headerlink" title="本文在将一幅图像中包含的对象粘贴到已经填充有实例的另一幅图像的背景下研究复制粘贴。而[13]在拥有一堆对象实例和背景场景的情况下研究复制粘贴以提高性能"></a>本文在将一幅图像中包含的对象粘贴到已经填充有实例的另一幅图像的背景下研究复制粘贴。而[13]在拥有一堆对象实例和背景场景的情况下研究复制粘贴以提高性能</h4></li>
<li><h4 id="loss-reweighting：在训练过程的每一轮中，可根据样本分布为每个训练样本重新赋予权重。"><a href="#loss-reweighting：在训练过程的每一轮中，可根据样本分布为每个训练样本重新赋予权重。" class="headerlink" title="loss reweighting：在训练过程的每一轮中，可根据样本分布为每个训练样本重新赋予权重。"></a>loss reweighting：在训练过程的每一轮中，可根据样本分布为每个训练样本重新赋予权重。</h4></li>
</ul>
</li>
</ul>
<h2 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h2><ul>
<li><h4 id="主要内容："><a href="#主要内容：" class="headerlink" title="主要内容："></a>主要内容：</h4><ul>
<li><h4 id="随机选择两张图像；随机尺度抖动、随机水平翻转；选择其中一个图像中的部分实例进行粘贴；对标签进行调整：对于实例分割任务，移除掉完全被遮挡的实例掩码，对于目标检测任务，移除部分遮挡的实例标注"><a href="#随机选择两张图像；随机尺度抖动、随机水平翻转；选择其中一个图像中的部分实例进行粘贴；对标签进行调整：对于实例分割任务，移除掉完全被遮挡的实例掩码，对于目标检测任务，移除部分遮挡的实例标注" class="headerlink" title="随机选择两张图像；随机尺度抖动、随机水平翻转；选择其中一个图像中的部分实例进行粘贴；对标签进行调整：对于实例分割任务，移除掉完全被遮挡的实例掩码，对于目标检测任务，移除部分遮挡的实例标注"></a>随机选择两张图像；随机尺度抖动、随机水平翻转；选择其中一个图像中的部分实例进行粘贴；对标签进行调整：对于实例分割任务，移除掉完全被遮挡的实例掩码，对于目标检测任务，移除部分遮挡的实例标注</h4></li>
<li><h4 id="没有对周围的文本进行建模，因此生成的图像与真实的图像在同时出现对象或对象的相关尺度方面有很大的差异"><a href="#没有对周围的文本进行建模，因此生成的图像与真实的图像在同时出现对象或对象的相关尺度方面有很大的差异" class="headerlink" title="没有对周围的文本进行建模，因此生成的图像与真实的图像在同时出现对象或对象的相关尺度方面有很大的差异"></a>没有对周围的文本进行建模，因此生成的图像与真实的图像在同时出现对象或对象的相关尺度方面有很大的差异</h4></li>
<li><h4 id="将目标混合进图像：加不加模糊影响不大"><a href="#将目标混合进图像：加不加模糊影响不大" class="headerlink" title="将目标混合进图像：加不加模糊影响不大"></a>将目标混合进图像：加不加模糊影响不大</h4></li>
<li><h4 id="尺度抖动：标准尺度抖动（0-8-1-25）与large-scale-jittering-0-1-2-0"><a href="#尺度抖动：标准尺度抖动（0-8-1-25）与large-scale-jittering-0-1-2-0" class="headerlink" title="尺度抖动：标准尺度抖动（0.8-1.25）与large scale jittering(0.1-2.0)"></a>尺度抖动：标准尺度抖动（0.8-1.25）与large scale jittering(0.1-2.0)</h4></li>
<li><h4 id="除了研究监督数据上的复制粘贴，也尝试将其与其他未标记的图像合并下的自训练复制粘贴实验"><a href="#除了研究监督数据上的复制粘贴，也尝试将其与其他未标记的图像合并下的自训练复制粘贴实验" class="headerlink" title="除了研究监督数据上的复制粘贴，也尝试将其与其他未标记的图像合并下的自训练复制粘贴实验"></a>除了研究监督数据上的复制粘贴，也尝试将其与其他未标记的图像合并下的自训练复制粘贴实验</h4></li>
<li><h4 id="自训练步骤：先基于已标注数据训练一个模型；利用该模型在未标注数据上生成伪标签数据；将真实标签实例粘贴在具有伪标签的图像上，结合真实标注数据一起再训练一个模型"><a href="#自训练步骤：先基于已标注数据训练一个模型；利用该模型在未标注数据上生成伪标签数据；将真实标签实例粘贴在具有伪标签的图像上，结合真实标注数据一起再训练一个模型" class="headerlink" title="自训练步骤：先基于已标注数据训练一个模型；利用该模型在未标注数据上生成伪标签数据；将真实标签实例粘贴在具有伪标签的图像上，结合真实标注数据一起再训练一个模型"></a>自训练步骤：先基于已标注数据训练一个模型；利用该模型在未标注数据上生成伪标签数据；将真实标签实例粘贴在具有伪标签的图像上，结合真实标注数据一起再训练一个模型</h4></li>
</ul>
</li>
<li></li>
<li><h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h4><ul>
<li><h4 id="scale-jittering：简单来说，就是crop-size是固定的，而image-size是随机可变的。举例来说，比如把crop-size固定在224×224，而image的短边可以按比例缩放到-256-480-区间的某个随机数值，然后随机偏移裁剪个224×224的图像区域。"><a href="#scale-jittering：简单来说，就是crop-size是固定的，而image-size是随机可变的。举例来说，比如把crop-size固定在224×224，而image的短边可以按比例缩放到-256-480-区间的某个随机数值，然后随机偏移裁剪个224×224的图像区域。" class="headerlink" title="scale jittering：简单来说，就是crop size是固定的，而image size是随机可变的。举例来说，比如把crop size固定在224×224，而image的短边可以按比例缩放到[256, 480]区间的某个随机数值，然后随机偏移裁剪个224×224的图像区域。"></a>scale jittering：简单来说，就是crop size是固定的，而image size是随机可变的。举例来说，比如把crop size固定在224×224，而image的短边可以按比例缩放到[256, 480]区间的某个随机数值，然后随机偏移裁剪个224×224的图像区域。</h4></li>
</ul>
</li>
</ul>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><ul>
<li><h4 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h4><ul>
<li><p>网络结构：我们使用Efficient-Net [55]或ResNet [27]作为主干架构的Mask R-CNN [26]。 我们还采用特征金字塔网络[38]进行多尺度特征融合。 我们使用从P2到P6的金字塔等级，锚点大小为8×2，每个像素3个锚点。 我们最强的模型使用Cascade R-CNN [2]，EfficientNet-B7作为骨干网和NAS-FPN [17]作为功能金字塔，级别从P3到P7。 锚点大小为4×2，每个像素有9个锚点。 我们的NAS-FPN模型使用5次重复，我们用ResNet bot-tleneck块替换了卷积层[27]</p>
</li>
<li><p>训练参数：所有模型都使用同步批标准化，batchsize是256，权重衰减为0.00004,使用0.32的学习率和逐步学习率衰减,前1000步学习率从0.0032增加到0.32，在总训练步数的0.9、0.95和0.975处衰减学习率；从一个经过自我训练的ImageNet检查点初始化我们最大模型的主干，以加快训练速度；除非另有说明，否则所有其他结果均来自具有随机初始化的模型；除非另有说明，否则使用大规模抖动增强来训练模型；在我们的实验中，对于所有不同的增强和数据集大小，我们允许每个模型进行训练直到它收敛（即，验证集的性能不再提高）；例如，使用大规模抖动和“复制粘贴”增强从头开始训练模型需要576个epoch，而仅使用标准规模抖动进行训练需要96个epoch。 对于自训练实验，我们将批处理大小增加一倍，达到512，而其他所有超参数保持相同，但最大的模型除外，由于内存限制，我们将批处理大小保持为256。</p>
</li>
<li><p>数据集：正常标注数据集使用11.8万张图像的coco数据集，对于自训练使用12万张未标注coco数据集与Ob-jects365（61万张）作为未标注数据集；对于迁移学习实验，在coco上预训练，在pascalvoc上finetune；对于语义分割实验，在PASCAL VOC2012 segmentation dataset的训练集上训练（1500张）；对于目标检测，在voc07、12训练集上训练；还在LVIS v1.0（100k训练图像）上对复制粘贴进行基准测试，并在LVIS v1.0val（20k图像）上报告结果。 LVIS有1203个类别可以模拟自然图像中类别的长尾分布。</p>
</li>
</ul>
</li>
<li><h4 id="copypaste对于各种训练设置都是健壮的："><a href="#copypaste对于各种训练设置都是健壮的：" class="headerlink" title="copypaste对于各种训练设置都是健壮的："></a>copypaste对于各种训练设置都是健壮的：</h4><ul>
<li><p>对于backbone初始化的鲁棒性：</p>
</li>
<li><p>对于训练schedules的鲁棒性：</p>
</li>
<li><p>能够提高large scale jittering的效果：</p>
</li>
<li><p>使用适用于各种backbone与图像大小：</p>
</li>
</ul>
</li>
<li><h4 id="copypaste有助于提高数据效率"><a href="#copypaste有助于提高数据效率" class="headerlink" title="copypaste有助于提高数据效率:"></a>copypaste有助于提高数据效率:</h4></li>
<li><h4 id="copypaste能够提高自训练的效果："><a href="#copypaste能够提高自训练的效果：" class="headerlink" title="copypaste能够提高自训练的效果："></a>copypaste能够提高自训练的效果：</h4></li>
<li><h4 id="copypaste提高了coco的tate-of-the-art："><a href="#copypaste提高了coco的tate-of-the-art：" class="headerlink" title="copypaste提高了coco的tate-of-the-art："></a>copypaste提高了coco的tate-of-the-art：</h4></li>
<li><h4 id="copypaste可以产生更好的pascal检测和分割表示："><a href="#copypaste可以产生更好的pascal检测和分割表示：" class="headerlink" title="copypaste可以产生更好的pascal检测和分割表示："></a>copypaste可以产生更好的pascal检测和分割表示：</h4></li>
<li><h4 id="copypaste可大大提高LVIS的价值："><a href="#copypaste可大大提高LVIS的价值：" class="headerlink" title="copypaste可大大提高LVIS的价值："></a>copypaste可大大提高LVIS的价值：</h4><ul>
<li>提高single-stage  LVIS的训练：</li>
<li>提高 two-stage  LVIS的训练：</li>
<li>与state of the art比较：</li>
</ul>
</li>
<li><h4 id="copypaste消融实验"><a href="#copypaste消融实验" class="headerlink" title="copypaste消融实验"></a>copypaste消融实验</h4></li>
<li><h4 id="copypaste可为COCO的较难分类提供更多收益"><a href="#copypaste可为COCO的较难分类提供更多收益" class="headerlink" title="copypaste可为COCO的较难分类提供更多收益"></a>copypaste可为COCO的较难分类提供更多收益</h4></li>
<li><h4 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h4><ul>
<li><h4 id="mixup与cutmix在目标检测中应用的论文：Bag-of-freebies-for-training-object-de-tection-neural-networks"><a href="#mixup与cutmix在目标检测中应用的论文：Bag-of-freebies-for-training-object-de-tection-neural-networks" class="headerlink" title="mixup与cutmix在目标检测中应用的论文：Bag of freebies for training object de-tection neural networks"></a>mixup与cutmix在目标检测中应用的论文：Bag of freebies for training object de-tection neural networks</h4></li>
<li><h4 id="数据不平衡论文："><a href="#数据不平衡论文：" class="headerlink" title="数据不平衡论文："></a>数据不平衡论文：</h4></li>
<li>Learning imbalanced datasets with label-distribution-aware margin loss</li>
<li>Bbn:  Bilateral-branch network with cumulative learning for long-tailed visual recognition. InCVPR, 2020</li>
<li>Decoupling  representation  and  classifier  for  long-tailed  recognition. InICLR, 2020 </li>
<li>Overcoming classifier im-balance  for  long-tail  object  detection  with  balanced  group softmax. InCVPR, 2020</li>
<li>Imbalance  problems  in  object  detection:   A  review.TPAMI, 2020</li>
</ul>
</li>
<li><h4 id="类平衡损失论文：Class-balanced-loss-based-on-effective-number-of-samples"><a href="#类平衡损失论文：Class-balanced-loss-based-on-effective-number-of-samples" class="headerlink" title="类平衡损失论文：Class-balanced loss based on effective number of samples"></a>类平衡损失论文：Class-balanced loss based on effective number of samples</h4></li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/Paper/Simple%20Copy-Paste%20is%20a%20Strong%20Data%20Augmentation%20Methodfor%20Instance%20Segmentation/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Paper/Semantic Image Synthesis with Spatially-Adaptive Normalization" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Semantic-Image-Synthesis-with-Spatially-Adaptive-Normalization"><a href="#Semantic-Image-Synthesis-with-Spatially-Adaptive-Normalization" class="headerlink" title="Semantic Image Synthesis with Spatially-Adaptive Normalization"></a>Semantic Image Synthesis with Spatially-Adaptive Normalization</h1><h2 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h2><ul>
<li>条件图像合成（语义图像到真实图像转换）</li>
</ul>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li>归一化层带来的语义信息丢失</li>
</ul>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><ul>
<li>在归一化层中，通过空间自适应、学习变换，调整其中的激活函数，使得语义信息可以贯穿整个网络</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>A. Brock, J. Donahue, and K. Simonyan.   Large scale gantraining for high fidelity natural image synthesis.   InInter-national  Conference  on  Learning  Representations  (ICLR)</li>
<li>Q. Chen and V. Koltun.  Photographic image synthesis withcascaded refinement networks.  InIEEE International Con-ference on Computer Vision (ICCV）</li>
<li>H. Zhang, T. Xu, H. Li, S. Zhang, X. Huang, X. Wang, andD. Metaxas. Stackgan: Text to photo-realistic image synthe-sis with stacked generative adversarial networks.   InIEEEInternational Conference on Computer Vision (ICCV)</li>
<li>H.  Zhang,  T.  Xu,  H.  Li,  S.  Zhang,  X.  Wang,  X.  Huang,and  D.  Metaxas.    Stackgan++:   Realistic  image  synthesiswith stacked generative adversarial networks.IEEE Transac-tions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/Paper/Semantic%20Image%20Synthesis%20with%20Spatially-Adaptive%20Normalization/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Paper/Perceptual Generative Adversarial Networks for Small Object Detection" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <hr>
<h1 id="Perceptual-Generative-Adversarial-Networks-for-Small-Object-Detection"><a href="#Perceptual-Generative-Adversarial-Networks-for-Small-Object-Detection" class="headerlink" title="Perceptual Generative Adversarial Networks for Small Object Detection"></a>Perceptual Generative Adversarial Networks for Small Object Detection</h1><hr>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p> 由于小目标的低分辨率和嘈杂的表征，因此检测小目标非常困难。 现有的目标检测管道通常通过在多尺度上学习所有目标的表征来检测小目标。 但是，这种特殊架构的性能提升通常受限于要花费大量的计算开销。 在这项工作中，我们通过**<del>开发单个体系结构（single architecture）</del>**来解决小目标检测问题，该体系结构将小目标的表示内</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">怎么理解？？</span><br><span class="line">个人理解：单个体系结构是区别于类似snipper的三种尺度结构</span><br></pre></td></tr></table></figure>

<p>部提升为“超分辨”目标，实现了与大目标相似的特性，因此更具判别性。 为此，我们提出了一种新的感知生成对抗网络（Perceptual GAN）模型，该模型通过**<del>缩小小目标与大目标之间的表征差异</del><strong>来改善小目标检测。 具体来说，它的生成器学会了</strong><del>将感知到的小目标的较差表征转换为与真实大目标相似的超分辨目标</del>**，以欺骗竞争的判别者。 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">生成器的主要任务</span><br></pre></td></tr></table></figure>

<p>同时，它的鉴别器与生成器竞争，以识别生成的表示形式，并在生成器上施加附加的感知要求-生成的小目标表示形式必须对检测目的有利。 对具有挑战性的清华腾讯100K [45]和加州理工学院[9]基准进行的广泛评估充分证明了Perceptual GAN在检测小目标（包括交通标志和行人）方面优于已建立的最新技术。 </p>
<h3 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h3><p> 深度学习管道可从**<del>目标区域（RoI）</del>**中学习深度表征，并根据所学习的表征进行分类，例如Fast R-CNN [11]和</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ROI的作用及输入输出是什么？？？？</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Faster R-CNN，这刺激了目标检测领域的最新进展 [32]。 这些管道实际上在具有高分辨率，清晰外观和结构的大型目标上可以很好地工作，从中可以辨别特征。 但是它们通常无法检测到非常小的物体，因为很难从劣质的外观和结构中学习丰富的表示，如图1所示。但是，在现实世界中，例如交通标志检测，行人检测等高级应用中，微小的物体都是非常普遍的。 自动驾驶：小目标检测比正常物体检测更具挑战性，到目前为止，好的解决方案仍然很少。</p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\fig1.PNG)</p>
<p>​         一些努力[4、25、18、39、23、1]已致力于解决小目标检测问题。 一种常见的做法[4，25]是增加输入图像的尺度，以增强小目标的分辨率并生成高分辨率的特征图。 其他一些人[39，23，1]则专注于开发网络变体以生成多尺度表示，从而增强了具有多个低层特征层的高层小尺度特征。 但是，所有这些方法都试图通过数据增强或天真的增加特征尺寸来增强小目标检测的性能。 <strong><del>简单地增加输入图像的比尺度通常会导致训练和测试花费大量时间</del>**。 此外，</strong><del>由低级特征构成的多尺度表示就像黑匣子一样工作，不能保证所构造的特征对于目标检测而言是可交互的和可区分的</del><strong>。 在这项工作中，我们认为有效表示小目标的一种更好的方法是发现<font color=red></strong><del>每个类别的小规模目标与大规模目标之间的固有结构相关性</del>**</font>，然后使用转换后的表示形式以更智能的方式提高网络能力。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">以往的两种解决小尺度目标检测的方法及局限性：</span><br><span class="line">1、增加输入图像的尺度：增加训练与测试时间</span><br><span class="line">2、由多个底层特征构造而成的高层多尺度表征：不能保证构造的特征  可交互可区分的？？</span><br><span class="line"></span><br><span class="line">这里的目的就是找到小目标特征与大目标特征的映射，所以需要成对的大小目标，这里的大小目标是内容完全相同，分表率一大一小的两个目标吗，还是只是类别相同的一大一小两个目标？？（趋向于后者）</span><br></pre></td></tr></table></figure>

<p>​         因此，我们提出了一种新颖的感知生成对抗网络（Perceptual GAN），以生成用于小目标的超分辨表示，以便进行更好的检测。 感知GAN旨在通过在网络学习过程中**<del>充分利用不同尺度目标之间的结构相关性</del><strong>，将小目标的表示与大目标的表示进行增强。 它由两个子网络组成，即，生成器网络和感知鉴别器网络。 具体而言，生成器是一种基于深度残差的深度特征生成模型，该模型通过从较低层引入细粒度的细节将小目标的原始不良特征转化为高度区分性特征，从而在中间表示上实现“超分辨率”。 鉴别器网络充当监督者，并为生成的细粒度细节的质量和优势提供指导。与原始GAN不同，在鉴别器中，鉴别器仅受过训练以区分假冒和真实表示，我们提出的感知GAN包括</strong><del>新的感知损失</del>** 为检测目的量身定制。 即，对判别器网络进行训练，不仅要区分生成的小目标的超分辨表示和原始</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">与传统鉴别器网络的区别：加入了新的感知损失，用于保证生成的超分辨率特征有益于目标检测精度的提升</span><br></pre></td></tr></table></figure>

<p>的、具有对抗性损失的真实大目标的表示，而且要证明检测精度得益于生成的超分辨特征 有感觉上的损失。</p>
<p>​         我们以另一种方式优化了生成器和鉴别器网络的参数，以解决最小-最大问题。 特别地，训练生成器网络的目的是通过从小目标生成最大的物体（如最大物体）表示来欺骗鉴别器，并提高检测精度。 另一方面，对鉴别器进行了训练，以提高其区分能力，以正确地区分生成的超分辨表示和来自大型物体的超分辨表示，并且还向生成器提供有关本地化精度的反馈。 通过这两个网络之间的竞争，有效地训练了生成器，以将小目标的表示增强为能够提供高检测精度的超分辨目标。 </p>
<p>​         综上所述，这项工作做出了以下贡献。 （1）我们是第一个成功应用GAN相似模型来解决具有挑战性的小尺度目标检测问题的人。 （2）我们引入了一个新的条件生成器模型，**<del>该模型学习大型和小型目标之间的加性残差表示，而不是像以前那样生成完整的表示。</del>** （3）我们引入了一种新的感知鉴别器，该鉴别器提供了更全面的监督，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">什么叫小目标与大目标之间的加性残差表征？？？？</span><br></pre></td></tr></table></figure>

<p>有助于进行检测，而不是仅仅区分假冒和真实的鉴别器。 （4）交通标志检测和行人检测的成功应用已经实现了最先进的性能。 </p>
<h3 id="二、引言"><a href="#二、引言" class="headerlink" title="二、引言"></a>二、引言</h3><ol>
<li><p>小目标检测</p>
<p> <strong>交通标志检测</strong>：交通标志检测和识别已成为智能车辆中的普遍问题，并且提出了各种方法[20、15、34、19、38、45]来解决这一具有挑战性的任务。 用于此任务的传统方法包括[20] [15]。 近年来，基于CNN的方法由于其准确性高而被广泛用于交通标志检测和分类。 特别是，Sermanetet等人[34] 提出使用<strong>跳跃连接</strong>将多阶段特征提供给分类器，以增强交通信号识别。 吉纳特[19] 提出用<strong>铰链损失</strong>训练CNN，从而提供更好的测试准确性和更快的稳定收敛。 Wuet等人[38] 使用CNN结合固定和可学习的过滤器来检测交通信号。 朱特等人[45] 训练了两个CNN以同时对交通标志进行和分类 </p>
<p> <strong>行人检测</strong>：手工制作的特征在行人检测中取得了巨大的成功。 例如，Doll’areet等人提出了集成通道特征（ICF）[8]和聚合通道特征（ACF）[7]，它们是构造行人检测器的最流行的手工特征。最近，深度学习方法极大地提高了行人检测器的性能 行人检测[29，33，28，36，41]。 瓦扬耶特人[29] 提出了CNN的信息隐藏层来模拟混合姿态信息，这可以进一步有利于行人检测任务。 蒂涅特人[36] 通过语义任务共同优化了行人检测。 Sermanetet等人[33] 利用多阶段特征将整体形状信息与局部独特信息整合在一起，以学习探测器。</p>
</li>
<li><p>生成对抗网络</p>
<p> 生成对抗网络（GANs）[14]是学习生成模型的框架。 Mathieuetal。[26] 和Dentonet等人[6]。 采用GAN来生成图像。 **<del>在[22]和[40]中，GAN被用来学习从一个流形到另一个流形的映射，分别用于样式转换和修复</del>**。 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GAN用途：图像样式转换、图像修复</span><br></pre></td></tr></table></figure>

<p>在[31]中描述了使用GAN进行无监督表示学习的想法。 <font color=red><strong><del>GAN在[21]中也应用于图像超分辨率</del></strong></font>。 据我们所知，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">待读：GAN用于超分辨率的文章</span><br></pre></td></tr></table></figure>

<p>这项工作是首次尝试将GAN容纳在目标检测任务中，通过生成小目标的超分辨表示来解决小规模问题。</p>
</li>
</ol>
<h3 id="三、感知GANS"><a href="#三、感知GANS" class="headerlink" title="三、感知GANS"></a>三、感知GANS</h3><p> 我们提出了一个新的感知GAN网络来解决具有挑战性的小目标检测问题。 我们在生成器模型上引入了新设计，该模型能够生成小目标的超分辨表示形式，并且还引入了一种新的鉴别器，考虑了对抗性损失和感知损失来“监督”生成过程。 在本节中，我们首先从全局角度介绍感知GAN的替代优化。 然后，给出了用于超分辨特征生成的生成器和用于对抗学习的鉴别器的细节。 </p>
<ol>
<li><p>概述</p>
<p> 原始GAN模型的学习目标[14]与一个minimax两人游戏相对应，其公式为 </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\loss1.PNG)</p>
<p> 其中，G表示生成器，该生成器学习从噪声分布pz（z）到数据x上的分布pdata（x）映射数据z，D表示鉴别器，该鉴别器估计来自数据分布pdata（x）而不是G的样本概率。 G的训练过程是使D犯错误的可能性最大化。 </p>
<p>​        <del><strong>在我们的案例中，x和z分别表示大型目标和小型目标（即F_landF_s）的表示形式</strong></del>。 我们希望学习一个生成器函数G，**<del>该函数将小目标F_s的表示转换为与大目标F_l的原始目标相似的超分辨G（F_s）</del>**。 由于Fs中包含</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在这里，小尺度目标的特征F_S与大尺度目标的特征F_L分别对应生成对抗网络中的z与x</span><br><span class="line">其次，条件生成器的作用简单概括为：G(F_S|f)+F_S~~F_L，其中f表示小目标的底层特征</span><br></pre></td></tr></table></figure>

<p>的信息有限，因此学习与大目标特征F_l的分布相匹配的小目标的表示G（Fs）可能会很困难。我们因此引入了一个新的条件生成器模型，该模型以额外的辅助信息为条件，即小目标的低级特征f，生成器通过残差模块学习在大目标和小目标之间的表示生成<font color=red>**<del>残差表示</del>**</font>。 </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\loss2.PNG)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1、这里的残差表示F_S+G(F_S|f)：就是一种跳跃链接的网络结构，表示将深层的特征与浅层的特征相加</span><br><span class="line"></span><br><span class="line">2、F_S与f的区别：F_S是conv5输出的小目标特征，f是conv1输出的低级特征,但是G(F_S|f)怎么理解，生成器网络中并没有输入F_S这一项，而是后面eltwise sum操作时采用到了F_S</span><br><span class="line"></span><br><span class="line">2、个人理解：上文也提到了，引入残差表示是为了弥补F_S信息有限，难以学习与大目标特征相匹配的G(F_S)</span><br></pre></td></tr></table></figure>

<p>在这种情况下，通过直接学习小目标的超分辨表示，可以大大简化生成器训练。 例如，如果<font color=red>**<del>输入的表示来自一个大目标</del><strong></font>，则生成器仅需要学习<font color=red></strong><del>零映射</del>**</font>。 此外，我们在鉴别器上引入了感知损失，以利于检测任务，如下</p>
<p>所述。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">输入的到底是什么？？</span><br><span class="line">1、输入的是一整张图像的特征图，那怎么区分图中的大小目标</span><br><span class="line">2、输入的是每个目标的区域特征，但是ROI操作在conv1之后，从conv1出来的特征能够将每个目标的特征分开吗</span><br><span class="line"></span><br><span class="line">零映射的个人理解：</span><br><span class="line">1、映射到0，即G(F_S|f)&#x3D;0</span><br><span class="line">应对输入表征为大尺度目标的表征时，这里直接对G(F_S|f)做零映射（下文提到的），则F_S+G(F_S|f)&#x3D;F_S+0，即输出依然为大尺度的表征，而不做超分辨率</span><br><span class="line">2、相当于z&#x3D;0，即G(0|f)</span><br></pre></td></tr></table></figure>

<pre><code>     如图2所示，生成器网络旨在为小目标生成超分辨表示。鉴别器包括两个分支，即 对抗分支用于区分生成的超分辨表示和大目标的原始解析，而感知分支用于受益于生成表示的检测准确性。 我们以另一种方式优化生成器和判别器网络中嵌入的参数，以解决对抗性最小-最大问题。</code></pre>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\fig2.PNG)</p>
<p>​          <em>图2.基于感知GAN的目标检测网络的训练过程。 首先**<del>使用仅包含大对象的训练图像来训练鉴别器网络的感知分支以及底部卷积层</del><strong>。 然后，~~**利用仅包含小对象的训练图像，对生成器网络进行训练</strong>~~，以生成用于小对象的超分辨大对象表示。 鉴别器网络的对抗分支经过训练，可以区分生成的用于小物体的超分辨表示和用于真实大物体的原始分辨表示。 通过交替训练反复提高生成器网络和鉴别器网络的能力，可以提高特别是对于小物体的检测精度</em> </p>
<p>用带有参数θg的G_θg 表示生成器网络。 我们通过优化损失函数L_dis来获得θg： </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\func1.PNG)</p>
<p>其中L_dis是对抗损失L_dis-a和判别器网络产生的感知损失L_dis-p的加权组合，这在3.3节中有详细介绍。 通过为小目标的生成超分辨特征G_Θg（Fs）和大目标的特征F_L分配正确的标签，训练鉴别器网络的对抗分支以最大化概率。</p>
<p>​         假设D_Θa是由Θa参数化的判别器网络的对抗分支。 我们通过优化特定损失函数L_a来获得Θa ：</p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\func2.PNG)</p>
<p> 其中损失L_a被定义为 </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\func3.PNG)</p>
<p> 最终，鼓励鉴别器网络区分当前生成的小目标超分辨表示与原始大目标的原始分辨表示之间的差异。</p>
<p> 为了证明从生成的超分辨表示中受益的检测精度，**<del>应该首先根据大物体的特征对感知分支进行良好的训练，以实现较高的检测精度</del>**。 D_Θp表示由Θp参数化的鉴别器网络的感知分支。 通过使用大目标的表示优化特定</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">为什么首先用大目标子集对感知分支进行训练：</span><br><span class="line">为了保证感知分支在大目标特征的输入情况有着良好的表现，从而对超分辨特征起到较好的监督</span><br></pre></td></tr></table></figure>

<p>的损失函数L_dis-p来获得Θp：</p>
<p>​                                                     ![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\func4.PNG)</p>
<p>其中L_dis-p表示分类和边界框回归的多任务损失，详见3.3节。</p>
<p>​        <font color=red><del><strong>以所有实例的平均大小，我们分别获得包含小目标和大目标的两个子集。</strong></del></font>对于整体训练，我们首先基于 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">小尺度定义:以所有实例的平均尺度为界，区分大小尺度</span><br><span class="line">大目标子集：仅包含大目标bbox的数据</span><br><span class="line">小目标子集：同理</span><br></pre></td></tr></table></figure>

<p><strong><del>包含大目标的子集对底部卷积层和判别网络的感知分支的参数进行学习</del>**。 在所学感知分支的指导下，我们~~**基于包含小目标的子集进一步训练生成器</strong>，<strong>判别网络的对抗分支则使用以上两个子集（大目标子集与小目标子集）进行训练</strong>~~。 我们生成器的训练与鉴别器网络对抗分支的训练交替执行，直到最终达到平衡点，即 对于小型物体，可以生成具有较高检测精度的大型物体，例如超分辨特征。 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">训练过程：</span><br><span class="line">先用大目标子集训练底层卷积与判别器的感知分支</span><br><span class="line">然后在感知分支的监督下：</span><br><span class="line">用小目标子集训练生成器（训练时没有输入大目标特征，而在测试时会输入大目标特征，生成器是怎么处理大目标特征的输入的？？上文提到零映射，但那是怎么学习当输入为大目标特征时进行零映射的？？）</span><br><span class="line">并用两个子集一起训练判别器的对抗分支</span><br></pre></td></tr></table></figure>



</li>
</ol>
<ol start="2">
<li><p>条件生成对抗结构</p>
<pre><code>     生成器网络旨在生成用于小目标的超分辨表示，以提高检测精度。 为实现此目的，我们将生成器设计为深层残差学习网络，**~~该网络通过借助残差学习引入更多小目标所缺少的细粒度细节~~**，将小目标的表示范围扩大到超分辨目标。 </code></pre>
<p>​         如图3所示，生成器将来自底部卷积层的特征作为输入，保留了许多底层细节，并为特征超分辨率提供了信息。 首先将生成的特征传递到3×3卷积滤波器，然后传递到1×1卷积滤波器，以将特征维度增加到与“ Conv5”相同的大小。 然后，引入具有相同布局的两个残差块，残差模块均由两个3×3卷积滤波器组成，之后是批处理归一化层和ReLU激活层，<font color=blue>**<del>以学习大目标和小目标之间的残差表示</del>**</font>，作为生成模型。为得到小目标的超分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">注意总共有两个地方用到了残差学习：一个是生成器内部（就是这里的2个残差模块）、一个是生成器之后的F_S+G(F_S|f)</span><br><span class="line"></span><br><span class="line">这里的两个残差模块是怎么就学习到了大小目标间的残差表示的？？？？</span><br><span class="line">这里的B Residual Block模块的原理是？？？？</span><br></pre></td></tr></table></figure>

<p>辨率表示，使用学习到的残差表示，将生成器输出的特征与conv5输出的池化后特征（pooled feature）<font color=blue>**<del>通过按元素求和运算</del>**</font>，以此来增强从“ Conv5”输出的池化后特征。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">eltwise操作与concat区别：</span><br><span class="line">eltwise操作：将大小、通道数（W、H、c）完全相同的两个特征对应像素相乘或相加，其分为三种：product（点乘）， sum（相加减） 和 max（取大值），其中sum是默认操作</span><br><span class="line">concat操作只是将两个大小相同（W、H）的特征按照通道拼接</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">此处的生成器与原始生成器在网络结构上有着较大的区别:</span><br><span class="line">一般的生成器结构为encoder-decoder结构，而此处为残差结构</span><br></pre></td></tr></table></figure>

<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\fig3.PNG)</p>
<p> <em>图3.提出的感知生成对抗网络的详细信息。 （a）生成器是一个深度残差网络，它将具有较低层细节的特征作为特征输入，并将其传递给3×3卷积滤波器，然后传递给1×1卷积滤波器，以增加特征尺寸以使其与“ Conv5”一致 ”。 然后使用每个残差块包含卷积层，然后进行批归一化和ReLU激活，以学习残差表示，该残差表示用于通过元素逐和运算将合并的特征从小对象的``Conv5’’增强为超分辨表示。（ b）鉴别器将大对象的特征和小对象的超分辨表示作为输入，并分为两个分支。 对抗分支由三个完全连接的层组成，然后是Sigmoid激活，用于估计当前输入表示属于真实大对象的概率。 感知分支由两个完全连接的层组成，后面是两个输出同级层，分别用于分类和包围盒回归，以从生成的超分辨表示中受益，以证明检测准确性</em> </p>
</li>
</ol>
<ol start="3">
<li><p>判别网络结构</p>
<p>​         如图3所示，训练鉴别器网络不仅可以区分生成的小目标超分辨特征和真实目标中的原始分辨率，还可以证明受益于生成的超分辨特征的检测精度。鉴别器将产生的超分辨表征作为输入，将其传递到两个分支，即对抗分支和感知分支。 对抗分支由两个全连接层组成，接着是具有sigmoid激活的输出层，这会产生对抗性损失。 感知分支由两个全连接层组成，然后由两个同位输出层组成，这会产生感知损失，以判断有助于超分辨表征的检测性能。 两个分支的前两个全连接层的输出单元数分别为4096和1024。 </p>
<p>​         给定对抗性损失L_dis-a和感知损失L_dis-p，最终损失函数L_dis可以作为两个单独损失成分的加权总和产生。 给定加权参数w1和w2，我们定义L_dis = w1×L_dis-a + w2×L_dis-p，以鼓励生成器网络生成具有高检测精度的超分辨表示。 在这里，我们将w1和w2都设置为1。</p>
<p><strong>对抗损失</strong>：D_Θa表示是带有参数Θa的鉴别器网络的对抗分支。 将针对每个object proposal生成的表征G_Θg（Fs）作为输入，此分支输出输入表征属于真实大目标的估计概率，表示为D__Θa（G_Θg（Fs））。 通过尝试用生成的表征欺骗判别器网络，引入了对抗损失以鼓励生成器网络为小目标生成与大目标相似的超分辨表示。 对抗损失L_dis-a被定义为</p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\func5.PNG) </p>
<p> <strong>感知损失:</strong> 以每个proposal的超分辨表征为输入，感知分支输出K + 1个类别的置信度p =（p0，…，pk）和对于每个类的边界框回归偏移量r_k =（ r_kx，r_ky，r_kw，r_kh），并由k索引。 遵循[12]中的参数化方案，rk指定相对于目标建议的尺度不变转换和对数空间高度/宽度偏移。 每个培训建议都标有ground truth类别g和ground truth边界框回归目标r*。 计算以下的多任务损失L_dis-p以证明从每个目标建议的生成的超分辨特征中受益的检测准确性：</p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\func6.PNG)</p>
<p>其中L_cls和L_loc分别是分类损失和边界框回归损失。 特别的，L_cls（p，g）= -logpg是ground truth类别g的对数损失，L_loc是[11]中提出的smooth L1损失。 对于背景proposal（即g = 0），L_loc被忽略。</p>
<p><font color=red><strong>整体的理解：</strong></font></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">网络结构的理解：</span><br><span class="line">1、生成网络：</span><br><span class="line">首先是生成器generator：</span><br><span class="line">输入：底层卷积特征f</span><br><span class="line">输出：生成特征G(Fs|f)</span><br><span class="line">生成器结构：一个深度残差学习模块</span><br><span class="line">3*3卷积、1*1卷积（将特征维度增加到conv5相同的大小），经过ROI pooling之后，进入两个相同的残差模块：3*3卷积层、批归一化层、relu激活层、3*3卷积层（学习大小目标间的残差表示???？）</span><br><span class="line">eltwise sum操作：与concat不同，该操作将两个大小以及通道数均相同（W\H\C）的特征图进行按元素对应相加</span><br><span class="line"></span><br><span class="line">然后是从generator出来之后 ，从整体上看，也是一个残差模块：池化后特征F_S与生成特征G(F_S|f)的eltwise sum操作，即F_S+G(F_S|f)，而这个也就是超分辨特征</span><br><span class="line"></span><br><span class="line">2、判别网络</span><br><span class="line">1）、对抗分支（训练时才有该分支）：</span><br><span class="line">输入：大目标特征F_l 或 超分辨特征G(F_s|f)+F_s</span><br><span class="line">输出：输入的特征是否是真实的大目标特征的概率</span><br><span class="line">网络结构：3个全连接层+sigmoid输出层</span><br><span class="line">2）、感知分支：</span><br><span class="line">输入：大目标特征（训练感知分支时），超分辨特征（训练生成器时），大目标特征或超分辨特征（测试时）</span><br><span class="line">输出：各类别置信度p（p0, ..., pk）与bbox的回归偏移量rk（rk_x, rk_y, rk_w, rk_h）</span><br><span class="line">网络结构：两个全连接层，跟着两个全连接层分支，作为两种输出</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">损失函数：</span><br><span class="line">1、对于损失函数La：</span><br><span class="line">D_θa表示判别器，G_θg表示生成器，F_L表示真实大目标特征，F_S表示小目标特征，G_θg（F_S）表示超分特征，这里的G_θg（F_S）实际是G(F_s|f)+F_s</span><br><span class="line">该函数的形式与生成对抗网络的损失函数一致</span><br><span class="line">该函数用于对判别器对抗分支的参数θa的优化</span><br><span class="line"></span><br><span class="line">2、对于损失函数L_dis</span><br><span class="line">该函数用于对生成器参数θg的优化</span><br><span class="line">其是由判别器的对抗损失L_dis-a与感知损失L_dis-p的加权求和得到的，文中将权重w1与w2均设置为1</span><br><span class="line">其中L_dis-a，L_dis-p形式如下</span><br><span class="line">其中L_dis-p损失用于判别器感知分支参数θp的优化，其由类别损失L_cls与位置损失L_loc组成，Lloc损失在g&#x3D;0时可忽略，其中p表示对抗分支输出的k个类别的置信度（p0，...，pk）,rg表示类别g的bbox回归偏移量，r*表示真实的回归偏移量</span><br><span class="line">其中L_cls形式如下，Lloc为fast rcnn中的smooth L1损失</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">训练过程：</span><br><span class="line">1、先训练判别器感知分支</span><br><span class="line">训练集根据所有实例的平均尺度划分为大目标子集与小目标子集</span><br><span class="line">感知分支在大目标子集上训练：首先感知分支必须在大目标特征上的具有良好表现，才能保证超分辨特征对检测精度提升的受益</span><br><span class="line">通过优化损失函数L_dis-p来获取θp，θp是指判别器的判别分支D_θp中的参数</span><br><span class="line"></span><br><span class="line">2、生成器与判别器对抗分支交替训练</span><br><span class="line">生成器在小目标子集上训练：生成器的主要目标就是将小目标特征转换成超分特征，对于大目标特征的输入不做任何变换（即零映射）</span><br><span class="line">通过优化损失函数L_dis来获取θg，θg是指生成器G_θg中的参数</span><br><span class="line"></span><br><span class="line">对抗分支在两个子集上训练：对应了对抗分支的输入，其输入是大目标特征与超分特征，这对应的就是大目标子集与小目标子集</span><br><span class="line">通过优化损失函数L_a来获取θa，θa是指判别器对抗分支D_θa中的参数</span><br><span class="line"></span><br></pre></td></tr></table></figure>



</li>
</ol>
<h3 id="四、实验"><a href="#四、实验" class="headerlink" title="四、实验"></a>四、实验</h3><ol>
<li><p>数据集与评估机制</p>
<ol>
<li><p>）交通标志检测数据集</p>
<p> 清华腾讯100K [45]是一个大型交通标志基准，包含30,000个交通标志实例。图像的分辨率为2,048×2,048。 根据[45]，我们将忽略实例小于100的类，并剩下45个类。 使用与Microsoft COCO基准相同的检测指标评估性能。 我们报告了不同物体的检测性能，包括小目标（面积&lt;32×32pix-els），中物体（32×32 &lt;面积&lt;96×96）和大物体（面积&gt; 96×96）。 对应于三种划分的实例数分别为3270、3829和599。 这种评估方案有助于我们了解检测器对不同大小的物体的检测能力。 </p>
</li>
<li><p>）行人检测数据集</p>
<p> 加州理工学院的基准测试[9]是最受欢迎的行人检测数据集。 注释了约250,000帧，总共有350,000个边界框和2300个唯一的行人。 我们使用[44，27]中采用的训练数据的密集采样（每第4帧）。 按照常规评估设置[9]，对行人超过50像素，没有或部分遮挡的行人进行性能评估，这些行进通常很小。 评估指标是[10-2,100]中每幅图像的误报率（FPPI）的对数平均丢失率（表示为M Rfollowing [42]）。</p>
</li>
</ol>
</li>
</ol>
<ol start="2">
<li><p>实施细节</p>
<p>​        对于交通标志检测，我们使用[24]中采用的预训练的VGG-CNN-M-1024模型[3]来初始化我们的网络。 对于行人检测，我们使用[41]中采用的预训练的VGG-16模型[35]。 对于生成器和鉴别器网络，新添加的卷积层和完全连接层的参数用“ Xavier”初始化[13]。 我们将最短边的图像尺寸调整为1600像素和960像素，分别作为交通标志检测和行人检测的输入。 接下来[16]，我们直接通过步长为2的卷积层执行下采样。该实现基于在Caffe平台[17]上构建的公开可用的Faster R-CNN框架[11]。 </p>
<p>​         在具有12GB内存的单个NVIDIA GeForce GTX TITAN X GPU上，通过动量为0.9，重量衰减为0.0005的随机梯度下降（SGD）训练整个网络。 为了训练生成器网络，每个SGD微型批次都包含每个训练图像中的128个选定目标建议。 根据[11]，在每个小批量生产中，有25％的目标建议是前景，与地面真值边界框重叠，且该边界框至少有0.5 IoU，其余的是背景。 为了训练鉴别器网络，每个SGD微型批次都包含从四个训练图像中选择的32个前景目标建议。 生成器网络中的剩余块数设置为6。 对于清华腾讯100K [45]基准测试，我们按照[32]中的建议训练区域建议网（RPN），以生成有关训练和测试图像的目标建议。 对于Caltech基准[9]，我们利用在Caltech训练集上训练的ACFpedestrian检测器[7]来生成目标建议。 对于测试，Perceptual GAN平均在0.6秒内处理一张图像（不包括目标提议时间）。 </p>
</li>
<li><p>表现比较</p>
<ol>
<li><p>）交通标志检测</p>
<p> 表1提供了我们的方法与其他最新技术在平均召回率和交通信号检测准确度方面的比较。 可以看出，提出的感知GAN优于Zhuet等人以前的最新方法[45]。 在平均召回率和准确性方面：在不同目标大小的三个子集上，分别为89％和84％vs.87％和82％，96％和91％vs94％和91％，89％和91％vs88％和91％。 具体来说，我们的方法进行了很大的改进，即在小型子集上的平均调用率和准确性分别提高了2％和2％，这证明了其在精确检测小目标方面的优越性。 表2显示了每个类别的召回率和准确性的比较。 我们的方法可以在大多数情况下（例如“ p3”和“ pm55”）中获得最佳性能，在这种情况下，小情况最常见。 在图5中提供了关于不同目标大小的准确性-召回曲线的更多比较，可以进一步证明所提出的生成对抗性学习策略的有效性。</p>
</li>
</ol>
<p>​                                                    ![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\table1.PNG) </p>
<p>​        ![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\table2.PNG)</p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\fig5.PNG)</p>
<p> 图7中显示了几个小目标检测结果的例子。我们将视觉结果与Zhuet等人的视觉结果进行了比较[45]。 注意Zhuetal。[45] 输入分辨率为2,048×2,048的原始图像作为输入，可能会花费大量时间进行培训和测试。 相反，感知GAN仅将分辨率为1600×1600的图像作为输入。 此外，Zhuet等人[45]没有采用任何数据增强方法。 已被应用。 如图7所示，一般来说，我们的方法可以对大多数目标进行小规模的准确分类和定位，而Zhuet等人[45] 由于严重的小规模问题，无法定位某些实例。 </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\fig7.PNG)</p>
<ol>
<li><p>）行人检测</p>
<p> 由于Caltech基准[9]上的行人实例通常是小规模的，因此其整体性能可用于评估检测小目标的方法的能力。 我们将Percep-tual GAN的结果与所有在Caltech测试设备上实现最佳性能的方法进行了比较，包括VJ [37]，HOG [5]，LDCF [27]，Katamari [2]，SpatialPooling + [30]，TA -CNN [36]，棋盘格[43]，CompACT-Deep [44]和RPN + BF [41]。 如图4所示，该方法优于所有以前的方法，并实现了最低的对数平均漏检率（9.48％），证明了其在检测小目标方面的优越性。 </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\fig4.PNG)</p>
</li>
</ol>
</li>
<li><p>消融研究</p>
<p> 我们研究了感知GAN的不同组成部分的有效性。 所有实验都是在清华腾讯100K [45]数据集上进行的。以下介绍了感知GAN和参数设置的不同变体对小目标以及所有大小不同的目标的性能。 </p>
<ol>
<li><p>）生成器超分辨率特征的有效性</p>
<p> 为了验证生成的超分辨表示在检测小目标方面的优越性，我们将我们的方法与其他几种功能增强解决方案进行了比较，包括组合底层特征，通过简单地增加输入比例来提高图像分辨率， 多尺度作为输入。 所有这些方法都是基于基本卷积层和带有端到端训练的感知分支来实现的。 如表3所示，“skip pooling”表示通过[1]中提出的通过跳跃池化将底层特征组合在一起而训练的模型。 我们的感知GAN在小型物体上的平均召回率和准确性分别比该方法高出13％和2％，这证明了我们的方法可以有效地合并来自低层的细粒度细节以改善小目标检测。 “ LargeScale Images”代表通过将输入图像的比例简单地增加到2048×2048来训练具有更高分辨率图像的模型。 “多尺度输入”表示使用[11]中采用的具有多尺度设置（s∈1120、1340、1600、1920、2300）的输入图像训练的模型。 可以观察到，我们的感知GAN在小目标上的性能均优于两种方法。 这表明我们的方法在增强小目标检测方面比仅增加输入图像比例或使用多比例设置更有效。 </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\table3.PNG)</p>
<p>​         我们进一步可视化了一些生成的超分辨特征，如图6所示。第二列和最后一列显示了从顶部卷积层汇集的原始特征，分别用于建议小目标和大目标。 第三列和第四列分别显示了生成器为小目标所学习的残差表示和生成的超分辨特征。 可以观察到，生成器成功地学习了将小目标的不良表示转换为类似于大目标的超分辨的表示，从而验证了感知GAN的有效性。 </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\fig6.PNG)</p>
</li>
<li><p>）对抗训练的有效性</p>
<p>提出的感知GAN通过替代优化来训练生成器和判别器。 为了证明对抗训练的必要性，我们在表4中报告了训练阶段有或没有其他优化的情况下我们模型的性能。“我们的基线”表示使用生成器网络训练建议的检测管道的模型。 端到端，无需任何替代性优化步骤。 “ OursAlt”表示交替训练生成器和鉴别器的模型。 通过将“ OursAlt”与“ OursBaseline”进行比较，可以观察到，使用替代性优化方法后，在小尺寸物体检测方面的召回率和准确度将得到显着提高。 这表明PerceptualGAN通过对抗性训练递归地提高生成器和鉴别器的能力，可以提高其在检测小目标方面的性能。 </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\table4.PNG)</p>
</li>
<li><p>）生成器学习的不同底层</p>
<p> 拟议的生成器从较低层的表示中学习小目标的细粒度细节。 特别是，我们将“ Conv1”中的功能用作学习生成器的输入。 为了验证此设置的有效性，我们分别使用“ Conv2”和“ Conv3”中的功能进行了额外的实验来学习生成器。 如表5所示，通过使用高层的表示，我们可以观察到性能持续下降。 原因是下层可以捕获更多小目标的细节。 因此，使用“ Conv1”中的低级功能学习生成器具有最佳性能。 </p>
<p>![](C:\Users\12466\Pictures\paper\Perceptual Generative Adversarial Networks for Small Object Detection\table5.PNG)</p>
</li>
</ol>
</li>
<li><p>就一般性的小目标检测的讨论</p>
<p> 为了评估拟议的生成器在更一般和多样化的目标类别上的泛化能力，我们将生成器网络端对端地通过PASCALVOC 2007和VOC 2012的训练集联合训练了拟议的检测管道。 在VOC 2007的测试集上，以最具挑战性的类（例如，船，瓶子，椅子和植物）对它进行评估，这些类中最常见的是小实例。 我们的方法分别为船，瓶，椅和植物的平均精度（AP）分别达到69.4％，60.2％，57.9％和41.8％。 它显着优于fast R-CNN [11]的基线，即59.4％，38.3％，42.8％和31.8％，很好地证明了所提出的生成器对一般小目标检测的泛化能力。</p>
</li>
</ol>
<h3 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h3><p>​         在本文中，我们提出了一种新型的生成对抗网络来解决小目标检测的挑战性问题。 感性GAN通过利用反复更新的生成器网络和鉴别器网络来生成用于小目标的超分辨表示，以提高检测性能。 生成器从较低层的细粒度细节中学习残差表示，并通过尝试使识别器蒙骗以增强区分这两种表示的能力，来增强小目标的表示以接近大目标的表示。 两种网络交替优化的竞争促使Perceptual GAN为小目标生成超分辨的大物体像表示，从而提高了检测性能。大量实验证明了拟议的感知GAN在检测小目标方面的优越性。  </p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/Paper/Perceptual%20Generative%20Adversarial%20Networks%20for%20Small%20Object%20Detection/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Paper/Panoptic-based Image Synthesis" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
    <div class="article-entry" itemprop="articleBody">
      
        <hr>
<h1 id="Panoptic-based-Image-Synthesis"><a href="#Panoptic-based-Image-Synthesis" class="headerlink" title="Panoptic-based Image Synthesis"></a>Panoptic-based Image Synthesis</h1><hr>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>​        用于生成光反射图像的条件图像合成服务于从内容编辑到内容生成的各种应用。 先前的条件图像合成算法主要**<del>依赖于语义图</del><strong>，并且经常</strong><del>在多个实例相互遮挡的复杂环境中失败</del>**。 我们提出了一种全景感知图像合成网络，生</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">之前的条件合成图像方法  特点及局限性：</span><br><span class="line">1、依赖于语义图</span><br><span class="line">2、在多实例拥挤场景中，由于遮挡的原因，导致生成图像的失败</span><br></pre></td></tr></table></figure>

<p>成<font color=red>**<del>以全景图像为条件</del>**</font>的高保真度和真实感图像，该全景图像将语义和实例信息统一起来。 为此，我们在卷积和上</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">全景图像与之前的语义图像区别是什么？？？？</span><br><span class="line">区别：1、语义图像（语义分割）：将不同语义的内容用不同颜色标注，但没有将同一类别的每个实例单独用一红颜色标注出，当实例相互遮挡时就会导致无法区分两个实例的边缘，这也是为什么本文使用全景分割的原因；2、全景图像（全景分割）：将实例分割与语义分割结合，将每个不同个体的实例也做了不同颜色的标注，其他与语义分割是一致的；3、实例分割：类似目标检测，只不过不是给出bbox，而是给出每个实例的边缘信息，与语义分割的区别在于，实力分割不需要对每个像素进行颜色标注，只需要对边缘进行标注</span><br><span class="line"></span><br><span class="line">参考链接：https:&#x2F;&#x2F;blog.csdn.net&#x2F;electech6&#x2F;article&#x2F;details&#x2F;85317608</span><br></pre></td></tr></table></figure>

<p>采样层中有效地使用了全景图。我们证明，通过对生成器的建议更改，我们可以通过在更高级别的复杂实例交互环境中生成图像来改进以前的最新方法。此外，我们提出的方法在mean IoU（联合上的交集）和detAP（检测平均精度）的指标上也优于先前的最新方法。 </p>
<h3 id="一、引言"><a href="#一、引言" class="headerlink" title="一、引言"></a>一、引言</h3><p>​        图像合成是指生成多样且逼真的图像的任务，其中称为条件图像合成的流行子类别输出以某些输入数据为条件的图像。 最近，深度神经网络在条件图像合成[12、4、33、39、40、38、1]方面取得了成功，其中条件输入之一是语义分割图。 扩展此概念，在本文中，我们对由全景图引导的真实感图像的生成感兴趣。 **<del>全景图统一了语义图和实例图</del>**。 具体来说，它们提供有关可计数类的对象实例的信息，这些可计数类称为“thing”，例如人，动物和汽车。 此外，它们还包含有关类的语义信息，这些类是无定形区域、图案或纹理，例如草，天空和墙壁。 这些类称为“stuff”。 </p>
<p>​         我们对全景图很感兴趣，因为语义图没有提供足够的信息来合成“thing”（实例），尤其是在复杂的环境中（其中有多个实例相互交互）。 当对象较小且实例被部分遮挡时，即使sota（SPADE [24]其将边界图像输入到网络中），也无法生成高保真度图像。 从图1可以看出，这个问题是从一个斑马到另一个斑马的连续模式，这是**<del>传统卷积和上采样算法中类与实例边界无关</del>**的结果。 为了解决这个</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">传统卷积和上采样算法中类与实例边界无关：？？？？</span><br></pre></td></tr></table></figure>

<p>问题，我们用**<del>全景感知卷积和全景光感知上采样层替换了生成器中的卷积和上采样层</del>**。我们将这种图像合成形式称</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">由于传统卷积与上采样的类与实例边界无关性导致的遮挡目标间连续的问题，使用以上两个新的结构替代传统卷积与上采样</span><br></pre></td></tr></table></figure>

<p>为基于全景图像的合成。我们在两种多样且具有挑战性的方面评估了我们提出的图像生成器 数据集：城市景观[5]和COCO-Stuff [2]。 我们证明了我们能够高效，准确地使用全景图来生成更高保真度的图像，并改进了先前方法使用的评估指标[4、33、24]。 </p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\fig1.PNG)</p>
<p>​         我们的主要贡献可以归纳如下：1。 我们建议在条件图像生成设置中使用基于全景图对卷积进行加权的全景感知卷积。 类似的机械方法以前曾用于具有二进制掩码和学习的软掩码的其他任务[16、8]，但未用于具有多类全景掩码的图像合成。2. 我们提出了全景感知的上采样，以解决上采样的低分辨率特征和高分辨率全景图之间的不对齐问题。 这确保了语义和实例细节不会丢失，并且我们还可以在生成的图像和全景图之间保持更高的准确性。3。 我们证明了使用我们提出的网络架构，我们不仅看到了更多的真实感图像，而且在用对象检测模型进行评估时，我们还观察到了Cityscapes和COCO-Stuff数据集上对象检测得分的显着改善。</p>
<h3 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h3><p>​         生成对抗网络（GANs）[7]通过对自然图像分布进行建模并合成与自然图像难以区分的新样本来进行图像合成。 这可以通过在零和博弈中使用都试图优化对立目标函数的生成器和鉴别器网络来实现。 许多条件图像合成工作都使用GANsto生成逼真的图像，我们的也是如此。 </p>
<p>​         条件图像合成可以根据要调节的输入的不同类型而有所不同。 例如，输入可以是文本[26、39、35、10]，自然和合成图像[14、42、18、43、11、41、15]或无监督的地标[19、13、29、6] 仅举几例。 最近，[25，4，12]使用语义图，[33，24]同时使用语义图和边界图作为生成器的输入，在生成器中，从实例图获得边界图。 如果边界图中的像素与四个邻居中的任何一个都不相同，则将其设置为1，否则将其设置为0。 此方法不会保留实例映射中包含的全部信息，尤其是当实例相互遮挡时。 属于同一实例的像素可能被多个边界分隔。 </p>
<p>​         **<del>内容感知卷积</del>**。已经有很多作品学习基于注意力机制对卷积激活进行加权[38，34，36，8]。 这些机制在特</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">内容感知卷积是什么？？？？</span><br><span class="line">部分卷积原理的个人理解：用于图像修复任务，其通过掩码图像，指定图像中那些像素是有意义的（即哪些像素用于卷积）</span><br><span class="line">在图像修复任务中，卷积只对待修复区域进行卷积，每次卷积操作之后，对掩码图像都进行更新，M会越来越小，最终消失，即完成修复</span><br><span class="line"></span><br><span class="line">参考链接：https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_33594380&#x2F;article&#x2F;details&#x2F;88969580</span><br></pre></td></tr></table></figure>

<p>征图上进行操作，以在做出决策时捕获彼此相关的空间位置。 在另一研究领域中，<strong>通过二进制掩码得到的空间位置可能对输出并没有贡献（例如，在图像修补的情况下，填充图像中孔洞的任务，这些孔洞便没有贡献</strong>）提</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">个人理解：</span><br><span class="line">也就是说，有些时候图像中的部分像素对于卷积没有意义或不是很重要，这时就使用内容感知卷积，通过注意力机制只对更有意义的像素进行卷积？？？？</span><br></pre></td></tr></table></figure>

<p>供给我们。 在此任务中，[17，31]使用部分卷积，以便在给定具有孔和有效像素的二进制蒙版的情况下，卷积结果仅取决于有效像素。我们的卷积层类似于图像修复中使用的卷积层，而不是带有空洞的掩码，而是我们给了一个全景图像，因此我们知道**<del>一个实例的卷积结果不应该依赖于另一个实例或属于不同语义类别的像素</del>**，我</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">个人理解：</span><br><span class="line">对一个实例进行卷积时，只对属于该实例的像素做卷积</span><br></pre></td></tr></table></figure>

<p>们没有给出二进制掩码，但是我们根据全景图即时高效地生成了二进制掩码。 </p>
<p>​         **<del>内容感知上采样</del>**：最近邻和双线性插值是深度学习应用中最常</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">同样是基于全景掩码的指导进行上采样，在高分辨率掩码的指导下，低分辨率图像能够使得上采样得到的高分辨率图像，与掩码形状做了对齐。</span><br></pre></td></tr></table></figure>

<p>用的上采样方法。 这些方法基于像素坐标的相对位置使用手工制作的算法。 在学习语义分割[23、30]以及图像和视频超分辨率[28]任务的上采样权重方面也引起了极大的兴趣。 最近，[20，32]提出了特征导向的上采样算法。 这些方法在特征图上进行操作以对内容进行编码，然后根据内容对特征进行上采样。 在我们的方法中，类似于全景感知卷积层中的思想，我们利用高分辨率全景地图来解决上采样特征地图和全景图中的未对齐问题。 </p>
<h3 id="三、方法"><a href="#三、方法" class="headerlink" title="三、方法"></a>三、方法</h3><p>​         在本节中，我们首先详细介绍全景感知卷积和全景感知上采样层。 然后，我们描述整个网络体系结构 </p>
<h4 id="3-1全景感知卷积层"><a href="#3-1全景感知卷积层" class="headerlink" title="3.1全景感知卷积层"></a>3.1全景感知卷积层</h4><pre><code>     我们将使用全景图的部分卷积运算称为全景知觉部分卷积层，该层与其他将部分卷积用于不同任务的工作共享基本原理[8，16]。 设卷积滤波器权重和相应的偏差。X为特征值，P为当前卷积（滑动）窗口的全景图值。</code></pre>
<p>​        M为相应的二进制掩码。M定义哪些像素将有助于基于全景图的卷积运算输出。 *<em><del>与全景分割图像中中心像素具有相同像素值的像素，值为1，反之值为0</del>**</em>。表示为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">如下图所示，执行全景感知卷积操作可以使得对某个实例进行卷积计算时，只考虑实例本身，而不考虑周围环境以及其他实例的像素。</span><br></pre></td></tr></table></figure>



<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\func1.PNG)</p>
<p>​         这可以通过以下方式实现：首先从色块中减去中心像素，然后将绝对值阶段至（0,1）区间内，然后从1中减去截断后的输出，以反转零和一。 图2描述了二进制掩码M的结构。 </p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\fig2.PNG)</p>
<p>​         每个位置的部分卷积表示为： </p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\func2.PNG)</p>
<p>​         其中O表示逐元素相乘且当M所有元素均为1时，1的形状与M相同（式子其中的1指的是与X形状相同的满1矩阵）。比例因子<del><strong>sum（1）/ sum（M）</strong></del>进行归一化处理，以计算有效输入的变</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">该项用于做卷积结果有效信息的缩放：</span><br><span class="line">当M全部是1，即全部像素具有意义（全部参与卷积），则有效信息最多，当M只有部分是1时，则表示有消息少了，则通过sum（1）&#x2F; sum（M）来放大卷积结果，即适当增加有效信息。</span><br></pre></td></tr></table></figure>

<p>化量，如[16]所示。 使用Equation2，实例或填充的卷积结果仅取决于属于相同实例或填充的特征值 </p>
<h4 id="3-2全景感知上采样层"><a href="#3-2全景感知上采样层" class="headerlink" title="3.2全景感知上采样层"></a>3.2全景感知上采样层</h4><p>​         当可以使用更高分辨率的全景图（例如用于内容生成任务的图像合成的情况下）时，我们建议使用全景感知上采样层作为传统上采样层的替代方案。 最近邻采样是在[1，24，33，24]中使用的有条件的图像合成任务中常用的常规上采样选择。但是，最近邻采样算法是手工制作的，可以进行复制。 例如，在一个2×2上采样场景中，最近邻居算法会**<del>将左上角的像素值复制到2×2窗口的周围像素上</del>**，这会产生两个问题，如图3所示 。</p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\fig3.PNG)</p>
<p>​         首先，它会**<del>导致上采样得到的高分辨率特征图与真实高分辨率全景图像空间位置不对齐的问题</del><strong>。 图3顶部说明了此问题，使用传统的上采样方法会导致实例B的特征被复制并错误地用于实例A。 在图3中，为清楚起见，我们演示了在上采样的全景图中的未对齐情况，但是我们仅对特征图中的对齐感兴趣。 我们将解决这种不对准的操作称为“上采样对准”校正。其次，如图3底部所示，</strong><del>高分辨率全景图可能包含新类别，而低分辨率全景图中可能不存在实例</del>**。 这意味着</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">就是说，高分辨率图像中，由于分辨率的增大，原本一些小的实例没有在低分辨率图像中出现，但是在高分辨率图像中出现了，如果使用传统上采样就会丢掉这些新增实例的信息</span><br></pre></td></tr></table></figure>

<p>需要生成新特征并将其替换为上采样特征图。 我们将此操作称为**<del>“孔填充”</del>**。 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">孔填充的算法：如算法1所示（已知高分辨率全景图、低分辨率全景图、低分辨率特征图，求高分辨率特征图的过程。），在当高分辨率全景图与低分辨率全景图对应位置像素相同时，高分辨率特征图对应位置像素与低分辨率特征图像素值一直，若高分辨率全景图与低分辨率全景图对应位置像素相同，则高分辨率特征图的像素值置为0，也就是所谓的“孔填充”</span><br><span class="line">孔填充的理解：当高分辨率全景图与低分辨率全景图对应位置像素不同，表示高分辨率全景图中可能出现了新实例</span><br></pre></td></tr></table></figure>

<p>​         图4描述了上述两个问题在Cityscapes数据集的网络中不同层发生的频率。 如图所示，尤其是在较早的图层中，新生成的像素中超过30％的像素特征与全景图不对齐，并且属于新实例或语义图的许多像素首次以新比例出现 。</p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\fig4.PNG)</p>
<p>​         为了解决这两个问题，<strong>全景感知上采样层执行两步过程：上采样对齐校正和孔填充</strong>，如图3所示。S表示语义图，然后对特征F进行上采样。我们对2×2上采样感兴趣，因为它是图像合成方法中最常用的上采样比例。 我们对上采样Fd感兴趣，以便在更高比例的全景图P’u和语义图S’u的指导下生成上采样特征图F’u，并生成掩码M’correction。</p>
<p>​         为了纠正2×2上采样层中的未对准，我们扫描了每个像素的四个邻居。 <strong><del>在2×2窗口中，如果我们找到了分辨率较高的相应像素的全景身份与分辨率较低的相邻像素的全景身份之间的匹配，则将那个邻近特征复制到上采样特征图中的相应索引。</del></strong> 在</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">怎么实现的对齐？？？？</span><br><span class="line">这个全景图像用于每个特征图？应该是只输入一次，然后对其中的特征图进行指导？？？？</span><br><span class="line">为什么要上采样？？？？</span><br></pre></td></tr></table></figure>

<p>Algorithm1中描述了此方法。 注意，如果循环中没有if陈述，则第一个for循环将对应于最近邻上采样算法。 我们还更新了掩码M‘correction，以跟踪已成功对齐的索引。在随后的for循环中，对于尚未对齐的索引，我们检查是否有其他邻居与它们的全景身份匹配 。</p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\alg1.PNG)</p>
<p>​         在算法1之后，我们最终得到了部分填充的上采样特征图和一个Mcorrection mask，它定义了哪个坐标找到了匹配项。 之后，我们计算finalF′uby ：</p>
<p>​        ![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\func-1.PNG)</p>
<p>​         我们通过输入语义图（Su）作为输入和全景图（Pu）作为指导，用全景图知觉卷积层生成补全。 我们使用语义图对来自K×2W×2H语义图的特征进行编码，其中K是该层到较高维C×2W×2H的类数 </p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\func3.PNG)</p>
<p>​         通过全景感知的上采样层，针对特定实例或背景语义所特有的特征不会复制到另一个实例或背景语义上，从而提高了生成图像的准确性。</p>
<h4 id="3-3-网络结构"><a href="#3-3-网络结构" class="headerlink" title="3.3 网络结构"></a>3.3 网络结构</h4><p>​         由SPADE [24]推动的最终提出的架构如图5所示。与SPADE相似，我们将降采样后的分割图馈送到生成器的第一层，但在我们的体系结构中，它是全景感知的卷积层，可对＃Classes×的特征进行编码 W×语义映射到更高的尺寸1024×W×H。 在网络的其余部分，我们用Panopticaware卷积层替换ResNet块中的所有卷积层，并用Panoptic感知上采样层替换所有上采样层。 每个块的操作尺度不同，我们对语义和全景图进行下采样以匹配特征的尺度。SPADE模块的输入保留为语义图，用于学习非规范化参数。 全景图不适合此计算，因为卷积运算需要固定数量的通道。 因此，我们依靠SPADE根据语义类为网络提供正确的特征统计量。我们将全景图馈送到全景感知的卷积层，以便基于实例和类执行卷积操作。 原始的全分辨率全景图和语义图也被馈送到全景光学的上采样层，以执行上采样对齐校正和孔填充。架构的第一层中的全景感知卷积层对从＃Classes×W×Hmanmantic映射到更高级别的特征进行编码 维度编码的功能在网络其余部分的全景感知向上采样层之间共享。 当从第一层生成的部分卷积层的通道数与在不同块处预期的通道数不匹配时，我们将尺寸减小1×1卷积层。 该层在图5中用绿色框表示。请注意，在图5中绿色框被多次描绘，但是它们在阶段之间共享。 通过共享权重，我们不会在基线上引入其他参数，除非可以忽略1×1卷积的成本。 共享这些权重也是有意义的，因为该层的任务在每个阶段都是通用的，这是为实例和语义类生成在该阶段首次出现的功能。</p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\fig5.PNG)</p>
<h3 id="四、实验"><a href="#四、实验" class="headerlink" title="四、实验"></a>四、实验</h3><p>​         <strong>数据集。</strong>我们对Cityscapes [5]和COCO-Stuff [2]数据集进行了实验，这些数据集具有实例和语义分割标签。 Cityscapes数据集包含3,000个城市街道场景的训练图像和500个验证图像，以及35个语义类和9个实例类。 所有类别均在合成图像时使用，但只有19个类别用于城市景观评估基准所定义的语义评估。 COCO-Stuff数据集包含118,000个室内和室外场景的训练图像和5,000个验证图像。 该数据集具有182个语义类和81个实例类。 </p>
<p>​         <strong>实施细节。</strong>我们使用SPADE基线[24]提供的参数。 具体来说，我们使用syncbatch归一化来收集GPU之间的统计信息，并将Spectral Norm [21]应用于生成器和区分器中的所有层。 我们为COCO-Stuff训练并生成256×256分辨率的图像，并为Cityscapes数据集生成256×512的图像。 我们在批次大小为16的Cityscapes数据集上训练了200个时期，并通过[24]线性衰减了100个时期之后的学习率。 对COCO-Stuff数据集训练100个纪元，批量大小为48个，学习率恒定。将生成器和鉴别器的初始学习率分别设置为0.0001和0.0004，并使用ADAM求解器训练网络，其中β1= 0和β2= 0.999.Performance Metrics。 作为先前的条件图像合成工作[24、33]的评估指标，加上用于检测成功生成的对象实例的另一指标。 前两个指标是平均相交重叠量（mIoU）和整体像素精度（准确性），是通过在合成图像上推断出最新的语义分割模型并比较预测的分割蒙版与地面真实语义匹配的程度来获得的 地图。 此外，我们通过训练有素的物体检测网络使用检测平均精度（detAP）来评估合成图像上的实例检测精度 </p>
<p>​         我们使用[24]中使用的相同分割网络进行评估。 具体来说，对于COCO-Stuff，我们使用DeepLabV2 [3，22]，对于Cityscapes数据集，使用DRN-D-105 [37]。为了进行检测，我们将Faster-RCNN [27]与ResNet-50backbone一起使用。 除了mIoU，准确性和detAP性能指标外，我们还使用Fr’echet起始距离（FID）[9]来测量合成结果的分布与真实图像的分布之间的距离。基线。我们将我们的方法与三种方法进行比较。 lar图像合成框架，即：级联细化网络（CRN）[4]，半参数图像合成（SIMS）[25]和空间自适应非规范化模型（SPADE）[24]。 CRN使用具有给定语义标签图的深层网络，无需经过对抗训练即可反复将输出从低分辨率细化到高分辨率。 SIMS使用由一组训练图像构成的图像段存储库，并通过adeep网络细化边界。 SIMS和CRN都仅在语义图上运行。 SPADE是当前最先进的条件图像合成方法，不仅使用语义图，而且还通过边界图合并实例信息。 如果其对象标识与其4个相邻像素中的任意一个不同，则边界图中的像素为1，否则为0。 这种方法不能提供完整的实例信息，尤其是在杂乱的场景中，其中有很多物体相互遮挡。 我们将其与SIMS onCityscapes数据集进行比较，而不是与COCO-stuff数据集进行比较，因为SIMS需要查询训练集图像，并且对于大型数据集（例如COCO-stuffdataset）而言，在计算上是昂贵的 </p>
<p>​         <strong>定量结果：</strong>在表1和表2中，我们分别提供了Cityscapes和COCO-Stuff数据集的结果，发现我们的方法在物体检测得分mIoU和 两个数据集中的像素级精度。 表4报告了Cityscapes数据集中每个类的值。 我们几乎改善了所有课程。 特别是，我们提出的方法将交通标志的mIoU从44.7提高到50.0，这是一个具有挑战性的类，因为标志的尺寸很小。 </p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\table1.PNG)</p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\table2.PNG)</p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\table3.PNG)</p>
<p>​         与发布的SPADE模型相比，我们观察到的FID分数略有下降，而我们使用[24]提供的参数训练的SPADE模型也有所下降。 FIDscore尝试匹配真实图像和生成图像之间的方差/差异，而不关心条件语义图和实例图的对应关系。我们的结果与基础语义图和实例图具有更好的对应性。 尽管这是期望的行为，但结果可能会受到人为提示偏差的影响。 我们怀疑，输入中的此类注释偏差（例如直线偏差，过于简化的多边形偏差）可能会使方差的匹配变差。 还应注意，即使SIMS达到较差的detAP和mIoU分数，其图像FID得分也比其他方法低得多。 这是因为SIMS从训练数据集中复制了图像色块，有时复制的色块不忠实地匹配给定的分割掩码。 这个问题在de-tAP评分中变得更加明显，因为SIMS会在不确保全景图一致的汽车数量的情况下复制补丁。 </p>
<p>​         <strong>定性比较。</strong>在图6和7中，我们提供了本方法和其他竞争方法的图像合成结果。 我们还提供Faster-RCNN的边界框检测预测。 我们特别提供了多个实例相互遮挡的示例。 我们发现，在具有挑战性的场景中，我们的方法可以产生具有更好视觉质量的实例。 具体来说，我们发现我们的方法即使在落后时也会产生不同的汽车，即使它们离得很远也能产生可检测的人，如图6所示。从图7可以看出，我们发现其他方法可以将模式和tex- 对象在相邻实例之间的位置，而我们的方法则清楚地将它们分开。 </p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\fig6.PNG)</p>
<p>​         ![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\fig7.PNG)</p>
<p>​        <strong>消融研究。</strong>我们进行受控实验，并逐步添加我们提出的组件。 我们从基准SPADE模型[24]开始。 我们对模型进行了三次训练，并报告平均结果。 首先，我们用全景意识的卷积层替换ResNet块中的卷积和第一层。 其次，我们用全景感知的上采样层另外替换最近的邻居上采样层。 表4中显示了每种设置生成的图像的分割mIoU分数和detAP分数，其中每个添加的模块都会提高性能 </p>
<p>![](C:\Users\12466\Pictures\paper\Panoptic-based Image Synthesis\table4.PNG)</p>
<h3 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h3><p>​         总之，我们提出了一种基于全景的图像合成网络，该网络可以生成具有更高保真度的图像给基础的分割和实例信息。  我们证明了我们的方法在挑战性场景中更能生成独特的实例，并且在detAP度量标准（该度量标准之前从未用于评估条件图像合成结果）方面明显优于以前的最新技术。 </p>
<p>​         <strong>未来的工作。</strong>多模式图像合成和样式的可控制性对于内容生成应用程序非常重要。 我们实验中的体系结构不支持样式指导的图像合成。 但是，我们的工作可以扩展为通过pix2pixHD [33]中提出的编码器-解码器体系结构输出多种样式。 此外，建议的全景感知卷积和上采样层可用于对样式进行解码的特征图，并可提供进一步的改进。 我们将其留作未来的工作。 </p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2021/03/29/Paper/Panoptic-based%20Image%20Synthesis/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next &amp;raquo;</a>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2021 John Doe
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: false,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false,
		toc_hide_index: true,
		root: "/",
		innerArchive: true,
		showTags: false
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.toc_hide_index){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.0cf68a.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.e37972.js")}()</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'innerArchive')"><a href="javascript:void(0)" q-class="active:innerArchive">所有文章</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 33.333333333333336%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    
    	<section class="tools-section tools-section-all" q-show="innerArchive">
        <div class="search-wrap">
          <input class="search-ipt" q-model="search" type="text" placeholder="find something…">
          <i class="icon-search icon" q-show="search|isEmptyStr"></i>
          <i class="icon-close icon" q-show="search|isNotEmptyStr" q-on="click:clearChose(e)"></i>
        </div>
        <div class="widget tagcloud search-tag">
          <p class="search-tag-wording">tag:</p>
          <label class="search-switch">
            <input type="checkbox" q-on="click:toggleTag(e)" q-attr="checked:showTags">
          </label>
          <ul class="article-tag-list" q-show="showTags">
            
            <div class="clearfix"></div>
          </ul>
        </div>
        <ul class="search-ul">
          <p q-show="jsonFail" style="padding: 20px; font-size: 12px;">
            缺失模块。<br/>1、请确保node版本大于6.2<br/>2、在博客根目录（注意不是yilia根目录）执行以下命令：<br/> npm i hexo-generator-json-content --save<br/><br/>
            3、在根目录_config.yml里添加配置：
<pre style="font-size: 12px;" q-show="jsonFail">
  jsonContent:
    meta: false
    pages: false
    posts:
      title: true
      date: true
      path: true
      text: false
      raw: false
      content: false
      slug: false
      updated: false
      comments: false
      link: false
      permalink: false
      excerpt: false
      categories: false
      tags: true
</pre>
          </p>
          <li class="search-li" q-repeat="items" q-show="isShow">
            <a q-attr="href:path|urlformat" class="search-title"><i class="icon-quo-left icon"></i><span q-text="title"></span></a>
            <p class="search-time">
              <i class="icon-calendar icon"></i>
              <span q-text="date|dateformat"></span>
            </p>
            <p class="search-tag">
              <i class="icon-price-tags icon"></i>
              <span q-repeat="tags" q-on="click:choseTag(e, name)" q-text="name|tagformat"></span>
            </p>
          </li>
        </ul>
    	</section>
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接1</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接2</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接3</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接4</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接5</a>
            </li>
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接6</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">很惭愧&lt;br&gt;&lt;br&gt;只做了一点微小的工作&lt;br&gt;谢谢大家</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>